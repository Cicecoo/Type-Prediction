#registry
criterion: type_predicition_cross_entropy
optimizer: 'adam_simple'
lr_scheduler: 'polynomial_decay'
tokenizer: ~
bpe: ~

##################### default args #####################
common:
  no_progress_bar: 0
  log_interval: 100
  log_format: simple
  tensorboard_logdir: ''
  seed: 1
  cpu: 0
  fp16: 0
  memory_efficient_fp16: 0
  fp16_no_flatten_grads: 0
  fp16_init_scale: 128
  fp16_scale_window: ~
  fp16_scale_tolerance: 0.0
  min_loss_scale: 1e-4
  threshold_loss_scale: ~
  user_dir: ~
  empty_cache_freq: 0
  all_gather_list_size: 16384
  task: type_prediction

dataset:
  num_workers: 0
  skip_invalid_size_inputs_valid_test: 1
  max_tokens: ~
  max_sentences: 16
  required_batch_size_multiple: 8
  dataset_impl: raw
  train_subset: train
  valid_subset: valid
  validate_interval: 1
  fixed_validation_seed: ~
  disable_validation: 1
  max_tokens_valid: ~
  max_sentences_valid: 16
  curriculum: 100
  test_subset: test
  num_shards: 1
  shard_id: 0

  joined_dictionary: 1
  srcdict: /mnt/data1/zhaojunzhang/typilus-data/transformer/dict.txt
  src_sp: ~
  tgtdict: /mnt/data1/zhaojunzhang/typilus-data/transformer/dict.txt

distributed_training:
  distributed_world_size: 1
  distributed_rank: 0
  distributed_backend: nccl
  distributed_init_method: ~
  distributed_port: -1
  device_id: 0
  distributed_no_spawn: 0
  ddp_backend: c10d
  bucket_cap_mb: 25
  fix_batches_to_gpus: ~
  find_unused_parameters: 0
  fast_stat_sync: 0
  broadcast_buffers: 0
  global_sync_iter: 50
  warmup_iterations: 500

task:
  data: /mnt/data1/zhaojunzhang/typilus-data/transformer
  sample_break_mode: complete
  tokens_per_sample: 1024
  mask_prob: 0.15
  leave_unmasked_prob: 0.1
  random_token_prob: 0.1
  freq_weighted_replacement: 0
  mask_whole_words: 0
  pooler_activation_fn: 'tanh'
  
  source_lang: code
  target_lang: type
  load_alignments: 0
  left_pad_source: 1
  left_pad_target: 0
  max_source_positions: 2048
  max_target_positions: 2048
  upsample_primary: 1
  truncate_source: 1
  eval_accuracy: 1

model:
  arch: typetransformer
  pooler_dropout: 0.0
  activation_fn: gelu
  dropout: 0.0
  attention_dropout: 0.0
  activation_dropout: 0.0
  relu_dropout: 0.0
  encoder_type: lstm
  encoder_positional_embeddings: 1
  encoder_embed_path: 0
  encoder_embed_dim: 512
  encoder_ffn_embed_dim: 2048
  encoder_layers: 2
  encoder_attention_heads: 8
  encoder_normalize_before: 0
  encoder_learned_pos: 0
  decoder_embed_path: ''
  decoder_embed_dim: 0
  decoder_ffn_embed_dim: 0
  decoder_layers: 0
  decoder_attention_heads: 0
  decoder_learned_pos: 0
  decoder_normalize_before: 0
  share_decoder_input_output_embed: 0
  share_all_embeddings: 0
  no_token_positional_embeddings: 0
  adaptive_softmax_cutoff: 0
  adaptive_softmax_dropout: 0.0
  no_cross_attention: 0
  cross_self_attention: 0
  layer_wise_attention: 0
  encoder_layerdrop: 0.0
  decoder_layerdrop: 0.0
  encoder_layers_to_keep: ~
  decoder_layers_to_keep: ~
  layernorm_embedding: 0
  no_scale_embedding: 0
  encoder_max_relative_len: 0
  max_source_positions: 2048
  max_target_positions: 2048

optimization:
  max_epoch: 0
  max_update: 100
  clip_norm: 25
  sentence_avg: ~
  update_freq:
    - 1
  lr:
    - 0.0001
  min_lr: -1
  use_bmuf: 0
  force_anneal: ~
  warmup_updates: 5000
  end_learning_rate: 0.0
  power: 1.0
  total_num_update: 125000

  adam:
    adam_betas: '(0.9, 0.999)'
    adam_eps: 1e-6
    weight_decay: 0.0
    use_old_adam: 1

  adagrad:
    weight_decay: 0.0

  binary_cross_entropy:
    infonce: 0
    loss-weights: ''
    log-keys: ''

checkpoint:
  save_dir: /mnt/data1/zhaojunzhang/typilus-data/transformer/checkpoints
  restore_file: checkpoint_last.pt
  reset_dataloader: ~
  reset_lr_scheduler: ~
  reset_meters: ~
  reset_optimizer: ~
  optimizer_overrides: '{}'
  save_interval: 1
  save_interval_updates: 0
  keep_interval_updates: 0
  keep_last_epochs: -1
  keep_best_checkpoints: -1
  no_save: 0
  no_epoch_checkpoints: 0
  no_last_checkpoints: 0
  no_save_optimizer_state: ~
  best_checkpoint_metric: loss
  maximize_best_checkpoint_metric: 0
  patience: -1

eval:
  path: /mnt/data1/zhaojunzhang/typilus-data/transformer/checkpoints/checkpoint_last.pt
  remove_bpe: ~
  quiet: 1
  results_path: ~
  model_overrides: '{}'
