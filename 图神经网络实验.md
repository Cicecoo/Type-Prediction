## 数据集准备

Nov.3
### 使用docker

```
docker run --rm -it -v D:\WorkSpace\Projects\TypePred\typilus\data:/usr/data typilus-env:latest bash
```


### 脱离docker 下载数据

这个 Docker 容器是为了**数据准备流程**设计的，它会：

1. **下载 Python 代码仓库**（从 GitHub）
2. **使用 pytype 进行类型推断**（耗时很长）
3. **构建图数据结构**用于深度学习模型
4. **数据集分割**（训练/验证/测试集）

容器包含的关键工具：

- Python 3.6 + 175个常用库（TensorFlow, PyTorch, pandas 等）
- **pytype**（Google 的 Python 类型推断工具）
- **.NET Core SDK 2.2**（可能用于某些分析工具）
- Git（克隆仓库）
- 各种数据处理工具

是否必要？

**如果你有 Linux 服务器，Docker 不是必须的！**

#### 记录

而且，数据的下载和处理不必要耦合，完全可以先把代码下载好再考虑处理，而不用一直挂着docker

挂上screen下载数据

而且，既然是都说了占用很多空间，就不能把占用多少空间说明白吗？


### 修改脚本处理数据

Nov.4

- 新增了本地版脚本：[prepare_data_local.sh](vscode-file://vscode-app/d:/WorkSpace/Microsoft/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-browser/workbench/workbench.html)
    - 不再使用 `/usr/data`、[src](vscode-file://vscode-app/d:/WorkSpace/Microsoft/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-browser/workbench/workbench.html) 等容器路径，默认在当前工作目录下创建 `data-prep/` 输出。
    - 支持两种输入文件格式：
        - 每行一个 Git URL
        - 每行“`<url> <commit_sha>`”（即 spec）
    - 不再用脆弱的 `${line:19:-4}` 截字符串，改为从 URL 稳健解析目录名（`<owner>.<repo>`）。
    - pytype 的 Python 版本可配置（默认用当前 Python 次版本），自动收集本机 site-packages 供 pytype 查找依赖。
    - 近重复检测（dotnet）与 pytype 两步均可通过开关跳过（方便先跑通）。
    - 自动生成 [dataset.spec](vscode-file://vscode-app/d:/WorkSpace/Microsoft/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-browser/workbench/workbench.html)，后续图抽取与数据集切分按本地路径执行。
- 已设置新脚本可执行权限，并做了语法检查（bash -n）通过。

运行结束后，主要产物会在你指定的输出目录（默认 `./data-prep`）：

- [dataset.spec](vscode-file://vscode-app/d:/WorkSpace/Microsoft/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-browser/workbench/workbench.html)：规范化后的 URL+commit 列表
- `raw_repos/`：克隆的仓库
- `corpus_duplicates.json`：近重复（如未跳过）
- `graph-dataset/` 和 `graph-dataset-split/`：图数据及划分结果



```
# 1) 设定新数据根目录

DATA_ROOT=/mnt/data1/zhaojunzhang/typilus-data
SRC_DIR=/mnt/data1/zhaojunzhang/type_pred/typilus/src/data_preparation
mkdir -p "$DATA_ROOT/raw_repos"

# 2) 仅移动 git 仓库目录，安全且不误伤其它文件夹

find "$SRC_DIR" -mindepth 1 -maxdepth 1 -type d -print0 \
| while IFS= read -r -d '' d; do
  if [ -d "$d/.git" ]; then
    mv "$d" "$DATA_ROOT/raw_repos/"
  fi
done

# 3) 用本地脚本复用这些仓库（跳过克隆）

bash scripts/prepare_data_local.sh \
  -i - \
  --raw-repos "$DATA_ROOT/raw_repos" \
  -o "$DATA_ROOT"
```

执行脚本

```
DATA_ROOT=/mnt/data1/zhaojunzhang/typilus-data; cd /mnt/data1/zhaojunzhang/type_pred/typilus/src/data_preparation && bash scripts/prepare_data_local.sh -i - --raw-repos "$DATA_ROOT/raw_repos" -o "$DATA_ROOT" --skip-dedup --skip-pytype
```

``` 
screen -L -Logfile /home/zhaojunzhang/workspace/type_pred/screen/log_typilus_procress.txt -S type_data_2
```


### 训练

Nov.5

![[Pasted image 20251105230818.png]]

之前感觉拉下来的naturalcc和指导书对不上，没有setup没法install，也没有对应的data文件夹；
第一想法版本可能不对，就去原仓库看了
发现除了现在的main，还有一个master分支，感觉可能是老版本主分支，切换分支一看确实和文档描述对的上

typilus图数据也处理好了（没用docker）

![[Pasted image 20251105231157.png]]

之前想装个 tree，结果发现网上提供的官网打不开了，感觉可能比较花时间就先搁置了

接下来是naturalcc里的数据处理

先修改配置文件

![[Pasted image 20251105231602.png]]

![[Pasted image 20251105231741.png]]


![[Pasted image 20251105231916.png]]
![[Pasted image 20251105232018.png]]

忘记了checkout后requirements也不一样了

![[Pasted image 20251105232114.png]]

有一些版本冲突

![[Pasted image 20251105233239.png]]


重新指定 transformers\=\=4.28.1 和 tokenizers\=\=0.13.3 解决

![[Pasted image 20251105234956.png]]

改代码还是降级np？
![[Pasted image 20251105235019.png]]
![[Pasted image 20251105235123.png]]
![[Pasted image 20251105235212.png]]
![[Pasted image 20251105235236.png]]

之后是文档提到的NCC环境变量问题

![[Pasted image 20251105235313.png]]

干脆直接 开个 screen 并设置环境变量

![[Pasted image 20251105235431.png]]

```
export NCC=/mnt/data1/zhaojunzhang/typilus-data
```

成功运行

![[Pasted image 20251105235720.png]]

遇到了编码问题，不知道有没有影响

![[Pasted image 20251105235911.png]]


跑半天结果缺依赖

![[Pasted image 20251106005002.png]]


### 训练

Nov.6

数据集处理应该是完成了

![[Pasted image 20251106194808.png]]

```
screen -L -Logfile ./screen/log_naturalcc_train_2.txt -S naturalcc_train_2
```

```
conda activate naturalcc
```

```
pip install scikit-learn
```

![[Pasted image 20251106195133.png]]

![[Pasted image 20251106195205.png]]

device_id: 3

```
python naturalcc/run/type_prediction/typilus/train.py
```

![[Pasted image 20251106195421.png]]

conda install -n naturalcc -c conda-forge -y p11-kit gnutls libffi=3.4.*


之后 dgl 找不到需要的动态库，重装dgl

![[Pasted image 20251106202055.png]]

```
我查了你的环境并复现了导入失败的原因：你当前是 torch=2.4.0+cu124（CUDA 12.4），而已安装的 DGL 是 2.1.0，里面的 graphbolt 目录只带到了 2.2.x 的 .so，没有 libgraphbolt_pytorch_2.4.0.so，所以导入 dgl 报错。

我已在你的环境里做了这两步来解堵：

- 卸载了旧的 dgl 2.1.0
- 安装了与 PyTorch 2.4 匹配的 DGL CPU 轮子（dgl 2.4.0）
    - 验证：import dgl 成功，dgl=2.4.0

这解决了 FileNotFoundError 导入问题，但注意：这是 CPU 版 DGL。你的训练配置 [typilus.yml](vscode-file://vscode-app/d:/WorkSpace/Microsoft/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-browser/workbench/workbench.html) 里 `common.cpu: 0`，训练会把 DGLGraph 移到 GPU（[utils.apply_to_sample](vscode-file://vscode-app/d:/WorkSpace/Microsoft/Microsoft%20VS%20Code/resources/app/out/vs/code/electron-browser/workbench/workbench.html) 里对 DGLGraph 调用 `.to('cuda')`）。如果继续用 CPU 版 DGL，在动用 GPU 的地方会报 “DGL 未启用 CUDA”的错误。
```

```
换成 PyTorch 2.4.0 + cu121，然后安装对应的 DGL GPU 轮子
```

####

关于 dgl 的安装，花了很多时间
早知道先看官网了

https://www.dgl.ai/pages/start.html

```
pip install  dgl -f https://data.dgl.ai/wheels/torch-2.4/cu124/repo.html
```

![[Pasted image 20251106210636.png]]

比gpt好使
#### 

yaml版本问题

```
AttributeError: 
"safe_load()" has been removed, use

  yaml = YAML(typ='safe', pure=True)
  yaml.load(...)

instead of file "/home/zhaojunzhang/workspace/type_pred/naturalcc/ncc/utils/file_ops/yaml_io.py", line 54

        args = yaml.safe_load(reader)
```

####

```
FileNotFoundError: [Errno 2] No such file or directory: '~/typilus/type_inference/data-mmap/nodes.dict.json'
```

应该是开了新screen忘了配置环境变量

export NCC=/mnt/data1/zhaojunzhang/typilus-data


####

发现数据集没有准备好

```
FileNotFoundError: [Errno 2] No such file or directory: '/mnt/data1/zhaojunzhang/typilus-data/typilus/type_inference/data-mmap/nodes.dict.json'
```


查找log发现
```
"/mnt/data1/zhaojunzhang/type_pred/typilus/src/data_preparation/scripts/graph_generator/typeparsing/aliasreplacement.py", line 40, in <genexpr>
    (e.accept_visitor(self) for e in node.elements)
AttributeError: 'NoneType' object has no attribute 'accept_visitor'

```

打开screen发现
```
  File "/mnt/data1/zhaojunzhang/packages/anaconda3/envs/naturalcc/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: /lib/x86_64-linux-gnu/libp11-kit.so.0: undefined symbol: ffi_type_pointer, version LIBFFI_BASE_7.0
```


应该也是dgl的问题，现在重跑

![[Pasted image 20251106213130.png]]

似乎可以了，不过可能要等到明天

![[Pasted image 20251106223600.png]]

结果比想象得快

![[Pasted image 20251107003616.png]]

开始训练

```
python naturalcc/run/type_prediction/typilus/train.py
```


![[Pasted image 20251107003742.png]]

![[Pasted image 20251107003759.png]]

加载时间比较长，可能超过一分钟

![[Pasted image 20251107003911.png]]

最大显存占用

![[Pasted image 20251107004103.png]]

居然有性能监控？

![[Pasted image 20251107004037.png]]

一个 epoch 比较快

![[Pasted image 20251107003950.png]]


很遗憾，还没去睡就爆炸了

```
Traceback (most recent call last):
  File "naturalcc/run/type_prediction/typilus/train.py", line 332, in <module>
    cli_main()
  File "naturalcc/run/type_prediction/typilus/train.py", line 327, in cli_main
    single_main(args)
  File "naturalcc/run/type_prediction/typilus/train.py", line 249, in single_main
    valid_losses = validate(args, trainer, task, epoch_itr, valid_subsets)
  File "naturalcc/run/type_prediction/typilus/train.py", line 129, in validate
    trainer.valid_step(sample)
  File "/mnt/data1/zhaojunzhang/packages/anaconda3/envs/naturalcc/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/home/zhaojunzhang/workspace/type_pred/naturalcc/ncc/trainers/ncc_trainers.py", line 580, in valid_step
    return self.valid_step(sample, raise_oom=True)
  File "/mnt/data1/zhaojunzhang/packages/anaconda3/envs/naturalcc/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/home/zhaojunzhang/workspace/type_pred/naturalcc/ncc/trainers/ncc_trainers.py", line 565, in valid_step
    _loss, sample_size, logging_output = self.task.valid_step(
  File "/home/zhaojunzhang/workspace/type_pred/naturalcc/ncc/tasks/ncc_task.py", line 359, in valid_step
    loss, sample_size, logging_output = criterion(model, sample)
  File "/mnt/data1/zhaojunzhang/packages/anaconda3/envs/naturalcc/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/mnt/data1/zhaojunzhang/packages/anaconda3/envs/naturalcc/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/zhaojunzhang/workspace/type_pred/naturalcc/ncc/criterions/type_prediction/typilus.py", line 23, in forward
    net_output = model(**sample['net_input'], tgt_ids=sample['target'])
  File "/mnt/data1/zhaojunzhang/packages/anaconda3/envs/naturalcc/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/mnt/data1/zhaojunzhang/packages/anaconda3/envs/naturalcc/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/zhaojunzhang/workspace/type_pred/naturalcc/ncc/models/type_prediction/typilus.py", line 165, in forward
    encoder_out = self.encoder(src_graphs, **kwargs)
  File "/mnt/data1/zhaojunzhang/packages/anaconda3/envs/naturalcc/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/mnt/data1/zhaojunzhang/packages/anaconda3/envs/naturalcc/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/zhaojunzhang/workspace/type_pred/naturalcc/ncc/models/type_prediction/typilus.py", line 98, in forward
    nodes = graphs.ndata.pop(node_tokens).long()
  File "/mnt/data1/zhaojunzhang/packages/anaconda3/envs/naturalcc/lib/python3.8/_collections_abc.py", line 795, in pop
    value = self[key]
  File "/mnt/data1/zhaojunzhang/packages/anaconda3/envs/naturalcc/lib/python3.8/site-packages/dgl/view.py", line 80, in __getitem__
    return self._graph._get_n_repr(self._ntid, self._nodes)[key]
  File "/mnt/data1/zhaojunzhang/packages/anaconda3/envs/naturalcc/lib/python3.8/site-packages/dgl/frame.py", line 688, in __getitem__
    return self._columns[name].data
KeyError: 'subtoken'
```

再往上翻翻发现

```
  File "/home/zhaojunzhang/workspace/type_pred/naturalcc/ncc/criterions/type_prediction/typilus.py", line 24, in forward
    loss, sample_size = self.compute_loss(model, net_output, sample, reduce=reduce)
  File "/home/zhaojunzhang/workspace/type_pred/naturalcc/ncc/criterions/type_prediction/typilus.py", line 35, in compute_loss
    triple_loss, _ = self.triplet_loss.compute_loss(net_output, sample['target_equal_ids'])
  File "/home/zhaojunzhang/workspace/type_pred/naturalcc/ncc/criterions/type_prediction/_triplet.py", line 38, in compute_loss
    distance = torch.norm(repr.unsqueeze(dim=0) - repr.unsqueeze(dim=1), dim=-1, p=1)  # B x B
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 65.04 GiB. GPU 3 has a total capacity of 79.14 GiB of which 37.97 GiB is free. Including non-PyTorch memory, this process has 41.14 GiB memory in use. Of the allocated memory 2.35 GiB is allocated by PyTorch, and 38.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:
```

原来爆显存了

#### 关于数据剪裁

数据剪裁要怎么做呢？

先没有做，而是修改了计算方式；

![[Pasted image 20251107011015.png]]

```
screen -L -Logfile ./screen/naturalcc_train_3.txt -S naturalcc_train_3
```

```
 conda activate naturalcc
```

```
export NCC=/mnt/data1/zhaojunzhang/typilus-data
```

```
python ./run/type_prediction/typilus/train.py
```

似乎有自动恢复机制，但感觉可能不太根本

```
 (ncc_trainers.py:763, _log_oom())
[2025-11-07 01:16:49] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())
```

成功完成 1 epoch

![[Pasted image 20251107011940.png]]

但之前似乎是在验证阶段出问题

不知道能不能成功


### 推理

Nov.10 
完成训练后，这两天在搞推理

![[截屏2025-11-10 15.40.59.png]]


完成推理脚本后开始看优化部分
想着先调调参

![[截屏2025-11-10 17.24.26.png]]

到第三个 epoch loss 就开始波动不下降了
训练感觉有问题