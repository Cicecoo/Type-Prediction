[32m[2025-11-19 03:56:52]    INFO >> åŠ è½½é…ç½®: /home/zhaojunzhang/naturalcc/typilus/experiments/exp_lr_1e-4/config.yml (train_enhanced.py:382, cli_main())[0m
[32m[2025-11-19 03:56:52]    INFO >> å•GPUè®­ç»ƒ... (train_enhanced.py:410, cli_main())[0m
[32m[2025-11-19 03:56:52]    INFO >> è®­ç»ƒæ—¥å¿—å°†ä¿å­˜åˆ°: /home/zhaojunzhang/naturalcc/typilus/experiments/exp_lr_1e-4/logs (train_enhanced.py:296, single_main())[0m
[32m[2025-11-19 03:56:52]    INFO >> [nodes] dictionary: 9999 types (typilus.py:102, setup_task())[0m
[32m[2025-11-19 03:56:52]    INFO >> [edges] dictionary: 0 types (typilus.py:102, setup_task())[0m
[32m[2025-11-19 03:56:52]    INFO >> [supernodes.annotation] dictionary: 99 types (typilus.py:106, setup_task())[0m
[32m[2025-11-19 03:57:00]    INFO >> Typilus(
  (encoder): GGNNEncoder(
    (node_embedding): Embedding(9999, 64, padding_idx=0)
    (node_layer): Sequential(
      (0): Dropout(p=0.1, inplace=False)
      (1): Linear(in_features=64, out_features=64, bias=False)
      (2): Dropout(p=0.1, inplace=False)
    )
    (ggnns): ModuleList(
      (0): GatedGNN(
        (edge_weights): ModuleDict(
          (CHILD): Linear(in_features=64, out_features=64, bias=False)
          (OCCURRENCE_OF): Linear(in_features=64, out_features=64, bias=False)
          (NEXT): Linear(in_features=64, out_features=64, bias=False)
          (SUBTOKEN_OF): Linear(in_features=64, out_features=64, bias=False)
          (COMPUTED_FROM): Linear(in_features=64, out_features=64, bias=False)
          (LAST_LEXICAL_USE): Linear(in_features=64, out_features=64, bias=False)
          (NEXT_USE): Linear(in_features=64, out_features=64, bias=False)
          (RETURNS_TO): Linear(in_features=64, out_features=64, bias=False)
          (_CHILD): Linear(in_features=64, out_features=64, bias=False)
          (_OCCURRENCE_OF): Linear(in_features=64, out_features=64, bias=False)
          (_NEXT): Linear(in_features=64, out_features=64, bias=False)
          (_SUBTOKEN_OF): Linear(in_features=64, out_features=64, bias=False)
          (_COMPUTED_FROM): Linear(in_features=64, out_features=64, bias=False)
          (_LAST_LEXICAL_USE): Linear(in_features=64, out_features=64, bias=False)
          (_NEXT_USE): Linear(in_features=64, out_features=64, bias=False)
          (_RETURNS_TO): Linear(in_features=64, out_features=64, bias=False)
        )
        (rnn_cell): GRUCell(64, 64)
      )
      (1): GatedGNN(
        (edge_weights): ModuleDict(
          (CHILD): Linear(in_features=64, out_features=64, bias=False)
          (OCCURRENCE_OF): Linear(in_features=64, out_features=64, bias=False)
          (NEXT): Linear(in_features=64, out_features=64, bias=False)
          (SUBTOKEN_OF): Linear(in_features=64, out_features=64, bias=False)
          (COMPUTED_FROM): Linear(in_features=64, out_features=64, bias=False)
          (LAST_LEXICAL_USE): Linear(in_features=64, out_features=64, bias=False)
          (NEXT_USE): Linear(in_features=64, out_features=64, bias=False)
          (RETURNS_TO): Linear(in_features=64, out_features=64, bias=False)
          (_CHILD): Linear(in_features=64, out_features=64, bias=False)
          (_OCCURRENCE_OF): Linear(in_features=64, out_features=64, bias=False)
          (_NEXT): Linear(in_features=64, out_features=64, bias=False)
          (_SUBTOKEN_OF): Linear(in_features=64, out_features=64, bias=False)
          (_COMPUTED_FROM): Linear(in_features=64, out_features=64, bias=False)
          (_LAST_LEXICAL_USE): Linear(in_features=64, out_features=64, bias=False)
          (_NEXT_USE): Linear(in_features=64, out_features=64, bias=False)
          (_RETURNS_TO): Linear(in_features=64, out_features=64, bias=False)
        )
        (rnn_cell): GRUCell(128, 64)
      )
    )
  )
  (decoder): DenseDecoder(
    (cls_layers): Sequential(
      (0): Linear(in_features=64, out_features=64, bias=False)
      (1): Dropout(p=0.1, inplace=False)
      (2): Linear(in_features=64, out_features=99, bias=True)
    )
  )
) (train_enhanced.py:303, single_main())[0m
[32m[2025-11-19 03:57:00]    INFO >> æ¨¡åž‹: typilus, æŸå¤±å‡½æ•°: TypilusCriterion (train_enhanced.py:304, single_main())[0m
[32m[2025-11-19 03:57:00]    INFO >> æ¨¡åž‹å‚æ•°: 847843 (å¯è®­ç»ƒ: 847843) (train_enhanced.py:305, single_main())[0m
[32m[2025-11-19 03:57:00]    INFO >> ***********************CUDA enviroments for all 1 workers*********************** (utils.py:530, pretty_print_cuda_env_list())[0m
[32m[2025-11-19 03:57:00]    INFO >> rank   0: capabilities =  8.0  ; total memory = 81920 MB ; free memory = 80579 MB ; used memory = 1340 MB ; name = NVIDIA A800 80GB PCIe                    (utils.py:532, pretty_print_cuda_env_list())[0m
[32m[2025-11-19 03:57:00]    INFO >> ***********************CUDA enviroments for all 1 workers*********************** (utils.py:540, pretty_print_cuda_env_list())[0m
[32m[2025-11-19 03:57:00]    INFO >> ä½¿ç”¨ 1 ä¸ªGPUè®­ç»ƒ (train_enhanced.py:311, single_main())[0m
[32m[2025-11-19 03:57:00]    INFO >> no existing checkpoint found /home/zhaojunzhang/naturalcc/typilus/experiments/exp_lr_1e-4/checkpoints/checkpoint_last.pt (ncc_trainers.py:299, load_checkpoint())[0m
[32m[2025-11-19 03:57:00]    INFO >> loading train data for epoch 1 (ncc_trainers.py:314, get_train_iterator())[0m
[32m[2025-11-19 03:57:59]    INFO >> NOTE: your device may support faster training with fp16 or --amp (ncc_trainers.py:183, _setup_optimizer())[0m
[33m[2025-11-19 03:57:59] WARNING >> tensorboard or required dependencies not found, please see README for using tensorboard. (e.g. pip install tensorboardX) (progress_bar.py:314, __init__())[0m
/home/zhaojunzhang/workspace/type_pred/naturalcc/ncc/tasks/ncc_task.py:348: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=(isinstance(optimizer, AMPOptimizer))):
/home/zhaojunzhang/workspace/type_pred/naturalcc/ncc/utils/gradient_clip/fairseq_clip.py:56: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
[32m[2025-11-19 03:58:06]    INFO >> epoch 001:     50 / 1539 loss=5.57, wps=5307.8, ups=7.34, wpb=720, bsz=720, num_updates=50, lr=0.0001, gnorm=6.038, clip=0, train_wall=6, gb_free=74.2, wall=63 (progress_bar.py:258, log())[0m
[33m[2025-11-19 03:58:07] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 43.25 MiB is free. Including non-PyTorch memory, this process has 79.07 GiB memory in use. Of the allocated memory 73.64 GiB is allocated by PyTorch, and 4.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 03:58:07] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 2         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  75347 MiB |  75407 MiB |   1756 GiB |   1682 GiB |
|       from large pool |  74991 MiB |  75051 MiB |   1743 GiB |   1670 GiB |
|       from small pool |    356 MiB |    357 MiB |     12 GiB |     12 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  75347 MiB |  75407 MiB |   1756 GiB |   1682 GiB |
|       from large pool |  74991 MiB |  75051 MiB |   1743 GiB |   1670 GiB |
|       from small pool |    356 MiB |    357 MiB |     12 GiB |     12 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  75195 MiB |  75254 MiB |   1750 GiB |   1676 GiB |
|       from large pool |  74841 MiB |  74900 MiB |   1737 GiB |   1664 GiB |
|       from small pool |    354 MiB |    355 MiB |     12 GiB |     12 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  80462 MiB |  80498 MiB |  91994 MiB |  11532 MiB |
|       from large pool |  80070 MiB |  80136 MiB |  91590 MiB |  11520 MiB |
|       from small pool |    392 MiB |    394 MiB |    404 MiB |     12 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   5054 MiB |   5960 MiB |    875 GiB |    870 GiB |
|       from large pool |   5018 MiB |   5948 MiB |    859 GiB |    855 GiB |
|       from small pool |     35 MiB |     37 MiB |     15 GiB |     14 GiB |
|---------------------------------------------------------------------------|
| Allocations           |    6579    |    6582    |  136626    |  130047    |
|       from large pool |     868    |     869    |   57719    |   56851    |
|       from small pool |    5711    |    5714    |   78907    |   73196    |
|---------------------------------------------------------------------------|
| Active allocs         |    6579    |    6582    |  136626    |  130047    |
|       from large pool |     868    |     869    |   57719    |   56851    |
|       from small pool |    5711    |    5714    |   78907    |   73196    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     758    |     793    |    1006    |     248    |
|       from large pool |     562    |     612    |     804    |     242    |
|       from small pool |     196    |     197    |     202    |       6    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     654    |     656    |   86039    |   85385    |
|       from large pool |     306    |     306    |   44256    |   43950    |
|       from small pool |     348    |     350    |   41783    |   41435    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 03:58:07] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 03:58:07] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 03:58:07] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 03:58:07] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 03:58:13]    INFO >> epoch 001:    101 / 1539 loss=5.692, wps=4677.1, ups=7.66, wpb=610.7, bsz=610.7, num_updates=100, lr=0.0001, gnorm=5.849, clip=0, train_wall=5, gb_free=75.6, wall=70 (progress_bar.py:258, log())[0m
[32m[2025-11-19 03:58:21]    INFO >> epoch 001:    151 / 1539 loss=5.62, wps=5759.5, ups=7.05, wpb=816.7, bsz=816.7, num_updates=150, lr=0.0001, gnorm=6.153, clip=0, train_wall=6, gb_free=74.2, wall=77 (progress_bar.py:258, log())[0m
[32m[2025-11-19 03:58:27]    INFO >> epoch 001:    201 / 1539 loss=5.567, wps=5242.6, ups=8.17, wpb=641.7, bsz=641.7, num_updates=200, lr=0.0001, gnorm=6.281, clip=0, train_wall=6, gb_free=74.8, wall=83 (progress_bar.py:258, log())[0m
[32m[2025-11-19 03:58:34]    INFO >> epoch 001:    251 / 1539 loss=5.663, wps=5067.7, ups=7.94, wpb=637.9, bsz=637.9, num_updates=250, lr=0.0001, gnorm=6.518, clip=0, train_wall=6, gb_free=71.5, wall=89 (progress_bar.py:258, log())[0m
[32m[2025-11-19 03:58:41]    INFO >> epoch 001:    301 / 1539 loss=5.57, wps=5458.4, ups=6.94, wpb=786.5, bsz=786.5, num_updates=300, lr=0.0001, gnorm=6.767, clip=0, train_wall=7, gb_free=73.8, wall=97 (progress_bar.py:258, log())[0m
[32m[2025-11-19 03:58:47]    INFO >> epoch 001:    351 / 1539 loss=5.703, wps=5350.4, ups=7.97, wpb=671.6, bsz=671.6, num_updates=350, lr=0.0001, gnorm=7.192, clip=0, train_wall=6, gb_free=72.4, wall=103 (progress_bar.py:258, log())[0m
[32m[2025-11-19 03:58:56]    INFO >> epoch 001:    401 / 1539 loss=5.694, wps=5887.4, ups=6.91, wpb=851.7, bsz=851.7, num_updates=400, lr=0.0001, gnorm=7.357, clip=0, train_wall=7, gb_free=73.2, wall=110 (progress_bar.py:258, log())[0m
[33m[2025-11-19 03:59:05] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 7.25 MiB is free. Including non-PyTorch memory, this process has 79.11 GiB memory in use. Of the allocated memory 77.81 GiB is allocated by PyTorch, and 823.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 03:59:05] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 2            |        cudaMalloc retries: 4         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  79614 MiB |  79674 MiB |  12419 GiB |  12342 GiB |
|       from large pool |  79520 MiB |  79580 MiB |  12346 GiB |  12268 GiB |
|       from small pool |     94 MiB |     95 MiB |     73 GiB |     73 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  79614 MiB |  79674 MiB |  12419 GiB |  12342 GiB |
|       from large pool |  79520 MiB |  79580 MiB |  12346 GiB |  12268 GiB |
|       from small pool |     94 MiB |     95 MiB |     73 GiB |     73 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  79544 MiB |  79604 MiB |  12379 GiB |  12302 GiB |
|       from large pool |  79450 MiB |  79510 MiB |  12306 GiB |  12228 GiB |
|       from small pool |     93 MiB |     95 MiB |     73 GiB |     73 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  80498 MiB |  80500 MiB | 166722 MiB |  86224 MiB |
|       from large pool |  80400 MiB |  80400 MiB | 166242 MiB |  85842 MiB |
|       from small pool |     98 MiB |    392 MiB |    480 MiB |    382 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |    823 MiB |   3119 MiB |   6143 GiB |   6143 GiB |
|       from large pool |    819 MiB |   3112 MiB |   6057 GiB |   6057 GiB |
|       from small pool |      3 MiB |     23 MiB |     85 GiB |     85 GiB |
|---------------------------------------------------------------------------|
| Allocations           |    2036    |    2039    |     869 K  |     867 K  |
|       from large pool |     477    |     478    |     421 K  |     421 K  |
|       from small pool |    1559    |    1562    |     447 K  |     445 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    2036    |    2039    |     869 K  |     867 K  |
|       from large pool |     477    |     478    |     421 K  |     421 K  |
|       from small pool |    1559    |    1562    |     447 K  |     445 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     251    |     757    |    1201    |     950    |
|       from large pool |     202    |     561    |     961    |     759    |
|       from small pool |      49    |     196    |     240    |     191    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     132    |     133    |  540020    |  539888    |
|       from large pool |      79    |      81    |  324754    |  324675    |
|       from small pool |      53    |      55    |  215266    |  215213    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 03:59:05] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 03:59:05] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 03:59:05] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 03:59:05] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 03:59:08]    INFO >> epoch 001:    452 / 1539 loss=5.833, wps=2463.6, ups=3.9, wpb=631.6, bsz=631.6, num_updates=450, lr=0.0001, gnorm=6.638, clip=0, train_wall=6, gb_free=71.8, wall=123 (progress_bar.py:258, log())[0m
[32m[2025-11-19 03:59:18]    INFO >> epoch 001:    502 / 1539 loss=5.799, wps=3944.7, ups=5.31, wpb=743.1, bsz=743.1, num_updates=500, lr=0.0001, gnorm=6.936, clip=0, train_wall=9, gb_free=72.6, wall=132 (progress_bar.py:258, log())[0m
[32m[2025-11-19 03:59:26]    INFO >> epoch 001:    552 / 1539 loss=5.779, wps=4942.8, ups=7.52, wpb=657, bsz=657, num_updates=550, lr=0.0001, gnorm=6.985, clip=0, train_wall=6, gb_free=65.5, wall=139 (progress_bar.py:258, log())[0m
[32m[2025-11-19 03:59:32]    INFO >> epoch 001:    602 / 1539 loss=5.854, wps=5057.9, ups=7.56, wpb=668.6, bsz=668.6, num_updates=600, lr=0.0001, gnorm=7.03, clip=0, train_wall=6, gb_free=73.2, wall=146 (progress_bar.py:258, log())[0m
[32m[2025-11-19 03:59:40]    INFO >> epoch 001:    652 / 1539 loss=5.783, wps=4998.5, ups=7.02, wpb=712.2, bsz=712.2, num_updates=650, lr=0.0001, gnorm=7.833, clip=2, train_wall=7, gb_free=73.5, wall=153 (progress_bar.py:258, log())[0m
[32m[2025-11-19 03:59:47]    INFO >> epoch 001:    702 / 1539 loss=6.041, wps=4264.3, ups=6.34, wpb=672.5, bsz=672.5, num_updates=700, lr=0.0001, gnorm=6.057, clip=0, train_wall=7, gb_free=74.1, wall=161 (progress_bar.py:258, log())[0m
[32m[2025-11-19 03:59:55]    INFO >> epoch 001:    752 / 1539 loss=5.747, wps=5111.8, ups=6.75, wpb=757.4, bsz=757.4, num_updates=750, lr=0.0001, gnorm=7.735, clip=0, train_wall=7, gb_free=73.7, wall=168 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:00:03]    INFO >> epoch 001:    802 / 1539 loss=5.821, wps=5260, ups=7.25, wpb=725.2, bsz=725.2, num_updates=800, lr=0.0001, gnorm=7.046, clip=0, train_wall=6, gb_free=73.4, wall=175 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:00:10]    INFO >> epoch 001:    852 / 1539 loss=5.797, wps=4439.5, ups=6.92, wpb=641.1, bsz=641.1, num_updates=850, lr=0.0001, gnorm=7.55, clip=2, train_wall=7, gb_free=71.8, wall=182 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:00:17]    INFO >> epoch 001:    902 / 1539 loss=5.883, wps=4794.2, ups=7.26, wpb=660.1, bsz=660.1, num_updates=900, lr=0.0001, gnorm=7.339, clip=0, train_wall=6, gb_free=72.1, wall=189 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:00:24]    INFO >> epoch 001:    952 / 1539 loss=5.912, wps=4998.3, ups=7.01, wpb=713.2, bsz=713.2, num_updates=950, lr=0.0001, gnorm=6.774, clip=0, train_wall=7, gb_free=71.8, wall=196 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:00:28] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacity of 79.14 GiB of which 901.25 MiB is free. Including non-PyTorch memory, this process has 78.24 GiB memory in use. Of the allocated memory 74.92 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:00:28] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 3            |        cudaMalloc retries: 7         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  76322 MiB |  78597 MiB |  28415 GiB |  28340 GiB |
|       from large pool |  76303 MiB |  78579 MiB |  28261 GiB |  28187 GiB |
|       from small pool |     18 MiB |     19 MiB |    153 GiB |    153 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  76322 MiB |  78597 MiB |  28415 GiB |  28340 GiB |
|       from large pool |  76303 MiB |  78579 MiB |  28261 GiB |  28187 GiB |
|       from small pool |     18 MiB |     19 MiB |    153 GiB |    153 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  76304 MiB |  78579 MiB |  28342 GiB |  28268 GiB |
|       from large pool |  76285 MiB |  78562 MiB |  28189 GiB |  28114 GiB |
|       from small pool |     18 MiB |     19 MiB |    153 GiB |    153 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  79604 MiB |  79604 MiB | 305536 MiB | 225932 MiB |
|       from large pool |  79580 MiB |  79580 MiB | 304982 MiB | 225402 MiB |
|       from small pool |     24 MiB |     98 MiB |    554 MiB |    530 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   3281 MiB |   4789 MiB |  24274 GiB |  24271 GiB |
|       from large pool |   3276 MiB |   4783 MiB |  24097 GiB |  24094 GiB |
|       from small pool |      5 MiB |     27 MiB |    177 GiB |    177 GiB |
|---------------------------------------------------------------------------|
| Allocations           |     638    |     644    |    1881 K  |    1880 K  |
|       from large pool |     340    |     346    |     949 K  |     948 K  |
|       from small pool |     298    |     354    |     931 K  |     931 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     638    |     644    |    1881 K  |    1880 K  |
|       from large pool |     340    |     346    |     949 K  |     948 K  |
|       from small pool |     298    |     354    |     931 K  |     931 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |      96    |     123    |    1327    |    1231    |
|       from large pool |      84    |      84    |    1050    |     966    |
|       from small pool |      12    |      49    |     277    |     265    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     115    |     117    |    1087 K  |    1087 K  |
|       from large pool |      93    |      95    |     661 K  |     661 K  |
|       from small pool |      22    |      56    |     426 K  |     426 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:00:28] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:00:28] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:00:28] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:00:28] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:00:35]    INFO >> epoch 001:   1003 / 1539 loss=5.856, wps=3511.7, ups=5.41, wpb=649.4, bsz=649.4, num_updates=1000, lr=0.0001, gnorm=7.773, clip=0, train_wall=7, gb_free=72.1, wall=205 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:00:43]    INFO >> epoch 001:   1053 / 1539 loss=5.844, wps=5379.9, ups=6.54, wpb=822.6, bsz=822.6, num_updates=1050, lr=0.0001, gnorm=6.994, clip=0, train_wall=7, gb_free=68, wall=213 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:00:50] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 1.86 GiB. GPU 0 has a total capacity of 79.14 GiB of which 197.25 MiB is free. Including non-PyTorch memory, this process has 78.92 GiB memory in use. Of the allocated memory 75.66 GiB is allocated by PyTorch, and 2.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:00:50] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 4            |        cudaMalloc retries: 9         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  76955 MiB |  77477 MiB |  32758 GiB |  32683 GiB |
|       from large pool |  76942 MiB |  77464 MiB |  32579 GiB |  32504 GiB |
|       from small pool |     12 MiB |     15 MiB |    178 GiB |    178 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  76955 MiB |  77477 MiB |  32758 GiB |  32683 GiB |
|       from large pool |  76942 MiB |  77464 MiB |  32579 GiB |  32504 GiB |
|       from small pool |     12 MiB |     15 MiB |    178 GiB |    178 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  76936 MiB |  77458 MiB |  32677 GiB |  32602 GiB |
|       from large pool |  76923 MiB |  77445 MiB |  32498 GiB |  32423 GiB |
|       from small pool |     12 MiB |     15 MiB |    178 GiB |    178 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  80308 MiB |  80308 MiB | 310972 MiB | 230664 MiB |
|       from large pool |  80284 MiB |  80284 MiB | 310232 MiB | 229948 MiB |
|       from small pool |     24 MiB |    210 MiB |    740 MiB |    716 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   3352 MiB |   9143 MiB |  29231 GiB |  29228 GiB |
|       from large pool |   3341 MiB |   9131 MiB |  29025 GiB |  29022 GiB |
|       from small pool |     11 MiB |     23 MiB |    206 GiB |    206 GiB |
|---------------------------------------------------------------------------|
| Allocations           |     604    |     611    |    2166 K  |    2165 K  |
|       from large pool |     315    |     322    |    1085 K  |    1085 K  |
|       from small pool |     289    |     354    |    1080 K  |    1079 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     604    |     611    |    2166 K  |    2165 K  |
|       from large pool |     315    |     322    |    1085 K  |    1085 K  |
|       from small pool |     289    |     354    |    1080 K  |    1079 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |      88    |     189    |    1425    |    1337    |
|       from large pool |      76    |      84    |    1055    |     979    |
|       from small pool |      12    |     105    |     370    |     358    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      84    |      84    |    1245 K  |    1245 K  |
|       from large pool |      60    |      60    |     746 K  |     746 K  |
|       from small pool |      24    |      53    |     498 K  |     498 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:00:50] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:00:50] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:00:50] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:00:50] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:00:51]    INFO >> epoch 001:   1104 / 1539 loss=5.743, wps=5271.2, ups=5.67, wpb=929.6, bsz=929.6, num_updates=1100, lr=0.0001, gnorm=8.066, clip=2, train_wall=8, gb_free=72.8, wall=222 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:00:58]    INFO >> epoch 001:   1154 / 1539 loss=5.929, wps=4867.8, ups=7.03, wpb=692.6, bsz=692.6, num_updates=1150, lr=0.0001, gnorm=7.234, clip=0, train_wall=7, gb_free=73.1, wall=229 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:01:07]    INFO >> epoch 001:   1204 / 1539 loss=5.838, wps=4843, ups=7.14, wpb=678.4, bsz=678.4, num_updates=1200, lr=0.0001, gnorm=7.488, clip=0, train_wall=6, gb_free=71.2, wall=236 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:01:14]    INFO >> epoch 001:   1254 / 1539 loss=5.875, wps=5072.2, ups=6.94, wpb=730.9, bsz=730.9, num_updates=1250, lr=0.0001, gnorm=7.674, clip=0, train_wall=7, gb_free=71.3, wall=243 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:01:22]    INFO >> epoch 001:   1304 / 1539 loss=5.871, wps=4904.9, ups=6.67, wpb=735.4, bsz=735.4, num_updates=1300, lr=0.0001, gnorm=6.204, clip=0, train_wall=7, gb_free=74.3, wall=251 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:01:29]    INFO >> epoch 001:   1354 / 1539 loss=5.873, wps=4627.9, ups=7.04, wpb=657.2, bsz=657.2, num_updates=1350, lr=0.0001, gnorm=7.225, clip=2, train_wall=7, gb_free=73.4, wall=258 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:01:37]    INFO >> epoch 001:   1404 / 1539 loss=5.781, wps=4739.6, ups=6.65, wpb=712.5, bsz=712.5, num_updates=1400, lr=0.0001, gnorm=6.857, clip=2, train_wall=7, gb_free=73.3, wall=265 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:01:45]    INFO >> epoch 001:   1454 / 1539 loss=5.858, wps=4834.8, ups=6.89, wpb=702.2, bsz=702.2, num_updates=1450, lr=0.0001, gnorm=6.653, clip=0, train_wall=7, gb_free=71.6, wall=273 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:01:52]    INFO >> epoch 001:   1504 / 1539 loss=5.825, wps=4811.2, ups=6.91, wpb=695.9, bsz=695.9, num_updates=1500, lr=0.0001, gnorm=7.257, clip=0, train_wall=7, gb_free=70.8, wall=280 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:01:57]    INFO >> epoch 001 | loss 5.785 | wps 4790.4 | ups 6.72 | wpb 712.7 | bsz 712.7 | num_updates 1535 | lr 0.0001 | gnorm 6.975 | clip 0.3 | train_wall 201 | gb_free 76.6 | wall 285 (progress_bar.py:267, print())[0m
[33m[2025-11-19 04:01:57] WARNING >> tensorboard or required dependencies not found, please see README for using tensorboard. (e.g. pip install tensorboardX) (progress_bar.py:314, __init__())[0m
[32m[2025-11-19 04:02:12]    INFO >> epoch 001 | valid on 'valid' subset | loss 5.983 | wps 11101.9 | wpb 5412.5 | bsz 5412.5 | num_updates 1535 (progress_bar.py:267, print())[0m
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
/home/zhaojunzhang/workspace/type_pred/naturalcc/run/type_prediction/typilus/experiment_tools/train_enhanced.py:114: UserWarning: Glyph 35757 (\N{CJK UNIFIED IDEOGRAPH-8BAD}) missing from current font.
  plt.tight_layout()
/home/zhaojunzhang/workspace/type_pred/naturalcc/run/type_prediction/typilus/experiment_tools/train_enhanced.py:114: UserWarning: Glyph 32451 (\N{CJK UNIFIED IDEOGRAPH-7EC3}) missing from current font.
  plt.tight_layout()
/home/zhaojunzhang/workspace/type_pred/naturalcc/run/type_prediction/typilus/experiment_tools/train_enhanced.py:114: UserWarning: Glyph 32479 (\N{CJK UNIFIED IDEOGRAPH-7EDF}) missing from current font.
  plt.tight_layout()
/home/zhaojunzhang/workspace/type_pred/naturalcc/run/type_prediction/typilus/experiment_tools/train_enhanced.py:114: UserWarning: Glyph 35745 (\N{CJK UNIFIED IDEOGRAPH-8BA1}) missing from current font.
  plt.tight_layout()
/home/zhaojunzhang/workspace/type_pred/naturalcc/run/type_prediction/typilus/experiment_tools/train_enhanced.py:114: UserWarning: Glyph 24635 (\N{CJK UNIFIED IDEOGRAPH-603B}) missing from current font.
  plt.tight_layout()
/home/zhaojunzhang/workspace/type_pred/naturalcc/run/type_prediction/typilus/experiment_tools/train_enhanced.py:114: UserWarning: Glyph 36718 (\N{CJK UNIFIED IDEOGRAPH-8F6E}) missing from current font.
  plt.tight_layout()
/home/zhaojunzhang/workspace/type_pred/naturalcc/run/type_prediction/typilus/experiment_tools/train_enhanced.py:114: UserWarning: Glyph 25968 (\N{CJK UNIFIED IDEOGRAPH-6570}) missing from current font.
  plt.tight_layout()
/home/zhaojunzhang/workspace/type_pred/naturalcc/run/type_prediction/typilus/experiment_tools/train_enhanced.py:114: UserWarning: Glyph 26368 (\N{CJK UNIFIED IDEOGRAPH-6700}) missing from current font.
  plt.tight_layout()
/home/zhaojunzhang/workspace/type_pred/naturalcc/run/type_prediction/typilus/experiment_tools/train_enhanced.py:114: UserWarning: Glyph 20339 (\N{CJK UNIFIED IDEOGRAPH-4F73}) missing from current font.
  plt.tight_layout()
/home/zhaojunzhang/workspace/type_pred/naturalcc/run/type_prediction/typilus/experiment_tools/train_enhanced.py:114: UserWarning: Glyph 39564 (\N{CJK UNIFIED IDEOGRAPH-9A8C}) missing from current font.
  plt.tight_layout()
/home/zhaojunzhang/workspace/type_pred/naturalcc/run/type_prediction/typilus/experiment_tools/train_enhanced.py:114: UserWarning: Glyph 35777 (\N{CJK UNIFIED IDEOGRAPH-8BC1}) missing from current font.
  plt.tight_layout()
/home/zhaojunzhang/workspace/type_pred/naturalcc/run/type_prediction/typilus/experiment_tools/train_enhanced.py:115: UserWarning: Glyph 35757 (\N{CJK UNIFIED IDEOGRAPH-8BAD}) missing from current font.
  plt.savefig(plots_dir / 'training.png', dpi=120, bbox_inches='tight')
/home/zhaojunzhang/workspace/type_pred/naturalcc/run/type_prediction/typilus/experiment_tools/train_enhanced.py:115: UserWarning: Glyph 32451 (\N{CJK UNIFIED IDEOGRAPH-7EC3}) missing from current font.
  plt.savefig(plots_dir / 'training.png', dpi=120, bbox_inches='tight')
/home/zhaojunzhang/workspace/type_pred/naturalcc/run/type_prediction/typilus/experiment_tools/train_enhanced.py:115: UserWarning: Glyph 32479 (\N{CJK UNIFIED IDEOGRAPH-7EDF}) missing from current font.
  plt.savefig(plots_dir / 'training.png', dpi=120, bbox_inches='tight')
/home/zhaojunzhang/workspace/type_pred/naturalcc/run/type_prediction/typilus/experiment_tools/train_enhanced.py:115: UserWarning: Glyph 35745 (\N{CJK UNIFIED IDEOGRAPH-8BA1}) missing from current font.
  plt.savefig(plots_dir / 'training.png', dpi=120, bbox_inches='tight')
/home/zhaojunzhang/workspace/type_pred/naturalcc/run/type_prediction/typilus/experiment_tools/train_enhanced.py:115: UserWarning: Glyph 24635 (\N{CJK UNIFIED IDEOGRAPH-603B}) missing from current font.
  plt.savefig(plots_dir / 'training.png', dpi=120, bbox_inches='tight')
/home/zhaojunzhang/workspace/type_pred/naturalcc/run/type_prediction/typilus/experiment_tools/train_enhanced.py:115: UserWarning: Glyph 36718 (\N{CJK UNIFIED IDEOGRAPH-8F6E}) missing from current font.
  plt.savefig(plots_dir / 'training.png', dpi=120, bbox_inches='tight')
/home/zhaojunzhang/workspace/type_pred/naturalcc/run/type_prediction/typilus/experiment_tools/train_enhanced.py:115: UserWarning: Glyph 25968 (\N{CJK UNIFIED IDEOGRAPH-6570}) missing from current font.
  plt.savefig(plots_dir / 'training.png', dpi=120, bbox_inches='tight')
/home/zhaojunzhang/workspace/type_pred/naturalcc/run/type_prediction/typilus/experiment_tools/train_enhanced.py:115: UserWarning: Glyph 26368 (\N{CJK UNIFIED IDEOGRAPH-6700}) missing from current font.
  plt.savefig(plots_dir / 'training.png', dpi=120, bbox_inches='tight')
/home/zhaojunzhang/workspace/type_pred/naturalcc/run/type_prediction/typilus/experiment_tools/train_enhanced.py:115: UserWarning: Glyph 20339 (\N{CJK UNIFIED IDEOGRAPH-4F73}) missing from current font.
  plt.savefig(plots_dir / 'training.png', dpi=120, bbox_inches='tight')
/home/zhaojunzhang/workspace/type_pred/naturalcc/run/type_prediction/typilus/experiment_tools/train_enhanced.py:115: UserWarning: Glyph 39564 (\N{CJK UNIFIED IDEOGRAPH-9A8C}) missing from current font.
  plt.savefig(plots_dir / 'training.png', dpi=120, bbox_inches='tight')
/home/zhaojunzhang/workspace/type_pred/naturalcc/run/type_prediction/typilus/experiment_tools/train_enhanced.py:115: UserWarning: Glyph 35777 (\N{CJK UNIFIED IDEOGRAPH-8BC1}) missing from current font.
  plt.savefig(plots_dir / 'training.png', dpi=120, bbox_inches='tight')
[32m[2025-11-19 04:02:13]    INFO >> è®­ç»ƒæ›²çº¿å·²ä¿å­˜: /home/zhaojunzhang/naturalcc/typilus/experiments/exp_lr_1e-4/logs/plots/training.png (train_enhanced.py:118, plot())[0m
[32m[2025-11-19 04:02:13]    INFO >> saved checkpoint /home/zhaojunzhang/naturalcc/typilus/experiments/exp_lr_1e-4/checkpoints/checkpoint_best.pt (epoch 1 @ 1535 updates, score 5.983) (writing took 0.014811 seconds) (checkpoint_utils.py:78, save_checkpoint())[0m
[33m[2025-11-19 04:02:13] WARNING >> tensorboard or required dependencies not found, please see README for using tensorboard. (e.g. pip install tensorboardX) (progress_bar.py:314, __init__())[0m
/home/zhaojunzhang/workspace/type_pred/naturalcc/ncc/tasks/ncc_task.py:348: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=(isinstance(optimizer, AMPOptimizer))):
/home/zhaojunzhang/workspace/type_pred/naturalcc/ncc/utils/gradient_clip/fairseq_clip.py:56: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
[32m[2025-11-19 04:02:15]    INFO >> epoch 002:     15 / 1539 loss=5.818, wps=1722.6, ups=2.36, wpb=731.3, bsz=731.3, num_updates=1550, lr=0.0001, gnorm=6.524, clip=0, train_wall=7, gb_free=74.4, wall=301 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:02:21]    INFO >> epoch 002:     65 / 1539 loss=5.683, wps=4982.6, ups=7.56, wpb=658.8, bsz=658.8, num_updates=1600, lr=0.0001, gnorm=7.763, clip=0, train_wall=6, gb_free=73.4, wall=308 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:02:28]    INFO >> epoch 002:    115 / 1539 loss=5.71, wps=4960.1, ups=6.94, wpb=714.6, bsz=714.6, num_updates=1650, lr=0.0001, gnorm=7.442, clip=2, train_wall=7, gb_free=65.7, wall=315 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:02:36]    INFO >> epoch 002:    165 / 1539 loss=5.662, wps=5072.6, ups=6.87, wpb=738.8, bsz=738.8, num_updates=1700, lr=0.0001, gnorm=7.15, clip=2, train_wall=7, gb_free=73.6, wall=322 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:02:43]    INFO >> epoch 002:    215 / 1539 loss=5.834, wps=4975.1, ups=7.07, wpb=704.2, bsz=704.2, num_updates=1750, lr=0.0001, gnorm=7.26, clip=2, train_wall=7, gb_free=71.2, wall=329 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:02:52]    INFO >> epoch 002:    265 / 1539 loss=5.716, wps=5415.2, ups=6.2, wpb=873.5, bsz=873.5, num_updates=1800, lr=0.0001, gnorm=7.087, clip=0, train_wall=8, gb_free=74.7, wall=337 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:02:59]    INFO >> epoch 002:    315 / 1539 loss=5.711, wps=4639.5, ups=7.19, wpb=645.1, bsz=645.1, num_updates=1850, lr=0.0001, gnorm=6.99, clip=0, train_wall=7, gb_free=71.9, wall=344 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:03:06]    INFO >> epoch 002:    365 / 1539 loss=5.724, wps=4745.3, ups=7.24, wpb=655.8, bsz=655.8, num_updates=1900, lr=0.0001, gnorm=7.215, clip=0, train_wall=7, gb_free=74, wall=351 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:03:14]    INFO >> epoch 002:    415 / 1539 loss=5.746, wps=4719.8, ups=6.62, wpb=713.2, bsz=713.2, num_updates=1950, lr=0.0001, gnorm=6.438, clip=0, train_wall=7, gb_free=76.2, wall=359 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:03:14] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacity of 79.14 GiB of which 197.25 MiB is free. Including non-PyTorch memory, this process has 78.92 GiB memory in use. Of the allocated memory 74.93 GiB is allocated by PyTorch, and 3.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:03:14] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 5            |        cudaMalloc retries: 10        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  76327 MiB |  78599 MiB |  61960 GiB |  61886 GiB |
|       from large pool |  76308 MiB |  78581 MiB |  61612 GiB |  61537 GiB |
|       from small pool |     18 MiB |     21 MiB |    348 GiB |    348 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  76327 MiB |  78599 MiB |  61960 GiB |  61886 GiB |
|       from large pool |  76308 MiB |  78581 MiB |  61612 GiB |  61537 GiB |
|       from small pool |     18 MiB |     21 MiB |    348 GiB |    348 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  76304 MiB |  78579 MiB |  61824 GiB |  61750 GiB |
|       from large pool |  76285 MiB |  78562 MiB |  61476 GiB |  61402 GiB |
|       from small pool |     18 MiB |     21 MiB |    348 GiB |    348 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  80308 MiB |  80494 MiB | 311158 MiB | 230850 MiB |
|       from large pool |  80284 MiB |  80284 MiB | 310232 MiB | 229948 MiB |
|       from small pool |     24 MiB |    210 MiB |    926 MiB |    902 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   3980 MiB |   5490 MiB |  61023 GiB |  61019 GiB |
|       from large pool |   3975 MiB |   5484 MiB |  60627 GiB |  60623 GiB |
|       from small pool |      5 MiB |     27 MiB |    395 GiB |    395 GiB |
|---------------------------------------------------------------------------|
| Allocations           |     640    |     646    |    4090 K  |    4090 K  |
|       from large pool |     340    |     346    |    1969 K  |    1969 K  |
|       from small pool |     300    |     355    |    2121 K  |    2120 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     640    |     646    |    4090 K  |    4090 K  |
|       from large pool |     340    |     346    |    1969 K  |    1969 K  |
|       from small pool |     300    |     355    |    2121 K  |    2120 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |      88    |     181    |    1518    |    1430    |
|       from large pool |      76    |      76    |    1055    |     979    |
|       from small pool |      12    |     105    |     463    |     451    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      93    |      99    |    2309 K  |    2309 K  |
|       from large pool |      70    |      76    |    1305 K  |    1305 K  |
|       from small pool |      23    |      51    |    1004 K  |    1004 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:03:14] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:03:14] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:03:14] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:03:14] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:03:23]    INFO >> epoch 002:    466 / 1539 loss=5.724, wps=4643.4, ups=6.37, wpb=729.4, bsz=729.4, num_updates=2000, lr=0.0001, gnorm=6.709, clip=0, train_wall=7, gb_free=71.6, wall=366 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:03:30]    INFO >> epoch 002:    516 / 1539 loss=5.672, wps=4793.4, ups=6.77, wpb=708.4, bsz=708.4, num_updates=2050, lr=0.0001, gnorm=7.624, clip=0, train_wall=7, gb_free=71.2, wall=374 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:03:37]    INFO >> epoch 002:    566 / 1539 loss=5.773, wps=4479.2, ups=7.2, wpb=622.3, bsz=622.3, num_updates=2100, lr=0.0001, gnorm=5.912, clip=0, train_wall=7, gb_free=74, wall=381 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:03:45]    INFO >> epoch 002:    616 / 1539 loss=5.559, wps=5645, ups=6.48, wpb=871.1, bsz=871.1, num_updates=2150, lr=0.0001, gnorm=6.733, clip=0, train_wall=7, gb_free=68.6, wall=389 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:03:54]    INFO >> epoch 002:    666 / 1539 loss=5.6, wps=5094.4, ups=6.59, wpb=772.9, bsz=772.9, num_updates=2200, lr=0.0001, gnorm=7.453, clip=0, train_wall=7, gb_free=68.4, wall=396 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:04:01]    INFO >> epoch 002:    716 / 1539 loss=5.738, wps=5092.8, ups=7.19, wpb=708.6, bsz=708.6, num_updates=2250, lr=0.0001, gnorm=6.249, clip=0, train_wall=7, gb_free=73.1, wall=403 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:04:08]    INFO >> epoch 002:    766 / 1539 loss=5.566, wps=4588.4, ups=6.9, wpb=665.2, bsz=665.2, num_updates=2300, lr=0.0001, gnorm=7.083, clip=0, train_wall=7, gb_free=75.7, wall=410 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:04:15]    INFO >> epoch 002:    816 / 1539 loss=5.707, wps=4597.3, ups=7.01, wpb=656, bsz=656, num_updates=2350, lr=0.0001, gnorm=5.829, clip=0, train_wall=7, gb_free=72.2, wall=417 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:04:23]    INFO >> epoch 002:    866 / 1539 loss=5.635, wps=4763.6, ups=6.62, wpb=719.8, bsz=719.8, num_updates=2400, lr=0.0001, gnorm=6.414, clip=0, train_wall=7, gb_free=75.7, wall=425 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:04:31]    INFO >> epoch 002:    916 / 1539 loss=5.598, wps=4541.6, ups=6.76, wpb=671.5, bsz=671.5, num_updates=2450, lr=0.0001, gnorm=6.756, clip=0, train_wall=7, gb_free=73.1, wall=432 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:04:39]    INFO >> epoch 002:    966 / 1539 loss=5.651, wps=4390, ups=6.88, wpb=637.9, bsz=637.9, num_updates=2500, lr=0.0001, gnorm=6.823, clip=0, train_wall=7, gb_free=69.2, wall=440 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:04:40] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 37.25 MiB is free. Including non-PyTorch memory, this process has 79.08 GiB memory in use. Of the allocated memory 77.54 GiB is allocated by PyTorch, and 1.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:04:40] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 6            |        cudaMalloc retries: 12        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  79337 MiB |  79397 MiB |  78153 GiB |  78075 GiB |
|       from large pool |  78941 MiB |  79001 MiB |  77714 GiB |  77637 GiB |
|       from small pool |    395 MiB |    396 MiB |    438 GiB |    437 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  79337 MiB |  79397 MiB |  78153 GiB |  78075 GiB |
|       from large pool |  78941 MiB |  79001 MiB |  77714 GiB |  77637 GiB |
|       from small pool |    395 MiB |    396 MiB |    438 GiB |    437 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  79098 MiB |  79157 MiB |  77983 GiB |  77905 GiB |
|       from large pool |  78705 MiB |  78764 MiB |  77545 GiB |  77468 GiB |
|       from small pool |    393 MiB |    394 MiB |    437 GiB |    437 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  80468 MiB |  80470 MiB | 335872 MiB | 255404 MiB |
|       from large pool |  80032 MiB |  80032 MiB | 334532 MiB | 254500 MiB |
|       from small pool |    436 MiB |    438 MiB |   1340 MiB |    904 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   1070 MiB |   4610 MiB |  79115 GiB |  79114 GiB |
|       from large pool |   1030 MiB |   4603 MiB |  78616 GiB |  78615 GiB |
|       from small pool |     40 MiB |     41 MiB |    498 GiB |    498 GiB |
|---------------------------------------------------------------------------|
| Allocations           |    7296    |    7299    |    5179 K  |    5172 K  |
|       from large pool |     933    |     934    |    2516 K  |    2515 K  |
|       from small pool |    6363    |    6366    |    2663 K  |    2656 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    7296    |    7299    |    5179 K  |    5172 K  |
|       from large pool |     933    |     934    |    2516 K  |    2515 K  |
|       from small pool |    6363    |    6366    |    2663 K  |    2656 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     690    |     691    |    2130    |    1440    |
|       from large pool |     472    |     472    |    1460    |     988    |
|       from small pool |     218    |     219    |     670    |     452    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     454    |     454    |    2903 K  |    2902 K  |
|       from large pool |      63    |      63    |    1651 K  |    1651 K  |
|       from small pool |     391    |     391    |    1251 K  |    1251 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:04:40] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:04:40] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:04:40] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:04:40] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[33m[2025-11-19 04:04:45] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 1.25 MiB is free. Including non-PyTorch memory, this process has 79.12 GiB memory in use. Of the allocated memory 76.95 GiB is allocated by PyTorch, and 1.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:04:45] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 7            |        cudaMalloc retries: 15        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  78678 MiB |  78798 MiB |  79117 GiB |  79040 GiB |
|       from large pool |  78593 MiB |  78713 MiB |  78673 GiB |  78596 GiB |
|       from small pool |     85 MiB |     86 MiB |    443 GiB |    443 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  78678 MiB |  78798 MiB |  79117 GiB |  79040 GiB |
|       from large pool |  78593 MiB |  78713 MiB |  78673 GiB |  78596 GiB |
|       from small pool |     85 MiB |     86 MiB |    443 GiB |    443 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  78642 MiB |  78762 MiB |  78944 GiB |  78868 GiB |
|       from large pool |  78558 MiB |  78677 MiB |  78501 GiB |  78425 GiB |
|       from small pool |     84 MiB |     85 MiB |    443 GiB |    442 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  80504 MiB |  80504 MiB | 356340 MiB | 275836 MiB |
|       from large pool |  80416 MiB |  80416 MiB | 354934 MiB | 274518 MiB |
|       from small pool |     88 MiB |    436 MiB |   1406 MiB |   1318 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   1705 MiB |   8357 MiB |  79995 GiB |  79994 GiB |
|       from large pool |   1702 MiB |   8349 MiB |  79489 GiB |  79488 GiB |
|       from small pool |      2 MiB |     29 MiB |    505 GiB |    505 GiB |
|---------------------------------------------------------------------------|
| Allocations           |    1873    |    1876    |    5242 K  |    5240 K  |
|       from large pool |     462    |     464    |    2546 K  |    2545 K  |
|       from small pool |    1411    |    1414    |    2696 K  |    2694 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    1873    |    1876    |    5242 K  |    5240 K  |
|       from large pool |     462    |     464    |    2546 K  |    2545 K  |
|       from small pool |    1411    |    1414    |    2696 K  |    2694 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     221    |     689    |    2198    |    1977    |
|       from large pool |     177    |     471    |    1495    |    1318    |
|       from small pool |      44    |     218    |     703    |     659    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     167    |     168    |    2940 K  |    2940 K  |
|       from large pool |     120    |     125    |    1671 K  |    1671 K  |
|       from small pool |      47    |      59    |    1269 K  |    1269 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:04:45] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:04:45] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:04:45] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:04:45] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:04:47]    INFO >> epoch 002:   1018 / 1539 loss=5.598, wps=4054.1, ups=5.89, wpb=687.9, bsz=687.9, num_updates=2550, lr=0.0001, gnorm=6.339, clip=0, train_wall=6, gb_free=72.9, wall=448 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:04:55]    INFO >> epoch 002:   1068 / 1539 loss=5.499, wps=5045, ups=6.61, wpb=763.7, bsz=763.7, num_updates=2600, lr=0.0001, gnorm=7.544, clip=2, train_wall=7, gb_free=73.5, wall=456 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:05:04]    INFO >> epoch 002:   1118 / 1539 loss=5.408, wps=5158.7, ups=6.51, wpb=791.9, bsz=791.9, num_updates=2650, lr=0.0001, gnorm=7.019, clip=2, train_wall=7, gb_free=69.2, wall=463 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:05:11]    INFO >> epoch 002:   1168 / 1539 loss=5.564, wps=5090.4, ups=6.61, wpb=770.1, bsz=770.1, num_updates=2700, lr=0.0001, gnorm=7.015, clip=0, train_wall=7, gb_free=72.3, wall=471 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:05:19]    INFO >> epoch 002:   1218 / 1539 loss=5.595, wps=4713.5, ups=6.64, wpb=710, bsz=710, num_updates=2750, lr=0.0001, gnorm=6.385, clip=0, train_wall=7, gb_free=70.9, wall=479 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:05:22] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 482.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 121.25 MiB is free. Including non-PyTorch memory, this process has 79.00 GiB memory in use. Of the allocated memory 73.46 GiB is allocated by PyTorch, and 5.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:05:22] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 8            |        cudaMalloc retries: 18        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  72821 MiB |  75425 MiB |  86354 GiB |  86283 GiB |
|       from large pool |  72808 MiB |  75412 MiB |  85870 GiB |  85799 GiB |
|       from small pool |     12 MiB |     14 MiB |    483 GiB |    483 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  72821 MiB |  75425 MiB |  86354 GiB |  86283 GiB |
|       from large pool |  72808 MiB |  75412 MiB |  85870 GiB |  85799 GiB |
|       from small pool |     12 MiB |     14 MiB |    483 GiB |    483 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  72801 MiB |  75403 MiB |  86167 GiB |  86096 GiB |
|       from large pool |  72788 MiB |  75391 MiB |  85684 GiB |  85613 GiB |
|       from small pool |     12 MiB |     14 MiB |    483 GiB |    483 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  80384 MiB |  80384 MiB | 387082 MiB | 306698 MiB |
|       from large pool |  80360 MiB |  80360 MiB | 385538 MiB | 305178 MiB |
|       from small pool |     24 MiB |    226 MiB |   1544 MiB |   1520 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   5660 MiB |  11732 MiB |  87437 GiB |  87432 GiB |
|       from large pool |   5649 MiB |  11720 MiB |  86885 GiB |  86880 GiB |
|       from small pool |     11 MiB |     25 MiB |    551 GiB |    551 GiB |
|---------------------------------------------------------------------------|
| Allocations           |     603    |     612    |    5719 K  |    5718 K  |
|       from large pool |     312    |     320    |    2781 K  |    2781 K  |
|       from small pool |     291    |     356    |    2937 K  |    2937 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     603    |     612    |    5719 K  |    5718 K  |
|       from large pool |     312    |     320    |    2781 K  |    2781 K  |
|       from small pool |     291    |     356    |    2937 K  |    2937 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     120    |     229    |    2295    |    2175    |
|       from large pool |     108    |     116    |    1523    |    1415    |
|       from small pool |      12    |     113    |     772    |     760    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     118    |     118    |    3207 K  |    3206 K  |
|       from large pool |      91    |      91    |    1823 K  |    1823 K  |
|       from small pool |      27    |      54    |    1383 K  |    1383 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:05:22] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:05:22] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:05:22] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:05:22] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:05:27]    INFO >> epoch 002:   1269 / 1539 loss=5.545, wps=4815.9, ups=6.29, wpb=765.3, bsz=765.3, num_updates=2800, lr=0.0001, gnorm=6.727, clip=0, train_wall=7, gb_free=70.5, wall=486 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:05:35]    INFO >> epoch 002:   1319 / 1539 loss=5.602, wps=4830.6, ups=7.3, wpb=661.5, bsz=661.5, num_updates=2850, lr=0.0001, gnorm=5.775, clip=0, train_wall=6, gb_free=75, wall=493 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:05:42]    INFO >> epoch 002:   1369 / 1539 loss=5.459, wps=5013.7, ups=6.88, wpb=728.5, bsz=728.5, num_updates=2900, lr=0.0001, gnorm=6.164, clip=2, train_wall=7, gb_free=70.5, wall=501 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:05:49]    INFO >> epoch 002:   1419 / 1539 loss=5.597, wps=4513.1, ups=6.91, wpb=653.6, bsz=653.6, num_updates=2950, lr=0.0001, gnorm=6.103, clip=0, train_wall=7, gb_free=64.8, wall=508 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:05:59]    INFO >> epoch 002:   1469 / 1539 loss=5.473, wps=3758.6, ups=5.35, wpb=702.5, bsz=702.5, num_updates=3000, lr=0.0001, gnorm=6.763, clip=0, train_wall=9, gb_free=70.3, wall=517 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:06:08]    INFO >> epoch 002:   1519 / 1539 loss=5.511, wps=4410.4, ups=6.55, wpb=673.3, bsz=673.3, num_updates=3050, lr=0.0001, gnorm=6.875, clip=0, train_wall=7, gb_free=74.2, wall=525 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:06:11]    INFO >> epoch 002 | loss 5.625 | wps 4500.3 | ups 6.31 | wpb 712.7 | bsz 712.7 | num_updates 3070 | lr 0.0001 | gnorm 6.793 | clip 0.4 | train_wall 214 | gb_free 72.4 | wall 528 (progress_bar.py:267, print())[0m
[33m[2025-11-19 04:06:11] WARNING >> tensorboard or required dependencies not found, please see README for using tensorboard. (e.g. pip install tensorboardX) (progress_bar.py:314, __init__())[0m
[32m[2025-11-19 04:06:24]    INFO >> epoch 002 | valid on 'valid' subset | loss 5.738 | wps 11775.2 | wpb 5412.5 | bsz 5412.5 | num_updates 3070 | best_loss 5.983 (progress_bar.py:267, print())[0m
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
[32m[2025-11-19 04:06:24]    INFO >> è®­ç»ƒæ›²çº¿å·²ä¿å­˜: /home/zhaojunzhang/naturalcc/typilus/experiments/exp_lr_1e-4/logs/plots/training.png (train_enhanced.py:118, plot())[0m
[32m[2025-11-19 04:06:24]    INFO >> saved checkpoint /home/zhaojunzhang/naturalcc/typilus/experiments/exp_lr_1e-4/checkpoints/checkpoint_last.pt (epoch 2 @ 3070 updates, score 5.738) (writing took 0.012309 seconds) (checkpoint_utils.py:78, save_checkpoint())[0m
[33m[2025-11-19 04:06:24] WARNING >> tensorboard or required dependencies not found, please see README for using tensorboard. (e.g. pip install tensorboardX) (progress_bar.py:314, __init__())[0m
[32m[2025-11-19 04:06:28]    INFO >> epoch 003:     30 / 1539 loss=5.5, wps=1658.8, ups=2.44, wpb=681.1, bsz=681.1, num_updates=3100, lr=9.8e-05, gnorm=6.36, clip=0, train_wall=7, gb_free=70.7, wall=545 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:06:36]    INFO >> epoch 003:     80 / 1539 loss=5.566, wps=5293.1, ups=6.85, wpb=772.8, bsz=772.8, num_updates=3150, lr=9.8e-05, gnorm=6.23, clip=0, train_wall=7, gb_free=73.4, wall=553 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:06:40] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacity of 79.14 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 78.04 GiB memory in use. Of the allocated memory 74.93 GiB is allocated by PyTorch, and 2.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:06:40] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 9            |        cudaMalloc retries: 21        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  76326 MiB |  78600 MiB | 102451 GiB | 102377 GiB |
|       from large pool |  76307 MiB |  78583 MiB | 101871 GiB | 101797 GiB |
|       from small pool |     18 MiB |     19 MiB |    580 GiB |    580 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  76326 MiB |  78600 MiB | 102451 GiB | 102377 GiB |
|       from large pool |  76307 MiB |  78583 MiB | 101871 GiB | 101797 GiB |
|       from small pool |     18 MiB |     19 MiB |    580 GiB |    580 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  76304 MiB |  78579 MiB | 102235 GiB | 102160 GiB |
|       from large pool |  76285 MiB |  78562 MiB | 101655 GiB | 101581 GiB |
|       from small pool |     18 MiB |     19 MiB |    579 GiB |    579 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  79400 MiB |  79400 MiB | 483464 MiB | 404064 MiB |
|       from large pool |  79376 MiB |  79376 MiB | 481770 MiB | 402394 MiB |
|       from small pool |     24 MiB |     74 MiB |   1694 MiB |   1670 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   3073 MiB |   4962 MiB | 103113 GiB | 103110 GiB |
|       from large pool |   3068 MiB |   4948 MiB | 102456 GiB | 102453 GiB |
|       from small pool |      5 MiB |     27 MiB |    657 GiB |    657 GiB |
|---------------------------------------------------------------------------|
| Allocations           |     640    |     646    |    6746 K  |    6745 K  |
|       from large pool |     340    |     346    |    3209 K  |    3208 K  |
|       from small pool |     300    |     356    |    3536 K  |    3536 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     640    |     646    |    6746 K  |    6745 K  |
|       from large pool |     340    |     346    |    3209 K  |    3208 K  |
|       from small pool |     300    |     356    |    3536 K  |    3536 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     106    |     118    |    2420    |    2314    |
|       from large pool |      94    |      94    |    1573    |    1479    |
|       from small pool |      12    |      37    |     847    |     835    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     110    |     112    |    3792 K  |    3792 K  |
|       from large pool |      85    |      87    |    2095 K  |    2095 K  |
|       from small pool |      25    |      57    |    1696 K  |    1696 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:06:40] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:06:40] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:06:40] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:06:40] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:06:46]    INFO >> epoch 003:    131 / 1539 loss=5.495, wps=4736.4, ups=5.67, wpb=835, bsz=835, num_updates=3200, lr=9.8e-05, gnorm=6.467, clip=0, train_wall=7, gb_free=71.9, wall=561 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:06:53]    INFO >> epoch 003:    181 / 1539 loss=5.637, wps=4674.5, ups=7.12, wpb=656.8, bsz=656.8, num_updates=3250, lr=9.8e-05, gnorm=5.491, clip=0, train_wall=7, gb_free=73, wall=568 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:06:58] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 1.86 GiB. GPU 0 has a total capacity of 79.14 GiB of which 153.25 MiB is free. Including non-PyTorch memory, this process has 78.97 GiB memory in use. Of the allocated memory 75.67 GiB is allocated by PyTorch, and 2.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:06:58] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 10           |        cudaMalloc retries: 23        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  76958 MiB |  77481 MiB | 105988 GiB | 105913 GiB |
|       from large pool |  76945 MiB |  77468 MiB | 105386 GiB | 105311 GiB |
|       from small pool |     12 MiB |     21 MiB |    601 GiB |    601 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  76958 MiB |  77481 MiB | 105988 GiB | 105913 GiB |
|       from large pool |  76945 MiB |  77468 MiB | 105386 GiB | 105311 GiB |
|       from small pool |     12 MiB |     21 MiB |    601 GiB |    601 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  76936 MiB |  77458 MiB | 105764 GiB | 105689 GiB |
|       from large pool |  76923 MiB |  77445 MiB | 105164 GiB | 105089 GiB |
|       from small pool |     12 MiB |     21 MiB |    600 GiB |    600 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  80352 MiB |  80352 MiB | 489864 MiB | 409512 MiB |
|       from large pool |  80326 MiB |  80326 MiB | 487984 MiB | 407658 MiB |
|       from small pool |     26 MiB |    210 MiB |   1880 MiB |   1854 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   3393 MiB |   8163 MiB | 107067 GiB | 107064 GiB |
|       from large pool |   3380 MiB |   8148 MiB | 106386 GiB | 106383 GiB |
|       from small pool |     13 MiB |     27 MiB |    681 GiB |    681 GiB |
|---------------------------------------------------------------------------|
| Allocations           |     606    |     613    |    6985 K  |    6984 K  |
|       from large pool |     315    |     322    |    3323 K  |    3323 K  |
|       from small pool |     291    |     356    |    3662 K  |    3661 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     606    |     613    |    6985 K  |    6984 K  |
|       from large pool |     315    |     322    |    3323 K  |    3323 K  |
|       from small pool |     291    |     356    |    3662 K  |    3661 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     100    |     199    |    2520    |    2420    |
|       from large pool |      87    |      94    |    1580    |    1493    |
|       from small pool |      13    |     105    |     940    |     927    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      95    |      95    |    3925 K  |    3925 K  |
|       from large pool |      69    |      69    |    2166 K  |    2166 K  |
|       from small pool |      26    |      58    |    1758 K  |    1758 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:06:58] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:06:58] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:06:58] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:06:58] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:07:01]    INFO >> epoch 003:    232 / 1539 loss=5.289, wps=4587.3, ups=5.98, wpb=767.2, bsz=767.2, num_updates=3300, lr=9.8e-05, gnorm=6.678, clip=2, train_wall=7, gb_free=74, wall=577 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:07:09]    INFO >> epoch 003:    282 / 1539 loss=5.522, wps=5084.5, ups=6.76, wpb=751.9, bsz=751.9, num_updates=3350, lr=9.8e-05, gnorm=5.455, clip=0, train_wall=7, gb_free=70.6, wall=584 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:07:18]    INFO >> epoch 003:    332 / 1539 loss=5.323, wps=5046.4, ups=6.38, wpb=790.4, bsz=790.4, num_updates=3400, lr=9.8e-05, gnorm=6.037, clip=0, train_wall=7, gb_free=73.8, wall=592 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:07:26]    INFO >> epoch 003:    382 / 1539 loss=5.473, wps=4341.1, ups=6.31, wpb=688.4, bsz=688.4, num_updates=3450, lr=9.8e-05, gnorm=6.243, clip=0, train_wall=8, gb_free=72.5, wall=600 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:07:33]    INFO >> epoch 003:    432 / 1539 loss=5.414, wps=4477.3, ups=6.81, wpb=657.8, bsz=657.8, num_updates=3500, lr=9.8e-05, gnorm=6.459, clip=0, train_wall=7, gb_free=66.2, wall=607 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:07:41]    INFO >> epoch 003:    482 / 1539 loss=5.43, wps=4906.8, ups=6.51, wpb=754, bsz=754, num_updates=3550, lr=9.8e-05, gnorm=7.178, clip=4, train_wall=7, gb_free=73.1, wall=615 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:07:50]    INFO >> epoch 003:    532 / 1539 loss=5.335, wps=5015.3, ups=6.51, wpb=770.5, bsz=770.5, num_updates=3600, lr=9.8e-05, gnorm=6.539, clip=0, train_wall=7, gb_free=73.8, wall=623 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:07:57]    INFO >> epoch 003:    582 / 1539 loss=5.49, wps=4667.7, ups=6.48, wpb=720.1, bsz=720.1, num_updates=3650, lr=9.8e-05, gnorm=5.669, clip=0, train_wall=7, gb_free=71.6, wall=630 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:08:04]    INFO >> epoch 003:    632 / 1539 loss=5.425, wps=4843.3, ups=7.18, wpb=674.5, bsz=674.5, num_updates=3700, lr=9.8e-05, gnorm=6.373, clip=0, train_wall=7, gb_free=66.5, wall=637 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:08:12]    INFO >> epoch 003:    682 / 1539 loss=5.413, wps=5031.3, ups=6.65, wpb=756.5, bsz=756.5, num_updates=3750, lr=9.8e-05, gnorm=6.474, clip=2, train_wall=7, gb_free=75.1, wall=645 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:08:22]    INFO >> epoch 003:    732 / 1539 loss=5.263, wps=4894.8, ups=6.04, wpb=810.3, bsz=810.3, num_updates=3800, lr=9.8e-05, gnorm=6.548, clip=0, train_wall=8, gb_free=73.9, wall=653 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:08:29]    INFO >> epoch 003:    782 / 1539 loss=5.261, wps=5200.2, ups=6.54, wpb=795, bsz=795, num_updates=3850, lr=9.8e-05, gnorm=7.035, clip=4, train_wall=7, gb_free=73.7, wall=661 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:08:30] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 29.25 MiB is free. Including non-PyTorch memory, this process has 79.09 GiB memory in use. Of the allocated memory 76.96 GiB is allocated by PyTorch, and 1.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:08:30] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 11           |        cudaMalloc retries: 26        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  78744 MiB |  78804 MiB | 123508 GiB | 123431 GiB |
|       from large pool |  78658 MiB |  78718 MiB | 122810 GiB | 122733 GiB |
|       from small pool |     85 MiB |     86 MiB |    698 GiB |    697 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  78744 MiB |  78804 MiB | 123508 GiB | 123431 GiB |
|       from large pool |  78658 MiB |  78718 MiB | 122810 GiB | 122733 GiB |
|       from small pool |     85 MiB |     86 MiB |    698 GiB |    697 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  78703 MiB |  78762 MiB | 123247 GiB | 123170 GiB |
|       from large pool |  78617 MiB |  78677 MiB | 122550 GiB | 122473 GiB |
|       from small pool |     85 MiB |     86 MiB |    697 GiB |    696 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  80476 MiB |  80476 MiB | 517426 MiB | 436950 MiB |
|       from large pool |  80386 MiB |  80386 MiB | 515324 MiB | 434938 MiB |
|       from small pool |     90 MiB |    246 MiB |   2102 MiB |   2012 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   1671 MiB |   7867 MiB | 124794 GiB | 124792 GiB |
|       from large pool |   1667 MiB |   7857 MiB | 124001 GiB | 124000 GiB |
|       from small pool |      4 MiB |     27 MiB |    792 GiB |    792 GiB |
|---------------------------------------------------------------------------|
| Allocations           |    1884    |    1887    |    8145 K  |    8143 K  |
|       from large pool |     463    |     464    |    3900 K  |    3900 K  |
|       from small pool |    1421    |    1424    |    4244 K  |    4243 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    1884    |    1887    |    8145 K  |    8143 K  |
|       from large pool |     463    |     464    |    3900 K  |    3900 K  |
|       from small pool |    1421    |    1424    |    4244 K  |    4243 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     225    |     300    |    2734    |    2509    |
|       from large pool |     180    |     180    |    1683    |    1503    |
|       from small pool |      45    |     123    |    1051    |    1006    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     169    |     169    |    4572 K  |    4572 K  |
|       from large pool |     121    |     124    |    2540 K  |    2540 K  |
|       from small pool |      48    |      51    |    2031 K  |    2031 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:08:30] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:08:30] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:08:30] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:08:30] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:08:37]    INFO >> epoch 003:    833 / 1539 loss=5.241, wps=4707.7, ups=6.4, wpb=736, bsz=736, num_updates=3900, lr=9.8e-05, gnorm=8.253, clip=2, train_wall=7, gb_free=73, wall=669 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:08:44]    INFO >> epoch 003:    883 / 1539 loss=5.466, wps=4796.8, ups=6.69, wpb=717, bsz=717, num_updates=3950, lr=9.8e-05, gnorm=5.975, clip=0, train_wall=7, gb_free=72.5, wall=676 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:08:52]    INFO >> epoch 003:    933 / 1539 loss=5.381, wps=4738.3, ups=6.5, wpb=729.5, bsz=729.5, num_updates=4000, lr=9.8e-05, gnorm=6.16, clip=0, train_wall=7, gb_free=67.3, wall=684 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:09:02]    INFO >> epoch 003:    983 / 1539 loss=5.354, wps=3904.2, ups=5.71, wpb=684.3, bsz=684.3, num_updates=4050, lr=9.8e-05, gnorm=6.04, clip=0, train_wall=8, gb_free=71.5, wall=693 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:09:09]    INFO >> epoch 003:   1033 / 1539 loss=5.291, wps=4441, ups=6.98, wpb=636.3, bsz=636.3, num_updates=4100, lr=9.8e-05, gnorm=5.995, clip=0, train_wall=7, gb_free=68.3, wall=700 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:09:16]    INFO >> epoch 003:   1083 / 1539 loss=5.317, wps=4958.2, ups=7.36, wpb=673.9, bsz=673.9, num_updates=4150, lr=9.8e-05, gnorm=5.754, clip=0, train_wall=6, gb_free=72.9, wall=707 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:09:23] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 39.25 MiB is free. Including non-PyTorch memory, this process has 79.08 GiB memory in use. Of the allocated memory 76.52 GiB is allocated by PyTorch, and 2.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:09:23] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 12           |        cudaMalloc retries: 28        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  78301 MiB |  78361 MiB | 133746 GiB | 133670 GiB |
|       from large pool |  77916 MiB |  77976 MiB | 132993 GiB | 132917 GiB |
|       from small pool |    385 MiB |    386 MiB |    753 GiB |    752 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  78301 MiB |  78361 MiB | 133746 GiB | 133670 GiB |
|       from large pool |  77916 MiB |  77976 MiB | 132993 GiB | 132917 GiB |
|       from small pool |    385 MiB |    386 MiB |    753 GiB |    752 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  78077 MiB |  78137 MiB | 133463 GiB | 133387 GiB |
|       from large pool |  77694 MiB |  77753 MiB | 132711 GiB | 132635 GiB |
|       from small pool |    383 MiB |    384 MiB |    752 GiB |    751 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  80466 MiB |  80504 MiB | 539302 MiB | 458836 MiB |
|       from large pool |  80042 MiB |  80326 MiB | 536864 MiB | 456822 MiB |
|       from small pool |    424 MiB |    426 MiB |   2438 MiB |   2014 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   2104 MiB |   6644 MiB | 134072 GiB | 134070 GiB |
|       from large pool |   2065 MiB |   6637 MiB | 133215 GiB | 133213 GiB |
|       from small pool |     38 MiB |     40 MiB |    856 GiB |    856 GiB |
|---------------------------------------------------------------------------|
| Allocations           |    7109    |    7112    |    8817 K  |    8810 K  |
|       from large pool |     916    |     917    |    4239 K  |    4238 K  |
|       from small pool |    6193    |    6196    |    4578 K  |    4572 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    7109    |    7112    |    8817 K  |    8810 K  |
|       from large pool |     916    |     917    |    4239 K  |    4238 K  |
|       from small pool |    6193    |    6196    |    4578 K  |    4572 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     742    |     743    |    3261    |    2519    |
|       from large pool |     530    |     530    |    2042    |    1512    |
|       from small pool |     212    |     213    |    1219    |    1007    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     510    |     511    |    4950 K  |    4949 K  |
|       from large pool |     132    |     132    |    2765 K  |    2765 K  |
|       from small pool |     378    |     379    |    2185 K  |    2184 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:09:23] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:09:23] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:09:23] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:09:23] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:09:24]    INFO >> epoch 003:   1134 / 1539 loss=5.304, wps=4381.2, ups=6.4, wpb=684.8, bsz=684.8, num_updates=4200, lr=9.8e-05, gnorm=5.941, clip=0, train_wall=6, gb_free=73, wall=714 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:09:33]    INFO >> epoch 003:   1184 / 1539 loss=5.322, wps=4542.5, ups=6.74, wpb=673.6, bsz=673.6, num_updates=4250, lr=9.8e-05, gnorm=5.773, clip=0, train_wall=7, gb_free=73.5, wall=722 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:09:40]    INFO >> epoch 003:   1234 / 1539 loss=5.201, wps=4775.2, ups=6.65, wpb=718.1, bsz=718.1, num_updates=4300, lr=9.8e-05, gnorm=6.14, clip=0, train_wall=7, gb_free=70.5, wall=729 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:09:47]    INFO >> epoch 003:   1284 / 1539 loss=5.305, wps=4512.9, ups=7.28, wpb=619.7, bsz=619.7, num_updates=4350, lr=9.8e-05, gnorm=5.814, clip=0, train_wall=6, gb_free=73.5, wall=736 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:09:54]    INFO >> epoch 003:   1334 / 1539 loss=5.28, wps=5118.5, ups=7.23, wpb=708, bsz=708, num_updates=4400, lr=9.8e-05, gnorm=5.574, clip=0, train_wall=7, gb_free=72.1, wall=743 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:10:02]    INFO >> epoch 003:   1384 / 1539 loss=5.137, wps=4971.6, ups=7.18, wpb=692.7, bsz=692.7, num_updates=4450, lr=9.8e-05, gnorm=6.186, clip=0, train_wall=7, gb_free=74.2, wall=750 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:10:09]    INFO >> epoch 003:   1434 / 1539 loss=5.173, wps=4693.3, ups=7.2, wpb=651.7, bsz=651.7, num_updates=4500, lr=9.8e-05, gnorm=5.689, clip=0, train_wall=7, gb_free=72.1, wall=757 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:10:17]    INFO >> epoch 003:   1484 / 1539 loss=5.213, wps=4404.4, ups=6.68, wpb=658.9, bsz=658.9, num_updates=4550, lr=9.8e-05, gnorm=5.558, clip=0, train_wall=7, gb_free=72.4, wall=764 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:10:24]    INFO >> epoch 003:   1534 / 1539 loss=5.276, wps=4652.5, ups=7.02, wpb=662.9, bsz=662.9, num_updates=4600, lr=9.8e-05, gnorm=5.814, clip=0, train_wall=7, gb_free=72, wall=772 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:10:25]    INFO >> epoch 003 | loss 5.358 | wps 4478.4 | ups 6.28 | wpb 712.7 | bsz 712.7 | num_updates 4605 | lr 9.8e-05 | gnorm 6.169 | clip 0.5 | train_wall 215 | gb_free 74.4 | wall 772 (progress_bar.py:267, print())[0m
[33m[2025-11-19 04:10:25] WARNING >> tensorboard or required dependencies not found, please see README for using tensorboard. (e.g. pip install tensorboardX) (progress_bar.py:314, __init__())[0m
[32m[2025-11-19 04:10:39]    INFO >> epoch 003 | valid on 'valid' subset | loss 5.209 | wps 11764.1 | wpb 5412.5 | bsz 5412.5 | num_updates 4605 | best_loss 5.983 (progress_bar.py:267, print())[0m
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
[32m[2025-11-19 04:10:39]    INFO >> è®­ç»ƒæ›²çº¿å·²ä¿å­˜: /home/zhaojunzhang/naturalcc/typilus/experiments/exp_lr_1e-4/logs/plots/training.png (train_enhanced.py:118, plot())[0m
[32m[2025-11-19 04:10:39]    INFO >> saved checkpoint /home/zhaojunzhang/naturalcc/typilus/experiments/exp_lr_1e-4/checkpoints/checkpoint_last.pt (epoch 3 @ 4605 updates, score 5.209) (writing took 0.013601 seconds) (checkpoint_utils.py:78, save_checkpoint())[0m
[33m[2025-11-19 04:10:39] WARNING >> tensorboard or required dependencies not found, please see README for using tensorboard. (e.g. pip install tensorboardX) (progress_bar.py:314, __init__())[0m
[32m[2025-11-19 04:10:46]    INFO >> epoch 004:     45 / 1539 loss=5.284, wps=1814.5, ups=2.41, wpb=751.7, bsz=751.7, num_updates=4650, lr=9.4e-05, gnorm=5.13, clip=0, train_wall=7, gb_free=72.7, wall=792 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:10:54]    INFO >> epoch 004:     95 / 1539 loss=5.042, wps=5012.7, ups=6.63, wpb=756, bsz=756, num_updates=4700, lr=9.4e-05, gnorm=6.338, clip=0, train_wall=7, gb_free=67.8, wall=800 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:11:03]    INFO >> epoch 004:    145 / 1539 loss=4.858, wps=5422.7, ups=5.17, wpb=1048.6, bsz=1048.6, num_updates=4750, lr=9.4e-05, gnorm=7.233, clip=0, train_wall=9, gb_free=75.1, wall=810 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:11:12]    INFO >> epoch 004:    195 / 1539 loss=5.122, wps=5032.9, ups=7.18, wpb=701.3, bsz=701.3, num_updates=4800, lr=9.4e-05, gnorm=6.282, clip=0, train_wall=7, gb_free=71.9, wall=816 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:11:19]    INFO >> epoch 004:    245 / 1539 loss=5.041, wps=4975.6, ups=6.69, wpb=743.6, bsz=743.6, num_updates=4850, lr=9.4e-05, gnorm=7.005, clip=0, train_wall=7, gb_free=73.5, wall=824 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:11:26]    INFO >> epoch 004:    295 / 1539 loss=5.043, wps=4683.9, ups=7.24, wpb=647.4, bsz=647.4, num_updates=4900, lr=9.4e-05, gnorm=5.943, clip=0, train_wall=7, gb_free=74.6, wall=831 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:11:33]    INFO >> epoch 004:    345 / 1539 loss=4.999, wps=4948.6, ups=7.2, wpb=687.4, bsz=687.4, num_updates=4950, lr=9.4e-05, gnorm=5.572, clip=0, train_wall=7, gb_free=69.9, wall=838 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:11:40]    INFO >> epoch 004:    395 / 1539 loss=4.838, wps=5182, ups=6.81, wpb=761.1, bsz=761.1, num_updates=5000, lr=9.4e-05, gnorm=6.747, clip=0, train_wall=7, gb_free=67.8, wall=845 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:11:50]    INFO >> epoch 004:    445 / 1539 loss=4.931, wps=3957.5, ups=6.28, wpb=630.5, bsz=630.5, num_updates=5050, lr=9.4e-05, gnorm=6.34, clip=0, train_wall=7, gb_free=71.4, wall=853 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:11:57]    INFO >> epoch 004:    495 / 1539 loss=5.009, wps=4955, ups=6.88, wpb=720.1, bsz=720.1, num_updates=5100, lr=9.4e-05, gnorm=5.648, clip=0, train_wall=7, gb_free=74, wall=860 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:12:04]    INFO >> epoch 004:    545 / 1539 loss=4.875, wps=4747.7, ups=6.77, wpb=701.6, bsz=701.6, num_updates=5150, lr=9.4e-05, gnorm=6.246, clip=0, train_wall=7, gb_free=73.5, wall=868 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:12:11]    INFO >> epoch 004:    595 / 1539 loss=4.829, wps=4408.1, ups=7, wpb=629.8, bsz=629.8, num_updates=5200, lr=9.4e-05, gnorm=5.128, clip=0, train_wall=7, gb_free=71, wall=875 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:12:12] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 13.25 MiB is free. Including non-PyTorch memory, this process has 79.10 GiB memory in use. Of the allocated memory 77.38 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:12:12] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 13           |        cudaMalloc retries: 30        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  79173 MiB |  79233 MiB | 167559 GiB | 167482 GiB |
|       from large pool |  79083 MiB |  79143 MiB | 166611 GiB | 166534 GiB |
|       from small pool |     89 MiB |     91 MiB |    948 GiB |    948 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  79173 MiB |  79233 MiB | 167559 GiB | 167482 GiB |
|       from large pool |  79083 MiB |  79143 MiB | 166611 GiB | 166534 GiB |
|       from small pool |     89 MiB |     91 MiB |    948 GiB |    948 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  79123 MiB |  79183 MiB | 167207 GiB | 167130 GiB |
|       from large pool |  79034 MiB |  79093 MiB | 166260 GiB | 166183 GiB |
|       from small pool |     89 MiB |     90 MiB |    946 GiB |    946 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  80492 MiB |  80492 MiB | 564646 MiB | 484154 MiB |
|       from large pool |  80398 MiB |  80398 MiB | 562140 MiB | 481742 MiB |
|       from small pool |     94 MiB |     94 MiB |   2506 MiB |   2412 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   1258 MiB |   7162 MiB | 164246 GiB | 164244 GiB |
|       from large pool |   1254 MiB |   7152 MiB | 163171 GiB | 163170 GiB |
|       from small pool |      4 MiB |     27 MiB |   1074 GiB |   1074 GiB |
|---------------------------------------------------------------------------|
| Allocations           |    1961    |    1964    |   11044 K  |   11042 K  |
|       from large pool |     470    |     471    |    5271 K  |    5271 K  |
|       from small pool |    1491    |    1494    |    5772 K  |    5770 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    1961    |    1964    |   11044 K  |   11042 K  |
|       from large pool |     470    |     471    |    5271 K  |    5271 K  |
|       from small pool |    1491    |    1494    |    5772 K  |    5770 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     223    |     223    |    3348    |    3125    |
|       from large pool |     176    |     176    |    2095    |    1919    |
|       from small pool |      47    |      47    |    1253    |    1206    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     140    |     140    |    6216 K  |    6216 K  |
|       from large pool |      92    |      96    |    3444 K  |    3444 K  |
|       from small pool |      48    |      58    |    2772 K  |    2772 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:12:12] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:12:12] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:12:12] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:12:12] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:12:20]    INFO >> epoch 004:    646 / 1539 loss=4.725, wps=4468.6, ups=6.66, wpb=671.1, bsz=671.1, num_updates=5250, lr=9.4e-05, gnorm=6.7, clip=0, train_wall=6, gb_free=68.7, wall=882 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:12:28] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacity of 79.14 GiB of which 983.25 MiB is free. Including non-PyTorch memory, this process has 78.16 GiB memory in use. Of the allocated memory 74.92 GiB is allocated by PyTorch, and 2.73 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:12:28] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 14           |        cudaMalloc retries: 32        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  76323 MiB |  78596 MiB | 170178 GiB | 170104 GiB |
|       from large pool |  76304 MiB |  78579 MiB | 169217 GiB | 169142 GiB |
|       from small pool |     18 MiB |     24 MiB |    961 GiB |    961 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  76323 MiB |  78596 MiB | 170178 GiB | 170104 GiB |
|       from large pool |  76304 MiB |  78579 MiB | 169217 GiB | 169142 GiB |
|       from small pool |     18 MiB |     24 MiB |    961 GiB |    961 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  76304 MiB |  78579 MiB | 169821 GiB | 169746 GiB |
|       from large pool |  76285 MiB |  78562 MiB | 168861 GiB | 168786 GiB |
|       from small pool |     18 MiB |     24 MiB |    960 GiB |    959 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  79522 MiB |  80432 MiB | 637044 MiB | 557522 MiB |
|       from large pool |  79496 MiB |  80338 MiB | 634538 MiB | 555042 MiB |
|       from small pool |     26 MiB |     94 MiB |   2506 MiB |   2480 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   3198 MiB |   4143 MiB | 166742 GiB | 166738 GiB |
|       from large pool |   3191 MiB |   4135 MiB | 165652 GiB | 165649 GiB |
|       from small pool |      7 MiB |     23 MiB |   1089 GiB |   1089 GiB |
|---------------------------------------------------------------------------|
| Allocations           |     640    |     646    |   11213 K  |   11212 K  |
|       from large pool |     340    |     346    |    5361 K  |    5361 K  |
|       from small pool |     300    |     356    |    5852 K  |    5851 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     640    |     646    |   11213 K  |   11212 K  |
|       from large pool |     340    |     346    |    5361 K  |    5361 K  |
|       from small pool |     300    |     356    |    5852 K  |    5851 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     107    |     222    |    3403    |    3296    |
|       from large pool |      94    |     175    |    2150    |    2056    |
|       from small pool |      13    |      47    |    1253    |    1240    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     126    |     128    |    6309 K  |    6309 K  |
|       from large pool |      98    |     100    |    3503 K  |    3503 K  |
|       from small pool |      28    |      51    |    2805 K  |    2805 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:12:28] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:12:28] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:12:28] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:12:28] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:12:29]    INFO >> epoch 004:    697 / 1539 loss=4.75, wps=3441.4, ups=5.41, wpb=636.6, bsz=636.6, num_updates=5300, lr=9.4e-05, gnorm=5.899, clip=0, train_wall=7, gb_free=67.8, wall=892 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:12:38]    INFO >> epoch 004:    747 / 1539 loss=4.791, wps=4089.9, ups=6.08, wpb=673.1, bsz=673.1, num_updates=5350, lr=9.4e-05, gnorm=5.734, clip=0, train_wall=8, gb_free=72.9, wall=900 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:12:45]    INFO >> epoch 004:    797 / 1539 loss=4.776, wps=4926, ups=6.94, wpb=710.1, bsz=710.1, num_updates=5400, lr=9.4e-05, gnorm=5.357, clip=0, train_wall=7, gb_free=72.3, wall=907 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:12:54]    INFO >> epoch 004:    847 / 1539 loss=4.527, wps=5030.1, ups=6.73, wpb=747.5, bsz=747.5, num_updates=5450, lr=9.4e-05, gnorm=7.188, clip=0, train_wall=7, gb_free=63.6, wall=915 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:13:01]    INFO >> epoch 004:    897 / 1539 loss=4.656, wps=5038.3, ups=6.47, wpb=778.3, bsz=778.3, num_updates=5500, lr=9.4e-05, gnorm=6.844, clip=0, train_wall=7, gb_free=70.2, wall=922 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:13:08]    INFO >> epoch 004:    947 / 1539 loss=4.547, wps=4614.4, ups=7.14, wpb=646.7, bsz=646.7, num_updates=5550, lr=9.4e-05, gnorm=5.958, clip=0, train_wall=7, gb_free=67.5, wall=929 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:13:16]    INFO >> epoch 004:    997 / 1539 loss=4.631, wps=4900.7, ups=6.41, wpb=764.9, bsz=764.9, num_updates=5600, lr=9.4e-05, gnorm=5.794, clip=0, train_wall=7, gb_free=75.5, wall=937 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:13:25]    INFO >> epoch 004:   1047 / 1539 loss=4.557, wps=4458.1, ups=7.09, wpb=628.6, bsz=628.6, num_updates=5650, lr=9.4e-05, gnorm=5.971, clip=0, train_wall=7, gb_free=72.5, wall=944 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:13:32]    INFO >> epoch 004:   1097 / 1539 loss=4.731, wps=5014.7, ups=6.87, wpb=729.6, bsz=729.6, num_updates=5700, lr=9.4e-05, gnorm=5.166, clip=0, train_wall=7, gb_free=71.1, wall=951 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:13:39]    INFO >> epoch 004:   1147 / 1539 loss=4.519, wps=4663.2, ups=6.89, wpb=676.4, bsz=676.4, num_updates=5750, lr=9.4e-05, gnorm=6.842, clip=0, train_wall=7, gb_free=56.5, wall=959 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:13:47]    INFO >> epoch 004:   1197 / 1539 loss=4.534, wps=5048.8, ups=6.69, wpb=754.7, bsz=754.7, num_updates=5800, lr=9.4e-05, gnorm=6.595, clip=0, train_wall=7, gb_free=75.6, wall=966 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:13:53]    INFO >> epoch 004:   1247 / 1539 loss=4.483, wps=4573.8, ups=7.29, wpb=627.8, bsz=627.8, num_updates=5850, lr=9.4e-05, gnorm=5.804, clip=0, train_wall=6, gb_free=75.6, wall=973 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:14:02]    INFO >> epoch 004:   1297 / 1539 loss=4.498, wps=4231, ups=6.56, wpb=644.6, bsz=644.6, num_updates=5900, lr=9.4e-05, gnorm=6.692, clip=2, train_wall=7, gb_free=74.6, wall=981 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:14:10]    INFO >> epoch 004:   1347 / 1539 loss=4.538, wps=5355.1, ups=6.69, wpb=801.1, bsz=801.1, num_updates=5950, lr=9.4e-05, gnorm=6.692, clip=0, train_wall=7, gb_free=66.8, wall=988 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:14:17] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 1.86 GiB. GPU 0 has a total capacity of 79.14 GiB of which 1.83 GiB is free. Including non-PyTorch memory, this process has 77.29 GiB memory in use. Of the allocated memory 73.80 GiB is allocated by PyTorch, and 2.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:14:17] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 15           |        cudaMalloc retries: 34        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  75053 MiB |  75996 MiB | 190873 GiB | 190800 GiB |
|       from large pool |  75040 MiB |  75983 MiB | 189802 GiB | 189729 GiB |
|       from small pool |     12 MiB |     13 MiB |   1070 GiB |   1070 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  75053 MiB |  75996 MiB | 190873 GiB | 190800 GiB |
|       from large pool |  75040 MiB |  75983 MiB | 189802 GiB | 189729 GiB |
|       from small pool |     12 MiB |     13 MiB |   1070 GiB |   1070 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  75035 MiB |  75977 MiB | 190472 GiB | 190399 GiB |
|       from large pool |  75022 MiB |  75964 MiB | 189403 GiB | 189330 GiB |
|       from small pool |     12 MiB |     13 MiB |   1069 GiB |   1069 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  78634 MiB |  79742 MiB | 645400 MiB | 566766 MiB |
|       from large pool |  78608 MiB |  79496 MiB | 642674 MiB | 564066 MiB |
|       from small pool |     26 MiB |    246 MiB |   2726 MiB |   2700 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   3580 MiB |   7454 MiB | 189481 GiB | 189477 GiB |
|       from large pool |   3567 MiB |   7440 MiB | 188266 GiB | 188263 GiB |
|       from small pool |     13 MiB |     21 MiB |   1214 GiB |   1214 GiB |
|---------------------------------------------------------------------------|
| Allocations           |     605    |     613    |   12564 K  |   12563 K  |
|       from large pool |     314    |     322    |    6052 K  |    6052 K  |
|       from small pool |     291    |     336    |    6511 K  |    6510 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     605    |     613    |   12564 K  |   12563 K  |
|       from large pool |     314    |     322    |    6052 K  |    6052 K  |
|       from small pool |     291    |     336    |    6511 K  |    6510 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |      91    |     217    |    3521    |    3430    |
|       from large pool |      78    |      94    |    2158    |    2080    |
|       from small pool |      13    |     123    |    1363    |    1350    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      89    |      90    |    7038 K  |    7038 K  |
|       from large pool |      60    |      61    |    3937 K  |    3937 K  |
|       from small pool |      29    |      51    |    3100 K  |    3100 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:14:17] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:14:17] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:14:17] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:14:17] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:14:18]    INFO >> epoch 004:   1398 / 1539 loss=4.461, wps=4742.2, ups=5.99, wpb=791.5, bsz=791.5, num_updates=6000, lr=9.4e-05, gnorm=7.477, clip=2, train_wall=7, gb_free=71.6, wall=996 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:14:25]    INFO >> epoch 004:   1448 / 1539 loss=4.384, wps=4935.9, ups=6.93, wpb=711.7, bsz=711.7, num_updates=6050, lr=9.4e-05, gnorm=7.326, clip=0, train_wall=7, gb_free=73.5, wall=1004 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:14:34]    INFO >> epoch 004:   1498 / 1539 loss=4.397, wps=4738.7, ups=6.95, wpb=682, bsz=682, num_updates=6100, lr=9.4e-05, gnorm=7.215, clip=2, train_wall=7, gb_free=74.2, wall=1011 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:14:36] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 25.25 MiB is free. Including non-PyTorch memory, this process has 79.09 GiB memory in use. Of the allocated memory 77.10 GiB is allocated by PyTorch, and 1.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:14:36] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 16           |        cudaMalloc retries: 35        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  78888 MiB |  78948 MiB | 194338 GiB | 194261 GiB |
|       from large pool |  78495 MiB |  78555 MiB | 193245 GiB | 193169 GiB |
|       from small pool |    393 MiB |    394 MiB |   1092 GiB |   1092 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  78888 MiB |  78948 MiB | 194338 GiB | 194261 GiB |
|       from large pool |  78495 MiB |  78555 MiB | 193245 GiB | 193169 GiB |
|       from small pool |    393 MiB |    394 MiB |   1092 GiB |   1092 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  78858 MiB |  78917 MiB | 193930 GiB | 193853 GiB |
|       from large pool |  78467 MiB |  78526 MiB | 192839 GiB | 192762 GiB |
|       from small pool |    390 MiB |    392 MiB |   1090 GiB |   1090 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  80480 MiB |  80482 MiB | 647248 MiB | 566768 MiB |
|       from large pool |  80048 MiB |  80048 MiB | 644114 MiB | 564066 MiB |
|       from small pool |    432 MiB |    434 MiB |   3134 MiB |   2702 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   1531 MiB |   4145 MiB | 193506 GiB | 193504 GiB |
|       from large pool |   1492 MiB |   4108 MiB | 192266 GiB | 192265 GiB |
|       from small pool |     38 MiB |     41 MiB |   1239 GiB |   1239 GiB |
|---------------------------------------------------------------------------|
| Allocations           |    7252    |    7255    |   12813 K  |   12806 K  |
|       from large pool |     929    |     930    |    6169 K  |    6168 K  |
|       from small pool |    6323    |    6326    |    6643 K  |    6637 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    7252    |    7255    |   12813 K  |   12806 K  |
|       from large pool |     929    |     930    |    6169 K  |    6168 K  |
|       from small pool |    6323    |    6326    |    6643 K  |    6637 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     318    |     319    |    3749    |    3431    |
|       from large pool |     102    |     102    |    2182    |    2080    |
|       from small pool |     216    |     217    |    1567    |    1351    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     462    |     464    |    7175 K  |    7174 K  |
|       from large pool |      77    |      77    |    4009 K  |    4009 K  |
|       from small pool |     385    |     387    |    3165 K  |    3165 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:14:36] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:14:36] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:14:36] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:14:36] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:14:40]    INFO >> epoch 004 | loss 4.74 | wps 4469.5 | ups 6.27 | wpb 712.7 | bsz 712.7 | num_updates 6140 | lr 9.4e-05 | gnorm 6.298 | clip 0.2 | train_wall 214 | gb_free 70.1 | wall 1017 (progress_bar.py:267, print())[0m
[33m[2025-11-19 04:14:40] WARNING >> tensorboard or required dependencies not found, please see README for using tensorboard. (e.g. pip install tensorboardX) (progress_bar.py:314, __init__())[0m
[32m[2025-11-19 04:14:53]    INFO >> epoch 004 | valid on 'valid' subset | loss 4.376 | wps 11862.3 | wpb 5412.5 | bsz 5412.5 | num_updates 6140 | best_loss 5.983 (progress_bar.py:267, print())[0m
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
[32m[2025-11-19 04:14:53]    INFO >> è®­ç»ƒæ›²çº¿å·²ä¿å­˜: /home/zhaojunzhang/naturalcc/typilus/experiments/exp_lr_1e-4/logs/plots/training.png (train_enhanced.py:118, plot())[0m
[32m[2025-11-19 04:14:53]    INFO >> saved checkpoint /home/zhaojunzhang/naturalcc/typilus/experiments/exp_lr_1e-4/checkpoints/checkpoint_last.pt (epoch 4 @ 6140 updates, score 4.376) (writing took 0.012599 seconds) (checkpoint_utils.py:78, save_checkpoint())[0m
[33m[2025-11-19 04:14:53] WARNING >> tensorboard or required dependencies not found, please see README for using tensorboard. (e.g. pip install tensorboardX) (progress_bar.py:314, __init__())[0m
[32m[2025-11-19 04:14:55]    INFO >> epoch 005:     10 / 1539 loss=4.476, wps=1556.8, ups=2.42, wpb=643.2, bsz=643.2, num_updates=6150, lr=8.9e-05, gnorm=6.194, clip=0, train_wall=7, gb_free=72.1, wall=1031 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:15:02]    INFO >> epoch 005:     60 / 1539 loss=4.387, wps=4544.7, ups=6.45, wpb=704.5, bsz=704.5, num_updates=6200, lr=8.9e-05, gnorm=6.723, clip=0, train_wall=7, gb_free=73.4, wall=1039 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:15:11]    INFO >> epoch 005:    110 / 1539 loss=4.442, wps=4957.7, ups=7.03, wpb=705.4, bsz=705.4, num_updates=6250, lr=8.9e-05, gnorm=6.668, clip=0, train_wall=7, gb_free=71.5, wall=1046 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:15:18]    INFO >> epoch 005:    160 / 1539 loss=4.477, wps=4613.7, ups=7.21, wpb=639.6, bsz=639.6, num_updates=6300, lr=8.9e-05, gnorm=5.971, clip=0, train_wall=7, gb_free=74, wall=1053 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:15:25]    INFO >> epoch 005:    210 / 1539 loss=4.457, wps=4637.1, ups=6.9, wpb=671.6, bsz=671.6, num_updates=6350, lr=8.9e-05, gnorm=5.865, clip=0, train_wall=7, gb_free=71, wall=1061 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:15:33]    INFO >> epoch 005:    260 / 1539 loss=4.571, wps=5445.9, ups=6.08, wpb=895.2, bsz=895.2, num_updates=6400, lr=8.9e-05, gnorm=6.293, clip=0, train_wall=8, gb_free=67.8, wall=1069 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:15:42]    INFO >> epoch 005:    310 / 1539 loss=4.349, wps=4857, ups=6.89, wpb=704.8, bsz=704.8, num_updates=6450, lr=8.9e-05, gnorm=6.84, clip=0, train_wall=7, gb_free=71.8, wall=1076 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:15:49]    INFO >> epoch 005:    360 / 1539 loss=4.212, wps=5147.1, ups=6.66, wpb=772.8, bsz=772.8, num_updates=6500, lr=8.9e-05, gnorm=6.872, clip=2, train_wall=7, gb_free=69.5, wall=1084 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:15:56] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 27.25 MiB is free. Including non-PyTorch memory, this process has 79.09 GiB memory in use. Of the allocated memory 76.85 GiB is allocated by PyTorch, and 1.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:15:56] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 17           |        cudaMalloc retries: 36        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  78634 MiB |  78694 MiB | 211161 GiB | 211084 GiB |
|       from large pool |  78243 MiB |  78303 MiB | 209958 GiB | 209881 GiB |
|       from small pool |    390 MiB |    391 MiB |   1202 GiB |   1202 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  78634 MiB |  78694 MiB | 211161 GiB | 211084 GiB |
|       from large pool |  78243 MiB |  78303 MiB | 209958 GiB | 209881 GiB |
|       from small pool |    390 MiB |    391 MiB |   1202 GiB |   1202 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  78618 MiB |  78677 MiB | 210720 GiB | 210643 GiB |
|       from large pool |  78229 MiB |  78288 MiB | 209518 GiB | 209442 GiB |
|       from small pool |    388 MiB |    389 MiB |   1201 GiB |   1200 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  80478 MiB |  80480 MiB | 647308 MiB | 566830 MiB |
|       from large pool |  80048 MiB |  80048 MiB | 644174 MiB | 564126 MiB |
|       from small pool |    430 MiB |    432 MiB |   3134 MiB |   2704 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   1783 MiB |   5192 MiB | 209175 GiB | 209173 GiB |
|       from large pool |   1744 MiB |   5187 MiB | 207813 GiB | 207811 GiB |
|       from small pool |     39 MiB |     41 MiB |   1361 GiB |   1361 GiB |
|---------------------------------------------------------------------------|
| Allocations           |    7208    |    7211    |   13967 K  |   13960 K  |
|       from large pool |     925    |     926    |    6636 K  |    6635 K  |
|       from small pool |    6283    |    6286    |    7330 K  |    7324 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    7208    |    7211    |   13967 K  |   13960 K  |
|       from large pool |     925    |     926    |    6636 K  |    6635 K  |
|       from small pool |    6283    |    6286    |    7330 K  |    7324 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     317    |     318    |    3750    |    3433    |
|       from large pool |     102    |     102    |    2183    |    2081    |
|       from small pool |     215    |     216    |    1567    |    1352    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     476    |     477    |    7847 K  |    7846 K  |
|       from large pool |      90    |      90    |    4312 K  |    4312 K  |
|       from small pool |     386    |     387    |    3534 K  |    3534 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:15:56] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:15:56] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:15:56] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:15:56] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:15:57]    INFO >> epoch 005:    411 / 1539 loss=4.44, wps=4502.5, ups=6.61, wpb=681.6, bsz=681.6, num_updates=6550, lr=8.9e-05, gnorm=6.263, clip=0, train_wall=7, gb_free=73.9, wall=1091 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:16:04]    INFO >> epoch 005:    461 / 1539 loss=4.279, wps=4370.1, ups=7.19, wpb=608, bsz=608, num_updates=6600, lr=8.9e-05, gnorm=6.116, clip=0, train_wall=7, gb_free=74.7, wall=1098 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:16:17]    INFO >> epoch 005:    511 / 1539 loss=4.383, wps=3094.6, ups=4.24, wpb=730.5, bsz=730.5, num_updates=6650, lr=8.9e-05, gnorm=5.736, clip=0, train_wall=11, gb_free=69.8, wall=1110 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:16:24]    INFO >> epoch 005:    561 / 1539 loss=4.421, wps=4363.3, ups=7.03, wpb=620.7, bsz=620.7, num_updates=6700, lr=8.9e-05, gnorm=6.423, clip=0, train_wall=7, gb_free=72.5, wall=1117 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:16:29] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 3.25 MiB is free. Including non-PyTorch memory, this process has 79.11 GiB memory in use. Of the allocated memory 77.48 GiB is allocated by PyTorch, and 1.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:16:29] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 18           |        cudaMalloc retries: 38        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  79276 MiB |  79336 MiB | 216573 GiB | 216496 GiB |
|       from large pool |  79185 MiB |  79245 MiB | 215342 GiB | 215265 GiB |
|       from small pool |     91 MiB |     92 MiB |   1230 GiB |   1230 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  79276 MiB |  79336 MiB | 216573 GiB | 216496 GiB |
|       from large pool |  79185 MiB |  79245 MiB | 215342 GiB | 215265 GiB |
|       from small pool |     91 MiB |     92 MiB |   1230 GiB |   1230 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  79244 MiB |  79303 MiB | 216121 GiB | 216043 GiB |
|       from large pool |  79153 MiB |  79212 MiB | 214892 GiB | 214815 GiB |
|       from small pool |     90 MiB |     92 MiB |   1228 GiB |   1228 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  80502 MiB |  80504 MiB | 647732 MiB | 567230 MiB |
|       from large pool |  80408 MiB |  80408 MiB | 644594 MiB | 564186 MiB |
|       from small pool |     94 MiB |    430 MiB |   3138 MiB |   3044 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   1165 MiB |   6539 MiB | 214885 GiB | 214884 GiB |
|       from large pool |   1162 MiB |   6529 MiB | 213491 GiB | 213490 GiB |
|       from small pool |      2 MiB |     25 MiB |   1393 GiB |   1393 GiB |
|---------------------------------------------------------------------------|
| Allocations           |    1983    |    1986    |   14316 K  |   14314 K  |
|       from large pool |     472    |     473    |    6818 K  |    6818 K  |
|       from small pool |    1511    |    1514    |    7497 K  |    7496 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    1983    |    1986    |   14316 K  |   14314 K  |
|       from large pool |     472    |     473    |    6818 K  |    6818 K  |
|       from small pool |    1511    |    1514    |    7497 K  |    7496 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     155    |     317    |    3759    |    3604    |
|       from large pool |     108    |     108    |    2190    |    2082    |
|       from small pool |      47    |     215    |    1569    |    1522    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     138    |     140    |    8036 K  |    8036 K  |
|       from large pool |      88    |      91    |    4428 K  |    4428 K  |
|       from small pool |      50    |      58    |    3608 K  |    3608 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:16:29] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:16:29] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:16:29] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:16:29] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:16:32]    INFO >> epoch 005:    612 / 1539 loss=4.217, wps=4671, ups=6.18, wpb=756, bsz=756, num_updates=6750, lr=8.9e-05, gnorm=7.545, clip=0, train_wall=7, gb_free=70.1, wall=1125 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:16:40]    INFO >> epoch 005:    662 / 1539 loss=4.38, wps=4878.1, ups=6.62, wpb=736.8, bsz=736.8, num_updates=6800, lr=8.9e-05, gnorm=6.741, clip=0, train_wall=7, gb_free=74.2, wall=1133 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:16:49]    INFO >> epoch 005:    712 / 1539 loss=4.463, wps=4899.9, ups=6.72, wpb=729, bsz=729, num_updates=6850, lr=8.9e-05, gnorm=6.839, clip=0, train_wall=7, gb_free=71.4, wall=1140 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:16:56]    INFO >> epoch 005:    762 / 1539 loss=4.39, wps=4998.4, ups=6.97, wpb=717.1, bsz=717.1, num_updates=6900, lr=8.9e-05, gnorm=6.425, clip=2, train_wall=7, gb_free=72.9, wall=1147 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:17:04]    INFO >> epoch 005:    812 / 1539 loss=4.441, wps=4183.7, ups=6.21, wpb=673.7, bsz=673.7, num_updates=6950, lr=8.9e-05, gnorm=6.058, clip=0, train_wall=8, gb_free=69.7, wall=1155 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:17:11]    INFO >> epoch 005:    862 / 1539 loss=4.275, wps=4755.5, ups=7.09, wpb=670.9, bsz=670.9, num_updates=7000, lr=8.9e-05, gnorm=6.399, clip=0, train_wall=7, gb_free=66.5, wall=1162 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:17:20]    INFO >> epoch 005:    912 / 1539 loss=4.362, wps=4549.6, ups=6.82, wpb=667, bsz=667, num_updates=7050, lr=8.9e-05, gnorm=6.221, clip=0, train_wall=7, gb_free=71.7, wall=1170 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:17:26] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacity of 79.14 GiB of which 131.25 MiB is free. Including non-PyTorch memory, this process has 78.99 GiB memory in use. Of the allocated memory 74.93 GiB is allocated by PyTorch, and 3.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:17:26] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 19           |        cudaMalloc retries: 39        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  76325 MiB |  78599 MiB | 227233 GiB | 227158 GiB |
|       from large pool |  76306 MiB |  78582 MiB | 225947 GiB | 225873 GiB |
|       from small pool |     18 MiB |     24 MiB |   1285 GiB |   1285 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  76325 MiB |  78599 MiB | 227233 GiB | 227158 GiB |
|       from large pool |  76306 MiB |  78582 MiB | 225947 GiB | 225873 GiB |
|       from small pool |     18 MiB |     24 MiB |   1285 GiB |   1285 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  76304 MiB |  78579 MiB | 226757 GiB | 226683 GiB |
|       from large pool |  76285 MiB |  78562 MiB | 225474 GiB | 225399 GiB |
|       from small pool |     18 MiB |     24 MiB |   1283 GiB |   1283 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  80374 MiB |  80442 MiB | 647732 MiB | 567358 MiB |
|       from large pool |  80348 MiB |  80348 MiB | 644594 MiB | 564246 MiB |
|       from small pool |     26 MiB |     94 MiB |   3138 MiB |   3112 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   4048 MiB |   5924 MiB | 225934 GiB | 225930 GiB |
|       from large pool |   4041 MiB |   5910 MiB | 224478 GiB | 224474 GiB |
|       from small pool |      7 MiB |     23 MiB |   1455 GiB |   1455 GiB |
|---------------------------------------------------------------------------|
| Allocations           |     640    |     646    |   14999 K  |   14999 K  |
|       from large pool |     340    |     346    |    7173 K  |    7173 K  |
|       from small pool |     300    |     356    |    7826 K  |    7825 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     640    |     646    |   14999 K  |   14999 K  |
|       from large pool |     340    |     346    |    7173 K  |    7173 K  |
|       from small pool |     300    |     356    |    7826 K  |    7825 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     120    |     154    |    3759    |    3639    |
|       from large pool |     107    |     107    |    2190    |    2083    |
|       from small pool |      13    |      47    |    1569    |    1556    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     111    |     113    |    8408 K  |    8408 K  |
|       from large pool |      84    |      86    |    4655 K  |    4655 K  |
|       from small pool |      27    |      48    |    3752 K  |    3752 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:17:26] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:17:26] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:17:26] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:17:26] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:17:27]    INFO >> epoch 005:    963 / 1539 loss=4.369, wps=4318.2, ups=6.38, wpb=676.6, bsz=676.6, num_updates=7100, lr=8.9e-05, gnorm=6.176, clip=0, train_wall=7, gb_free=70.4, wall=1177 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:17:36]    INFO >> epoch 005:   1013 / 1539 loss=4.181, wps=5495.7, ups=5.76, wpb=954.2, bsz=954.2, num_updates=7150, lr=8.9e-05, gnorm=6.997, clip=2, train_wall=8, gb_free=70.3, wall=1186 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:17:44]    INFO >> epoch 005:   1063 / 1539 loss=4.137, wps=4908.8, ups=6.21, wpb=791.1, bsz=791.1, num_updates=7200, lr=8.9e-05, gnorm=7.356, clip=2, train_wall=8, gb_free=64.7, wall=1194 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:17:53]    INFO >> epoch 005:   1113 / 1539 loss=4.233, wps=4416.2, ups=7.05, wpb=626.1, bsz=626.1, num_updates=7250, lr=8.9e-05, gnorm=6.294, clip=0, train_wall=7, gb_free=74.2, wall=1201 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:17:55] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 482.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 199.25 MiB is free. Including non-PyTorch memory, this process has 78.92 GiB memory in use. Of the allocated memory 73.46 GiB is allocated by PyTorch, and 4.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:17:55] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 20           |        cudaMalloc retries: 43        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  72823 MiB |  75427 MiB | 232756 GiB | 232684 GiB |
|       from large pool |  72810 MiB |  75414 MiB | 231439 GiB | 231368 GiB |
|       from small pool |     12 MiB |     21 MiB |   1316 GiB |   1316 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  72823 MiB |  75427 MiB | 232756 GiB | 232684 GiB |
|       from large pool |  72810 MiB |  75414 MiB | 231439 GiB | 231368 GiB |
|       from small pool |     12 MiB |     21 MiB |   1316 GiB |   1316 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  72801 MiB |  75403 MiB | 232269 GiB | 232198 GiB |
|       from large pool |  72788 MiB |  75391 MiB | 230954 GiB | 230883 GiB |
|       from small pool |     12 MiB |     21 MiB |   1314 GiB |   1314 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  80306 MiB |  80306 MiB | 688498 MiB | 608192 MiB |
|       from large pool |  80280 MiB |  80280 MiB | 685160 MiB | 604880 MiB |
|       from small pool |     26 MiB |    226 MiB |   3338 MiB |   3312 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   5580 MiB |   9572 MiB | 230920 GiB | 230915 GiB |
|       from large pool |   5567 MiB |   9557 MiB | 229429 GiB | 229423 GiB |
|       from small pool |     13 MiB |     31 MiB |   1491 GiB |   1491 GiB |
|---------------------------------------------------------------------------|
| Allocations           |     603    |     612    |   15362 K  |   15361 K  |
|       from large pool |     312    |     320    |    7349 K  |    7348 K  |
|       from small pool |     291    |     356    |    8012 K  |    8012 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     603    |     612    |   15362 K  |   15361 K  |
|       from large pool |     312    |     320    |    7349 K  |    7348 K  |
|       from small pool |     291    |     356    |    8012 K  |    8012 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     170    |     327    |    3991    |    3821    |
|       from large pool |     157    |     214    |    2322    |    2165    |
|       from small pool |      13    |     113    |    1669    |    1656    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     159    |     161    |    8616 K  |    8616 K  |
|       from large pool |     133    |     135    |    4773 K  |    4773 K  |
|       from small pool |      26    |      58    |    3842 K  |    3842 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:17:55] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:17:55] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:17:55] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:17:55] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:18:01]    INFO >> epoch 005:   1164 / 1539 loss=4.156, wps=4631.9, ups=5.94, wpb=780.4, bsz=780.4, num_updates=7300, lr=8.9e-05, gnorm=7.014, clip=2, train_wall=7, gb_free=69.6, wall=1210 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:18:08]    INFO >> epoch 005:   1214 / 1539 loss=4.504, wps=4455.6, ups=6.77, wpb=657.7, bsz=657.7, num_updates=7350, lr=8.9e-05, gnorm=5.703, clip=2, train_wall=7, gb_free=68.7, wall=1217 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:18:15]    INFO >> epoch 005:   1264 / 1539 loss=4.199, wps=4875.7, ups=7.68, wpb=635.1, bsz=635.1, num_updates=7400, lr=8.9e-05, gnorm=6.041, clip=0, train_wall=6, gb_free=73.5, wall=1224 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:18:22]    INFO >> epoch 005:   1314 / 1539 loss=4.448, wps=4423.2, ups=6.79, wpb=651.5, bsz=651.5, num_updates=7450, lr=8.9e-05, gnorm=5.383, clip=0, train_wall=7, gb_free=70, wall=1231 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:18:31]    INFO >> epoch 005:   1364 / 1539 loss=4.185, wps=4843.6, ups=6.68, wpb=725.6, bsz=725.6, num_updates=7500, lr=8.9e-05, gnorm=6.524, clip=0, train_wall=7, gb_free=74.7, wall=1239 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:18:38]    INFO >> epoch 005:   1414 / 1539 loss=4.393, wps=4412.8, ups=7, wpb=630.1, bsz=630.1, num_updates=7550, lr=8.9e-05, gnorm=5.893, clip=0, train_wall=7, gb_free=74.2, wall=1246 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:18:46]    INFO >> epoch 005:   1464 / 1539 loss=4.3, wps=5029.1, ups=6.59, wpb=763.7, bsz=763.7, num_updates=7600, lr=8.9e-05, gnorm=7.03, clip=2, train_wall=7, gb_free=48.5, wall=1253 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:18:54]    INFO >> epoch 005:   1514 / 1539 loss=4.167, wps=5124.6, ups=6.38, wpb=802.7, bsz=802.7, num_updates=7650, lr=8.9e-05, gnorm=7.4, clip=2, train_wall=7, gb_free=54.7, wall=1261 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:18:57]    INFO >> epoch 005 | loss 4.336 | wps 4411.9 | ups 6.19 | wpb 712.7 | bsz 712.7 | num_updates 7675 | lr 8.9e-05 | gnorm 6.475 | clip 0.5 | train_wall 219 | gb_free 63.5 | wall 1265 (progress_bar.py:267, print())[0m
[33m[2025-11-19 04:18:57] WARNING >> tensorboard or required dependencies not found, please see README for using tensorboard. (e.g. pip install tensorboardX) (progress_bar.py:314, __init__())[0m
[32m[2025-11-19 04:19:12]    INFO >> epoch 005 | valid on 'valid' subset | loss 4.218 | wps 11683.2 | wpb 5412.5 | bsz 5412.5 | num_updates 7675 | best_loss 5.983 (progress_bar.py:267, print())[0m
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
[32m[2025-11-19 04:19:12]    INFO >> è®­ç»ƒæ›²çº¿å·²ä¿å­˜: /home/zhaojunzhang/naturalcc/typilus/experiments/exp_lr_1e-4/logs/plots/training.png (train_enhanced.py:118, plot())[0m
[32m[2025-11-19 04:19:12]    INFO >> saved checkpoint /home/zhaojunzhang/naturalcc/typilus/experiments/exp_lr_1e-4/checkpoints/checkpoint_last.pt (epoch 5 @ 7675 updates, score 4.218) (writing took 0.012379 seconds) (checkpoint_utils.py:78, save_checkpoint())[0m
[33m[2025-11-19 04:19:12] WARNING >> tensorboard or required dependencies not found, please see README for using tensorboard. (e.g. pip install tensorboardX) (progress_bar.py:314, __init__())[0m
[32m[2025-11-19 04:19:15]    INFO >> epoch 006:     25 / 1539 loss=4.241, wps=1732.2, ups=2.44, wpb=708.8, bsz=708.8, num_updates=7700, lr=8.2e-05, gnorm=6.633, clip=0, train_wall=7, gb_free=74.9, wall=1282 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:19:23]    INFO >> epoch 006:     75 / 1539 loss=4.309, wps=5587, ups=6.47, wpb=863.7, bsz=863.7, num_updates=7750, lr=8.2e-05, gnorm=6.549, clip=0, train_wall=7, gb_free=75.2, wall=1289 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:19:30]    INFO >> epoch 006:    125 / 1539 loss=4.268, wps=4838.3, ups=7.17, wpb=675.3, bsz=675.3, num_updates=7800, lr=8.2e-05, gnorm=6.592, clip=0, train_wall=7, gb_free=70.3, wall=1296 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:19:39]    INFO >> epoch 006:    175 / 1539 loss=4.15, wps=4705.3, ups=6.83, wpb=689, bsz=689, num_updates=7850, lr=8.2e-05, gnorm=7.21, clip=2, train_wall=7, gb_free=74.3, wall=1304 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:19:41] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 1.86 GiB. GPU 0 has a total capacity of 79.14 GiB of which 535.25 MiB is free. Including non-PyTorch memory, this process has 78.59 GiB memory in use. Of the allocated memory 73.81 GiB is allocated by PyTorch, and 4.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:19:41] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 21           |        cudaMalloc retries: 44        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  75055 MiB |  75998 MiB | 254753 GiB | 254679 GiB |
|       from large pool |  75042 MiB |  75985 MiB | 253307 GiB | 253233 GiB |
|       from small pool |     12 MiB |     15 MiB |   1446 GiB |   1446 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  75055 MiB |  75998 MiB | 254753 GiB | 254679 GiB |
|       from large pool |  75042 MiB |  75985 MiB | 253307 GiB | 253233 GiB |
|       from small pool |     12 MiB |     15 MiB |   1446 GiB |   1446 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  75035 MiB |  75977 MiB | 254221 GiB | 254148 GiB |
|       from large pool |  75022 MiB |  75964 MiB | 252777 GiB | 252704 GiB |
|       from small pool |     12 MiB |     15 MiB |   1443 GiB |   1443 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  79970 MiB |  80406 MiB | 690500 MiB | 610530 MiB |
|       from large pool |  79944 MiB |  80306 MiB | 687088 MiB | 607144 MiB |
|       from small pool |     26 MiB |    100 MiB |   3412 MiB |   3386 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   4914 MiB |   8989 MiB | 249574 GiB | 249569 GiB |
|       from large pool |   4901 MiB |   8976 MiB | 247940 GiB | 247935 GiB |
|       from small pool |     13 MiB |     25 MiB |   1633 GiB |   1633 GiB |
|---------------------------------------------------------------------------|
| Allocations           |     605    |     613    |   16790 K  |   16790 K  |
|       from large pool |     314    |     322    |    7980 K  |    7979 K  |
|       from small pool |     291    |     356    |    8810 K  |    8810 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     605    |     613    |   16790 K  |   16790 K  |
|       from large pool |     314    |     322    |    7980 K  |    7979 K  |
|       from small pool |     291    |     356    |    8810 K  |    8810 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     172    |     210    |    4032    |    3860    |
|       from large pool |     159    |     160    |    2326    |    2167    |
|       from small pool |      13    |      50    |    1706    |    1693    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     164    |     164    |    9442 K  |    9442 K  |
|       from large pool |     136    |     136    |    5197 K  |    5196 K  |
|       from small pool |      28    |      57    |    4245 K  |    4245 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:19:41] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:19:41] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:19:41] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:19:41] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[33m[2025-11-19 04:19:47] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 904.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 535.25 MiB is free. Including non-PyTorch memory, this process has 78.59 GiB memory in use. Of the allocated memory 72.94 GiB is allocated by PyTorch, and 5.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:19:47] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 22           |        cudaMalloc retries: 45        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  69875 MiB |  74872 MiB | 255914 GiB | 255845 GiB |
|       from large pool |  69858 MiB |  74855 MiB | 254462 GiB | 254394 GiB |
|       from small pool |     17 MiB |     17 MiB |   1451 GiB |   1451 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  69875 MiB |  74872 MiB | 255914 GiB | 255845 GiB |
|       from large pool |  69858 MiB |  74855 MiB | 254462 GiB | 254394 GiB |
|       from small pool |     17 MiB |     17 MiB |   1451 GiB |   1451 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  69846 MiB |  74842 MiB | 255380 GiB | 255311 GiB |
|       from large pool |  69829 MiB |  74825 MiB | 253930 GiB | 253862 GiB |
|       from small pool |     17 MiB |     17 MiB |   1449 GiB |   1449 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  79970 MiB |  80006 MiB | 690536 MiB | 610566 MiB |
|       from large pool |  79944 MiB |  79944 MiB | 687088 MiB | 607144 MiB |
|       from small pool |     26 MiB |     62 MiB |   3448 MiB |   3422 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  10094 MiB |  11472 MiB | 250631 GiB | 250621 GiB |
|       from large pool |  10085 MiB |  11463 MiB | 248991 GiB | 248982 GiB |
|       from small pool |      8 MiB |     27 MiB |   1639 GiB |   1639 GiB |
|---------------------------------------------------------------------------|
| Allocations           |     643    |     661    |   16854 K  |   16853 K  |
|       from large pool |     344    |     362    |    8013 K  |    8013 K  |
|       from small pool |     299    |     356    |    8840 K  |    8840 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     643    |     661    |   16854 K  |   16853 K  |
|       from large pool |     344    |     362    |    8013 K  |    8013 K  |
|       from small pool |     299    |     356    |    8840 K  |    8840 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     172    |     190    |    4050    |    3878    |
|       from large pool |     159    |     159    |    2326    |    2167    |
|       from small pool |      13    |      31    |    1724    |    1711    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     151    |     153    |    9477 K  |    9477 K  |
|       from large pool |     121    |     123    |    5219 K  |    5219 K  |
|       from small pool |      30    |      62    |    4258 K  |    4258 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:19:47] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:19:47] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:19:47] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:19:47] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:19:48]    INFO >> epoch 006:    227 / 1539 loss=4.334, wps=4040.4, ups=5.62, wpb=719.2, bsz=719.2, num_updates=7900, lr=8.2e-05, gnorm=6.012, clip=0, train_wall=7, gb_free=71.4, wall=1312 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:19:55]    INFO >> epoch 006:    277 / 1539 loss=4.319, wps=4538.1, ups=7.25, wpb=625.7, bsz=625.7, num_updates=7950, lr=8.2e-05, gnorm=5.289, clip=0, train_wall=6, gb_free=74.5, wall=1319 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:20:02]    INFO >> epoch 006:    327 / 1539 loss=4.427, wps=5438.8, ups=6.55, wpb=830.5, bsz=830.5, num_updates=8000, lr=8.2e-05, gnorm=6.566, clip=0, train_wall=7, gb_free=70.3, wall=1327 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:20:11]    INFO >> epoch 006:    377 / 1539 loss=4.222, wps=4470.2, ups=6.8, wpb=657.6, bsz=657.6, num_updates=8050, lr=8.2e-05, gnorm=6.431, clip=0, train_wall=7, gb_free=71.1, wall=1334 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:20:18]    INFO >> epoch 006:    427 / 1539 loss=4.282, wps=5332.8, ups=6.91, wpb=772.1, bsz=772.1, num_updates=8100, lr=8.2e-05, gnorm=5.86, clip=0, train_wall=7, gb_free=75, wall=1342 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:20:21] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacity of 79.14 GiB of which 2.39 GiB is free. Including non-PyTorch memory, this process has 76.72 GiB memory in use. Of the allocated memory 70.76 GiB is allocated by PyTorch, and 5.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:20:21] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 23           |        cudaMalloc retries: 47        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  72059 MiB |  72460 MiB | 262338 GiB | 262268 GiB |
|       from large pool |  72042 MiB |  72442 MiB | 260852 GiB | 260781 GiB |
|       from small pool |     17 MiB |     21 MiB |   1486 GiB |   1486 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  72059 MiB |  72460 MiB | 262338 GiB | 262268 GiB |
|       from large pool |  72042 MiB |  72442 MiB | 260852 GiB | 260781 GiB |
|       from small pool |     17 MiB |     21 MiB |   1486 GiB |   1486 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  72044 MiB |  72444 MiB | 261790 GiB | 261719 GiB |
|       from large pool |  72027 MiB |  72426 MiB | 260305 GiB | 260235 GiB |
|       from small pool |     17 MiB |     21 MiB |   1484 GiB |   1484 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  78056 MiB |  80154 MiB | 696552 MiB | 618496 MiB |
|       from large pool |  78026 MiB |  79944 MiB | 692920 MiB | 614894 MiB |
|       from small pool |     30 MiB |    210 MiB |   3632 MiB |   3602 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   5996 MiB |   8377 MiB | 256697 GiB | 256691 GiB |
|       from large pool |   5983 MiB |   8364 MiB | 255017 GiB | 255011 GiB |
|       from small pool |     12 MiB |     31 MiB |   1680 GiB |   1680 GiB |
|---------------------------------------------------------------------------|
| Allocations           |     606    |     613    |   17287 K  |   17286 K  |
|       from large pool |     308    |     315    |    8230 K  |    8230 K  |
|       from small pool |     298    |     356    |    9056 K  |    9056 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     606    |     613    |   17287 K  |   17286 K  |
|       from large pool |     308    |     315    |    8230 K  |    8230 K  |
|       from small pool |     298    |     356    |    9056 K  |    9056 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     172    |     264    |    4145    |    3973    |
|       from large pool |     157    |     159    |    2329    |    2172    |
|       from small pool |      15    |     105    |    1816    |    1801    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     169    |     169    |    9721 K  |    9721 K  |
|       from large pool |     137    |     137    |    5362 K  |    5362 K  |
|       from small pool |      32    |      55    |    4358 K  |    4358 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:20:21] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:20:21] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:20:21] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:20:21] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:20:26]    INFO >> epoch 006:    478 / 1539 loss=4.331, wps=4540, ups=6.43, wpb=705.8, bsz=705.8, num_updates=8150, lr=8.2e-05, gnorm=5.793, clip=0, train_wall=7, gb_free=65, wall=1349 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:20:34]    INFO >> epoch 006:    528 / 1539 loss=4.15, wps=4509.4, ups=6.37, wpb=707.6, bsz=707.6, num_updates=8200, lr=8.2e-05, gnorm=6.394, clip=0, train_wall=7, gb_free=72, wall=1357 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:20:43]    INFO >> epoch 006:    578 / 1539 loss=4.108, wps=5264, ups=6.6, wpb=797.6, bsz=797.6, num_updates=8250, lr=8.2e-05, gnorm=6.267, clip=0, train_wall=7, gb_free=74.1, wall=1365 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:20:50]    INFO >> epoch 006:    628 / 1539 loss=4.103, wps=4708.5, ups=7.3, wpb=644.9, bsz=644.9, num_updates=8300, lr=8.2e-05, gnorm=6.439, clip=2, train_wall=6, gb_free=70.5, wall=1372 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:20:57]    INFO >> epoch 006:    678 / 1539 loss=4.134, wps=4844.1, ups=6.63, wpb=730.2, bsz=730.2, num_updates=8350, lr=8.2e-05, gnorm=6.453, clip=0, train_wall=7, gb_free=73.6, wall=1379 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:21:04]    INFO >> epoch 006:    728 / 1539 loss=4.237, wps=4451.3, ups=7.22, wpb=616.1, bsz=616.1, num_updates=8400, lr=8.2e-05, gnorm=5.729, clip=0, train_wall=7, gb_free=62, wall=1386 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:21:05] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 17.25 MiB is free. Including non-PyTorch memory, this process has 79.10 GiB memory in use. Of the allocated memory 76.16 GiB is allocated by PyTorch, and 2.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:21:05] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 24           |        cudaMalloc retries: 48        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  77932 MiB |  77992 MiB | 270810 GiB | 270734 GiB |
|       from large pool |  77549 MiB |  77609 MiB | 269273 GiB | 269197 GiB |
|       from small pool |    383 MiB |    384 MiB |   1536 GiB |   1536 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  77932 MiB |  77992 MiB | 270810 GiB | 270734 GiB |
|       from large pool |  77549 MiB |  77609 MiB | 269273 GiB | 269197 GiB |
|       from small pool |    383 MiB |    384 MiB |   1536 GiB |   1536 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  77897 MiB |  77956 MiB | 270242 GiB | 270166 GiB |
|       from large pool |  77516 MiB |  77575 MiB | 268708 GiB | 268632 GiB |
|       from small pool |    381 MiB |    382 MiB |   1534 GiB |   1533 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  80488 MiB |  80490 MiB | 698986 MiB | 618498 MiB |
|       from large pool |  80066 MiB |  80066 MiB | 694960 MiB | 614894 MiB |
|       from small pool |    422 MiB |    424 MiB |   4026 MiB |   3604 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   2495 MiB |   6667 MiB | 264824 GiB | 264822 GiB |
|       from large pool |   2456 MiB |   6661 MiB | 263086 GiB | 263084 GiB |
|       from small pool |     38 MiB |     40 MiB |   1738 GiB |   1738 GiB |
|---------------------------------------------------------------------------|
| Allocations           |    7076    |    7079    |   17882 K  |   17874 K  |
|       from large pool |     913    |     914    |    8520 K  |    8519 K  |
|       from small pool |    6163    |    6166    |    9361 K  |    9355 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    7076    |    7079    |   17882 K  |   17874 K  |
|       from large pool |     913    |     914    |    8520 K  |    8519 K  |
|       from small pool |    6163    |    6166    |    9361 K  |    9355 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     402    |     403    |    4376    |    3974    |
|       from large pool |     191    |     191    |    2363    |    2172    |
|       from small pool |     211    |     212    |    2013    |    1802    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     526    |     527    |   10055 K  |   10055 K  |
|       from large pool |     150    |     150    |    5552 K  |    5552 K  |
|       from small pool |     376    |     377    |    4503 K  |    4502 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:21:05] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:21:05] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:21:05] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:21:05] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:21:11]    INFO >> epoch 006:    779 / 1539 loss=4.187, wps=4400.6, ups=6.85, wpb=642.5, bsz=642.5, num_updates=8450, lr=8.2e-05, gnorm=6.13, clip=0, train_wall=6, gb_free=74.1, wall=1393 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:21:20]    INFO >> epoch 006:    829 / 1539 loss=4.131, wps=4446.3, ups=6.77, wpb=656.8, bsz=656.8, num_updates=8500, lr=8.2e-05, gnorm=6.239, clip=0, train_wall=7, gb_free=66.6, wall=1401 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:21:27]    INFO >> epoch 006:    879 / 1539 loss=4.099, wps=4906, ups=6.72, wpb=729.6, bsz=729.6, num_updates=8550, lr=8.2e-05, gnorm=6.043, clip=0, train_wall=7, gb_free=70.2, wall=1408 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:21:36]    INFO >> epoch 006:    929 / 1539 loss=4.355, wps=5101.3, ups=6.17, wpb=826.1, bsz=826.1, num_updates=8600, lr=8.2e-05, gnorm=6.552, clip=0, train_wall=8, gb_free=73.1, wall=1416 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:21:43]    INFO >> epoch 006:    979 / 1539 loss=4.06, wps=4651.2, ups=6.63, wpb=701.1, bsz=701.1, num_updates=8650, lr=8.2e-05, gnorm=5.553, clip=0, train_wall=7, gb_free=75.1, wall=1424 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:21:53] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 2.57 GiB. GPU 0 has a total capacity of 79.14 GiB of which 2.27 GiB is free. Including non-PyTorch memory, this process has 76.84 GiB memory in use. Of the allocated memory 66.03 GiB is allocated by PyTorch, and 10.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:21:53] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 25           |        cudaMalloc retries: 49        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  63499 MiB |  70130 MiB | 279629 GiB | 279567 GiB |
|       from large pool |  63479 MiB |  70110 MiB | 278045 GiB | 277983 GiB |
|       from small pool |     20 MiB |     60 MiB |   1584 GiB |   1584 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  63499 MiB |  70130 MiB | 279629 GiB | 279567 GiB |
|       from large pool |  63479 MiB |  70110 MiB | 278045 GiB | 277983 GiB |
|       from small pool |     20 MiB |     60 MiB |   1584 GiB |   1584 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  63481 MiB |  70111 MiB | 279042 GiB | 278980 GiB |
|       from large pool |  63461 MiB |  70091 MiB | 277460 GiB | 277398 GiB |
|       from small pool |     20 MiB |     60 MiB |   1582 GiB |   1582 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  78178 MiB |  80428 MiB | 698986 MiB | 620808 MiB |
|       from large pool |  78146 MiB |  80006 MiB | 694960 MiB | 616814 MiB |
|       from small pool |     32 MiB |    422 MiB |   4026 MiB |   3994 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   7300 MiB |  10790 MiB | 272808 GiB | 272800 GiB |
|       from large pool |   7288 MiB |  10778 MiB | 271014 GiB | 271007 GiB |
|       from small pool |     11 MiB |     29 MiB |   1793 GiB |   1793 GiB |
|---------------------------------------------------------------------------|
| Allocations           |     646    |    1326    |   18465 K  |   18465 K  |
|       from large pool |     330    |     403    |    8814 K  |    8814 K  |
|       from small pool |     316    |     924    |    9651 K  |    9650 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     646    |    1326    |   18465 K  |   18465 K  |
|       from large pool |     330    |     403    |    8814 K  |    8814 K  |
|       from small pool |     316    |     924    |    9651 K  |    9650 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     176    |     401    |    4376    |    4200    |
|       from large pool |     160    |     190    |    2363    |    2203    |
|       from small pool |      16    |     211    |    2013    |    1997    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     165    |     213    |   10388 K  |   10388 K  |
|       from large pool |     129    |     160    |    5749 K  |    5749 K  |
|       from small pool |      36    |      56    |    4638 K  |    4638 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:21:53] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:21:53] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:21:53] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:21:53] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:21:53]    INFO >> epoch 006:   1030 / 1539 loss=4.181, wps=4310.5, ups=5.9, wpb=730.1, bsz=730.1, num_updates=8700, lr=8.2e-05, gnorm=6.332, clip=0, train_wall=7, gb_free=11.5, wall=1432 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:22:00]    INFO >> epoch 006:   1080 / 1539 loss=4.304, wps=4851.6, ups=6.71, wpb=723.5, bsz=723.5, num_updates=8750, lr=8.2e-05, gnorm=5.89, clip=0, train_wall=7, gb_free=72.4, wall=1440 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:22:09]    INFO >> epoch 006:   1130 / 1539 loss=4.084, wps=4662.7, ups=6.15, wpb=757.6, bsz=757.6, num_updates=8800, lr=8.2e-05, gnorm=7.04, clip=2, train_wall=8, gb_free=72.1, wall=1448 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:22:16]    INFO >> epoch 006:   1180 / 1539 loss=4.343, wps=5009.3, ups=6.76, wpb=740.5, bsz=740.5, num_updates=8850, lr=8.2e-05, gnorm=6.175, clip=0, train_wall=7, gb_free=69, wall=1455 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:22:25]    INFO >> epoch 006:   1230 / 1539 loss=4.166, wps=4222.3, ups=6.4, wpb=659.3, bsz=659.3, num_updates=8900, lr=8.2e-05, gnorm=6.075, clip=0, train_wall=7, gb_free=73.8, wall=1463 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:22:32]    INFO >> epoch 006:   1280 / 1539 loss=4.258, wps=4526.8, ups=6.96, wpb=650.6, bsz=650.6, num_updates=8950, lr=8.2e-05, gnorm=6.026, clip=0, train_wall=7, gb_free=75.3, wall=1470 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:22:40]    INFO >> epoch 006:   1330 / 1539 loss=4.202, wps=4960.5, ups=6.69, wpb=741, bsz=741, num_updates=9000, lr=8.2e-05, gnorm=6.324, clip=0, train_wall=7, gb_free=71.3, wall=1478 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:22:47]    INFO >> epoch 006:   1380 / 1539 loss=4.218, wps=4447.1, ups=7.3, wpb=608.9, bsz=608.9, num_updates=9050, lr=8.2e-05, gnorm=5.959, clip=0, train_wall=6, gb_free=68.9, wall=1485 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:22:55]    INFO >> epoch 006:   1430 / 1539 loss=4.225, wps=5023.6, ups=6.68, wpb=751.8, bsz=751.8, num_updates=9100, lr=8.2e-05, gnorm=6.459, clip=0, train_wall=7, gb_free=70.5, wall=1492 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:23:03]    INFO >> epoch 006:   1480 / 1539 loss=4.043, wps=4638.9, ups=6.47, wpb=717, bsz=717, num_updates=9150, lr=8.2e-05, gnorm=6.277, clip=2, train_wall=7, gb_free=69.4, wall=1500 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:23:10]    INFO >> epoch 006:   1530 / 1539 loss=4.08, wps=4905.9, ups=7.28, wpb=674.1, bsz=674.1, num_updates=9200, lr=8.2e-05, gnorm=5.689, clip=0, train_wall=6, gb_free=74.6, wall=1507 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:23:11]    INFO >> epoch 006 | loss 4.214 | wps 4488 | ups 6.31 | wpb 711.1 | bsz 711.1 | num_updates 9209 | lr 8.2e-05 | gnorm 6.199 | clip 0.3 | train_wall 214 | gb_free 72.3 | wall 1508 (progress_bar.py:267, print())[0m
[33m[2025-11-19 04:23:11] WARNING >> tensorboard or required dependencies not found, please see README for using tensorboard. (e.g. pip install tensorboardX) (progress_bar.py:314, __init__())[0m
[32m[2025-11-19 04:23:24]    INFO >> epoch 006 | valid on 'valid' subset | loss 4.101 | wps 11948.8 | wpb 5412.5 | bsz 5412.5 | num_updates 9209 | best_loss 5.983 (progress_bar.py:267, print())[0m
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
[32m[2025-11-19 04:23:24]    INFO >> è®­ç»ƒæ›²çº¿å·²ä¿å­˜: /home/zhaojunzhang/naturalcc/typilus/experiments/exp_lr_1e-4/logs/plots/training.png (train_enhanced.py:118, plot())[0m
[32m[2025-11-19 04:23:24]    INFO >> saved checkpoint /home/zhaojunzhang/naturalcc/typilus/experiments/exp_lr_1e-4/checkpoints/checkpoint_last.pt (epoch 6 @ 9209 updates, score 4.101) (writing took 0.012756 seconds) (checkpoint_utils.py:78, save_checkpoint())[0m
[33m[2025-11-19 04:23:24] WARNING >> tensorboard or required dependencies not found, please see README for using tensorboard. (e.g. pip install tensorboardX) (progress_bar.py:314, __init__())[0m
[32m[2025-11-19 04:23:32]    INFO >> epoch 007:     41 / 1539 loss=4.269, wps=1674.7, ups=2.38, wpb=704.3, bsz=704.3, num_updates=9250, lr=7.4e-05, gnorm=5.493, clip=0, train_wall=7, gb_free=71.6, wall=1528 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:23:34] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacity of 79.14 GiB of which 1.83 GiB is free. Including non-PyTorch memory, this process has 77.29 GiB memory in use. Of the allocated memory 70.77 GiB is allocated by PyTorch, and 6.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:23:34] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 26           |        cudaMalloc retries: 51        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  72064 MiB |  72463 MiB | 300570 GiB | 300499 GiB |
|       from large pool |  72047 MiB |  72446 MiB | 298863 GiB | 298793 GiB |
|       from small pool |     17 MiB |     25 MiB |   1706 GiB |   1706 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  72064 MiB |  72463 MiB | 300570 GiB | 300499 GiB |
|       from large pool |  72047 MiB |  72446 MiB | 298863 GiB | 298793 GiB |
|       from small pool |     17 MiB |     25 MiB |   1706 GiB |   1706 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  72044 MiB |  72444 MiB | 299940 GiB | 299870 GiB |
|       from large pool |  72027 MiB |  72426 MiB | 298236 GiB | 298165 GiB |
|       from small pool |     17 MiB |     25 MiB |   1704 GiB |   1704 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  78634 MiB |  78794 MiB | 712436 MiB | 633802 MiB |
|       from large pool |  78610 MiB |  78670 MiB | 708318 MiB | 629708 MiB |
|       from small pool |     24 MiB |    124 MiB |   4118 MiB |   4094 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   6569 MiB |   8371 MiB | 290286 GiB | 290279 GiB |
|       from large pool |   6562 MiB |   8363 MiB | 288359 GiB | 288352 GiB |
|       from small pool |      6 MiB |     33 MiB |   1927 GiB |   1927 GiB |
|---------------------------------------------------------------------------|
| Allocations           |     606    |     613    |   19804 K  |   19803 K  |
|       from large pool |     308    |     315    |    9401 K  |    9401 K  |
|       from small pool |     298    |     356    |   10402 K  |   10402 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     606    |     613    |   19804 K  |   19803 K  |
|       from large pool |     308    |     315    |    9401 K  |    9401 K  |
|       from small pool |     298    |     356    |   10402 K  |   10402 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     168    |     222    |    4427    |    4259    |
|       from large pool |     156    |     160    |    2368    |    2212    |
|       from small pool |      12    |      62    |    2059    |    2047    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     162    |     163    |   11162 K  |   11162 K  |
|       from large pool |     137    |     138    |    6142 K  |    6142 K  |
|       from small pool |      25    |      62    |    5020 K  |    5020 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:23:34] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:23:34] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:23:34] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:23:34] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:23:40]    INFO >> epoch 007:     92 / 1539 loss=4.067, wps=4554.2, ups=6.75, wpb=674.7, bsz=674.7, num_updates=9300, lr=7.4e-05, gnorm=6.782, clip=2, train_wall=6, gb_free=74.6, wall=1535 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:23:47]    INFO >> epoch 007:    142 / 1539 loss=4.119, wps=4503.2, ups=6.79, wpb=663.1, bsz=663.1, num_updates=9350, lr=7.4e-05, gnorm=6.737, clip=2, train_wall=7, gb_free=73.4, wall=1542 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:23:55]    INFO >> epoch 007:    192 / 1539 loss=3.91, wps=5598.2, ups=6.32, wpb=885.1, bsz=885.1, num_updates=9400, lr=7.4e-05, gnorm=7.162, clip=0, train_wall=7, gb_free=67.7, wall=1550 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:24:04]    INFO >> epoch 007:    242 / 1539 loss=4.191, wps=5097.2, ups=6.42, wpb=794.3, bsz=794.3, num_updates=9450, lr=7.4e-05, gnorm=6.74, clip=0, train_wall=7, gb_free=70.7, wall=1558 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:24:12]    INFO >> epoch 007:    292 / 1539 loss=4.038, wps=4747.4, ups=6.79, wpb=699.6, bsz=699.6, num_updates=9500, lr=7.4e-05, gnorm=6.826, clip=2, train_wall=7, gb_free=71.4, wall=1566 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:24:17] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacity of 79.14 GiB of which 1.83 GiB is free. Including non-PyTorch memory, this process has 77.29 GiB memory in use. Of the allocated memory 70.08 GiB is allocated by PyTorch, and 6.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:24:17] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 27           |        cudaMalloc retries: 52        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  69006 MiB |  71763 MiB | 308769 GiB | 308702 GiB |
|       from large pool |  68989 MiB |  71746 MiB | 307018 GiB | 306950 GiB |
|       from small pool |     16 MiB |     18 MiB |   1751 GiB |   1751 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  69006 MiB |  71763 MiB | 308769 GiB | 308702 GiB |
|       from large pool |  68989 MiB |  71746 MiB | 307018 GiB | 306950 GiB |
|       from small pool |     16 MiB |     18 MiB |   1751 GiB |   1751 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  68980 MiB |  71736 MiB | 308120 GiB | 308053 GiB |
|       from large pool |  68963 MiB |  71719 MiB | 306372 GiB | 306304 GiB |
|       from small pool |     16 MiB |     17 MiB |   1748 GiB |   1748 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  78636 MiB |  78836 MiB | 712638 MiB | 634002 MiB |
|       from large pool |  78610 MiB |  78610 MiB | 708318 MiB | 629708 MiB |
|       from small pool |     26 MiB |    226 MiB |   4320 MiB |   4294 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   6901 MiB |  10618 MiB | 298170 GiB | 298163 GiB |
|       from large pool |   6892 MiB |  10608 MiB | 296191 GiB | 296185 GiB |
|       from small pool |      9 MiB |     25 MiB |   1978 GiB |   1978 GiB |
|---------------------------------------------------------------------------|
| Allocations           |     641    |     649    |   20344 K  |   20344 K  |
|       from large pool |     343    |     351    |    9674 K  |    9674 K  |
|       from small pool |     298    |     342    |   10670 K  |   10669 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     641    |     649    |   20344 K  |   20344 K  |
|       from large pool |     343    |     351    |    9674 K  |    9674 K  |
|       from small pool |     298    |     342    |   10670 K  |   10669 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     169    |     269    |    4528    |    4359    |
|       from large pool |     156    |     156    |    2368    |    2212    |
|       from small pool |      13    |     113    |    2160    |    2147    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     153    |     157    |   11466 K  |   11466 K  |
|       from large pool |     124    |     128    |    6323 K  |    6323 K  |
|       from small pool |      29    |      53    |    5142 K  |    5142 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:24:17] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:24:17] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:24:17] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:24:17] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:24:20]    INFO >> epoch 007:    343 / 1539 loss=4.079, wps=3897.8, ups=5.67, wpb=687.1, bsz=687.1, num_updates=9550, lr=7.4e-05, gnorm=6.846, clip=2, train_wall=8, gb_free=69.5, wall=1574 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:24:27]    INFO >> epoch 007:    393 / 1539 loss=4.264, wps=4327.6, ups=7.24, wpb=598.1, bsz=598.1, num_updates=9600, lr=7.4e-05, gnorm=5.616, clip=0, train_wall=7, gb_free=62, wall=1581 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:24:36]    INFO >> epoch 007:    443 / 1539 loss=4.121, wps=4463.9, ups=6.59, wpb=677.8, bsz=677.8, num_updates=9650, lr=7.4e-05, gnorm=5.756, clip=0, train_wall=7, gb_free=74.5, wall=1589 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:24:41] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 1.86 GiB. GPU 0 has a total capacity of 79.14 GiB of which 123.25 MiB is free. Including non-PyTorch memory, this process has 79.00 GiB memory in use. Of the allocated memory 75.66 GiB is allocated by PyTorch, and 2.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:24:41] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 28           |        cudaMalloc retries: 54        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  76958 MiB |  77480 MiB | 313195 GiB | 313120 GiB |
|       from large pool |  76945 MiB |  77467 MiB | 311423 GiB | 311348 GiB |
|       from small pool |     12 MiB |     18 MiB |   1772 GiB |   1772 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  76958 MiB |  77480 MiB | 313195 GiB | 313120 GiB |
|       from large pool |  76945 MiB |  77467 MiB | 311423 GiB | 311348 GiB |
|       from small pool |     12 MiB |     18 MiB |   1772 GiB |   1772 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  76936 MiB |  77458 MiB | 312537 GiB | 312462 GiB |
|       from large pool |  76923 MiB |  77445 MiB | 310767 GiB | 310692 GiB |
|       from small pool |     12 MiB |     18 MiB |   1769 GiB |   1769 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  80382 MiB |  80382 MiB | 719380 MiB | 638998 MiB |
|       from large pool |  80358 MiB |  80358 MiB | 715014 MiB | 634656 MiB |
|       from small pool |     24 MiB |     72 MiB |   4366 MiB |   4342 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   3423 MiB |   7648 MiB | 302343 GiB | 302340 GiB |
|       from large pool |   3412 MiB |   7637 MiB | 300341 GiB | 300338 GiB |
|       from small pool |     11 MiB |     19 MiB |   2002 GiB |   2002 GiB |
|---------------------------------------------------------------------------|
| Allocations           |     606    |     613    |   20614 K  |   20613 K  |
|       from large pool |     315    |     322    |    9816 K  |    9816 K  |
|       from small pool |     291    |     356    |   10797 K  |   10797 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     606    |     613    |   20614 K  |   20613 K  |
|       from large pool |     315    |     322    |    9816 K  |    9816 K  |
|       from small pool |     291    |     356    |   10797 K  |   10797 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     138    |     197    |    4559    |    4421    |
|       from large pool |     126    |     161    |    2376    |    2250    |
|       from small pool |      12    |      36    |    2183    |    2171    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     134    |     134    |   11614 K  |   11614 K  |
|       from large pool |     107    |     107    |    6417 K  |    6417 K  |
|       from small pool |      27    |      47    |    5197 K  |    5197 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:24:41] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:24:41] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:24:41] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:24:41] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:24:45]    INFO >> epoch 007:    494 / 1539 loss=4.146, wps=4422.3, ups=5.95, wpb=742.8, bsz=742.8, num_updates=9700, lr=7.4e-05, gnorm=6.343, clip=2, train_wall=7, gb_free=72.2, wall=1597 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:24:52]    INFO >> epoch 007:    544 / 1539 loss=4.135, wps=4548.9, ups=7.21, wpb=631.2, bsz=631.2, num_updates=9750, lr=7.4e-05, gnorm=5.567, clip=0, train_wall=7, gb_free=74.3, wall=1604 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:24:59]    INFO >> epoch 007:    594 / 1539 loss=4.247, wps=4795.5, ups=7.01, wpb=684.3, bsz=684.3, num_updates=9800, lr=7.4e-05, gnorm=6.01, clip=0, train_wall=7, gb_free=75.1, wall=1611 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:25:06]    INFO >> epoch 007:    644 / 1539 loss=4.094, wps=4658.4, ups=6.68, wpb=697.8, bsz=697.8, num_updates=9850, lr=7.4e-05, gnorm=6.515, clip=0, train_wall=7, gb_free=70.6, wall=1619 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:25:15]    INFO >> epoch 007:    694 / 1539 loss=4.03, wps=5520.8, ups=6.6, wpb=835.9, bsz=835.9, num_updates=9900, lr=7.4e-05, gnorm=7.652, clip=4, train_wall=7, gb_free=73.9, wall=1626 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:25:22]    INFO >> epoch 007:    744 / 1539 loss=4.095, wps=4902.7, ups=6.89, wpb=712, bsz=712, num_updates=9950, lr=7.4e-05, gnorm=5.601, clip=0, train_wall=7, gb_free=72.8, wall=1634 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:25:30]    INFO >> epoch 007:    794 / 1539 loss=4.101, wps=4432.4, ups=6.77, wpb=654.6, bsz=654.6, num_updates=10000, lr=7.4e-05, gnorm=6.157, clip=0, train_wall=7, gb_free=72.1, wall=1641 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:25:37]    INFO >> epoch 007:    844 / 1539 loss=4.105, wps=4848.7, ups=6.71, wpb=722.7, bsz=722.7, num_updates=10050, lr=7.4e-05, gnorm=6.783, clip=2, train_wall=7, gb_free=70.6, wall=1649 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:25:46]    INFO >> epoch 007:    894 / 1539 loss=4.153, wps=4612.7, ups=6.7, wpb=688.1, bsz=688.1, num_updates=10100, lr=7.4e-05, gnorm=5.942, clip=0, train_wall=7, gb_free=73.8, wall=1656 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:25:53]    INFO >> epoch 007:    944 / 1539 loss=3.996, wps=4834.9, ups=6.92, wpb=699, bsz=699, num_updates=10150, lr=7.4e-05, gnorm=6.365, clip=0, train_wall=7, gb_free=71.9, wall=1663 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:26:01]    INFO >> epoch 007:    994 / 1539 loss=4.049, wps=4840.4, ups=6.58, wpb=736.1, bsz=736.1, num_updates=10200, lr=7.4e-05, gnorm=6.661, clip=0, train_wall=7, gb_free=70.3, wall=1671 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:26:08]    INFO >> epoch 007:   1044 / 1539 loss=4.102, wps=4920, ups=6.97, wpb=705.7, bsz=705.7, num_updates=10250, lr=7.4e-05, gnorm=6.058, clip=0, train_wall=7, gb_free=73, wall=1678 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:26:17]    INFO >> epoch 007:   1094 / 1539 loss=4.101, wps=4615.9, ups=6.66, wpb=693.4, bsz=693.4, num_updates=10300, lr=7.4e-05, gnorm=6.385, clip=2, train_wall=7, gb_free=71.6, wall=1685 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:26:25]    INFO >> epoch 007:   1144 / 1539 loss=4.125, wps=4720.6, ups=6.01, wpb=784.9, bsz=784.9, num_updates=10350, lr=7.4e-05, gnorm=6.394, clip=0, train_wall=8, gb_free=74, wall=1694 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:26:33]    INFO >> epoch 007:   1194 / 1539 loss=4.115, wps=5205.5, ups=6.41, wpb=811.5, bsz=811.5, num_updates=10400, lr=7.4e-05, gnorm=6.305, clip=0, train_wall=7, gb_free=72.8, wall=1702 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:26:40]    INFO >> epoch 007:   1244 / 1539 loss=4.043, wps=4734.8, ups=6.9, wpb=686.2, bsz=686.2, num_updates=10450, lr=7.4e-05, gnorm=6.237, clip=0, train_wall=7, gb_free=68.3, wall=1709 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:26:47]    INFO >> epoch 007:   1294 / 1539 loss=4.061, wps=4454.1, ups=6.95, wpb=640.4, bsz=640.4, num_updates=10500, lr=7.4e-05, gnorm=5.79, clip=0, train_wall=7, gb_free=70.7, wall=1716 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:26:56]    INFO >> epoch 007:   1344 / 1539 loss=4.002, wps=4789.8, ups=6.87, wpb=697.4, bsz=697.4, num_updates=10550, lr=7.4e-05, gnorm=6.627, clip=2, train_wall=7, gb_free=70.4, wall=1723 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:27:04]    INFO >> epoch 007:   1394 / 1539 loss=3.985, wps=4641.8, ups=6.64, wpb=699.1, bsz=699.1, num_updates=10600, lr=7.4e-05, gnorm=6.64, clip=2, train_wall=7, gb_free=67.1, wall=1731 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:27:09] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 51.25 MiB is free. Including non-PyTorch memory, this process has 79.07 GiB memory in use. Of the allocated memory 76.76 GiB is allocated by PyTorch, and 1.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:27:09] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 29           |        cudaMalloc retries: 56        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  78538 MiB |  78598 MiB | 341065 GiB | 340988 GiB |
|       from large pool |  78151 MiB |  78211 MiB | 339139 GiB | 339063 GiB |
|       from small pool |    386 MiB |    388 MiB |   1925 GiB |   1925 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  78538 MiB |  78598 MiB | 341065 GiB | 340988 GiB |
|       from large pool |  78151 MiB |  78211 MiB | 339139 GiB | 339063 GiB |
|       from small pool |    386 MiB |    388 MiB |   1925 GiB |   1925 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  78257 MiB |  78317 MiB | 340344 GiB | 340268 GiB |
|       from large pool |  77872 MiB |  77932 MiB | 338421 GiB | 338345 GiB |
|       from small pool |    384 MiB |    386 MiB |   1922 GiB |   1922 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  80454 MiB |  80456 MiB | 750444 MiB | 669990 MiB |
|       from large pool |  80028 MiB |  80028 MiB | 745674 MiB | 665646 MiB |
|       from small pool |    426 MiB |    428 MiB |   4770 MiB |   4344 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   1855 MiB |   6794 MiB | 329939 GiB | 329938 GiB |
|       from large pool |   1816 MiB |   6788 MiB | 327761 GiB | 327759 GiB |
|       from small pool |     39 MiB |     41 MiB |   2178 GiB |   2178 GiB |
|---------------------------------------------------------------------------|
| Allocations           |    7142    |    7145    |   22485 K  |   22478 K  |
|       from large pool |     919    |     920    |   10761 K  |   10760 K  |
|       from small pool |    6223    |    6226    |   11723 K  |   11717 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    7142    |    7145    |   22485 K  |   22478 K  |
|       from large pool |     919    |     920    |   10761 K  |   10760 K  |
|       from small pool |    6223    |    6226    |   11723 K  |   11717 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     838    |     839    |    5272    |    4434    |
|       from large pool |     625    |     625    |    2887    |    2262    |
|       from small pool |     213    |     214    |    2385    |    2172    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     519    |     520    |   12654 K  |   12653 K  |
|       from large pool |     138    |     138    |    7032 K  |    7032 K  |
|       from small pool |     381    |     382    |    5621 K  |    5621 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:27:09] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:27:09] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:27:09] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:27:09] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:27:12]    INFO >> epoch 007:   1445 / 1539 loss=3.998, wps=4315.4, ups=6.03, wpb=716, bsz=716, num_updates=10650, lr=7.4e-05, gnorm=6.478, clip=0, train_wall=7, gb_free=68.1, wall=1739 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:27:19]    INFO >> epoch 007:   1495 / 1539 loss=4.052, wps=5159, ups=7.23, wpb=713.5, bsz=713.5, num_updates=10700, lr=7.4e-05, gnorm=6.803, clip=0, train_wall=7, gb_free=70.4, wall=1746 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:27:27]    INFO >> epoch 007 | loss 4.09 | wps 4463.8 | ups 6.26 | wpb 712.7 | bsz 712.7 | num_updates 10744 | lr 7.4e-05 | gnorm 6.365 | clip 0.7 | train_wall 217 | gb_free 70.2 | wall 1753 (progress_bar.py:267, print())[0m
[33m[2025-11-19 04:27:27] WARNING >> tensorboard or required dependencies not found, please see README for using tensorboard. (e.g. pip install tensorboardX) (progress_bar.py:314, __init__())[0m
[32m[2025-11-19 04:27:40]    INFO >> epoch 007 | valid on 'valid' subset | loss 4.05 | wps 11534.4 | wpb 5412.5 | bsz 5412.5 | num_updates 10744 | best_loss 5.983 (progress_bar.py:267, print())[0m
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
[32m[2025-11-19 04:27:41]    INFO >> è®­ç»ƒæ›²çº¿å·²ä¿å­˜: /home/zhaojunzhang/naturalcc/typilus/experiments/exp_lr_1e-4/logs/plots/training.png (train_enhanced.py:118, plot())[0m
[32m[2025-11-19 04:27:41]    INFO >> saved checkpoint /home/zhaojunzhang/naturalcc/typilus/experiments/exp_lr_1e-4/checkpoints/checkpoint_last.pt (epoch 7 @ 10744 updates, score 4.05) (writing took 0.013320 seconds) (checkpoint_utils.py:78, save_checkpoint())[0m
[33m[2025-11-19 04:27:41] WARNING >> tensorboard or required dependencies not found, please see README for using tensorboard. (e.g. pip install tensorboardX) (progress_bar.py:314, __init__())[0m
[32m[2025-11-19 04:27:41]    INFO >> epoch 008:      6 / 1539 loss=4.083, wps=1711.6, ups=2.34, wpb=730.3, bsz=730.3, num_updates=10750, lr=6.5e-05, gnorm=5.944, clip=0, train_wall=7, gb_free=68.7, wall=1767 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:27:49]    INFO >> epoch 008:     56 / 1539 loss=3.731, wps=5154.1, ups=7.01, wpb=735.8, bsz=735.8, num_updates=10800, lr=6.5e-05, gnorm=6.513, clip=2, train_wall=7, gb_free=73.9, wall=1775 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:27:58]    INFO >> epoch 008:    106 / 1539 loss=4.073, wps=4966.6, ups=6.48, wpb=766.8, bsz=766.8, num_updates=10850, lr=6.5e-05, gnorm=5.473, clip=0, train_wall=7, gb_free=73.2, wall=1782 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:28:05]    INFO >> epoch 008:    156 / 1539 loss=4.026, wps=4603, ups=7.06, wpb=652.3, bsz=652.3, num_updates=10900, lr=6.5e-05, gnorm=5.517, clip=0, train_wall=7, gb_free=75.6, wall=1789 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:28:13]    INFO >> epoch 008:    206 / 1539 loss=4.038, wps=5199.2, ups=6.23, wpb=834.7, bsz=834.7, num_updates=10950, lr=6.5e-05, gnorm=6.649, clip=2, train_wall=8, gb_free=73.5, wall=1797 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:28:20]    INFO >> epoch 008:    256 / 1539 loss=4.153, wps=4975.3, ups=6.97, wpb=714.1, bsz=714.1, num_updates=11000, lr=6.5e-05, gnorm=6.194, clip=0, train_wall=7, gb_free=71.5, wall=1805 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:28:27]    INFO >> epoch 008:    306 / 1539 loss=4.185, wps=4783, ups=6.64, wpb=720.8, bsz=720.8, num_updates=11050, lr=6.5e-05, gnorm=6.649, clip=0, train_wall=7, gb_free=71.8, wall=1812 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:28:37]    INFO >> epoch 008:    356 / 1539 loss=4.091, wps=4160.9, ups=6.25, wpb=665.6, bsz=665.6, num_updates=11100, lr=6.5e-05, gnorm=5.504, clip=0, train_wall=8, gb_free=74.7, wall=1820 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:28:44]    INFO >> epoch 008:    406 / 1539 loss=4.064, wps=4851.5, ups=6.86, wpb=707, bsz=707, num_updates=11150, lr=6.5e-05, gnorm=6.45, clip=0, train_wall=7, gb_free=72.1, wall=1827 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:28:52]    INFO >> epoch 008:    456 / 1539 loss=3.861, wps=5647.1, ups=6.45, wpb=875.6, bsz=875.6, num_updates=11200, lr=6.5e-05, gnorm=7.081, clip=0, train_wall=7, gb_free=72.6, wall=1835 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:28:59]    INFO >> epoch 008:    506 / 1539 loss=3.965, wps=5036.4, ups=6.72, wpb=749.6, bsz=749.6, num_updates=11250, lr=6.5e-05, gnorm=7.255, clip=0, train_wall=7, gb_free=74.3, wall=1843 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:29:08]    INFO >> epoch 008:    556 / 1539 loss=4.14, wps=4485, ups=6.89, wpb=651.2, bsz=651.2, num_updates=11300, lr=6.5e-05, gnorm=5.023, clip=0, train_wall=7, gb_free=71.8, wall=1850 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:29:15]    INFO >> epoch 008:    606 / 1539 loss=4.173, wps=4564.8, ups=6.69, wpb=682.8, bsz=682.8, num_updates=11350, lr=6.5e-05, gnorm=5.923, clip=0, train_wall=7, gb_free=75.2, wall=1857 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:29:22]    INFO >> epoch 008:    656 / 1539 loss=4.057, wps=4602.3, ups=7.23, wpb=636.2, bsz=636.2, num_updates=11400, lr=6.5e-05, gnorm=5.667, clip=0, train_wall=7, gb_free=72.5, wall=1864 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:29:30]    INFO >> epoch 008:    706 / 1539 loss=4.129, wps=4769.2, ups=6.89, wpb=691.9, bsz=691.9, num_updates=11450, lr=6.5e-05, gnorm=5.816, clip=0, train_wall=7, gb_free=70, wall=1871 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:29:38]    INFO >> epoch 008:    756 / 1539 loss=3.917, wps=4981.9, ups=6.85, wpb=727, bsz=727, num_updates=11500, lr=6.5e-05, gnorm=5.893, clip=0, train_wall=7, gb_free=70.9, wall=1879 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:29:46]    INFO >> epoch 008:    806 / 1539 loss=3.889, wps=4712.5, ups=6.79, wpb=694.2, bsz=694.2, num_updates=11550, lr=6.5e-05, gnorm=6.92, clip=2, train_wall=7, gb_free=68.9, wall=1886 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:29:52]    INFO >> epoch 008:    856 / 1539 loss=4.101, wps=4393.2, ups=7.37, wpb=595.7, bsz=595.7, num_updates=11600, lr=6.5e-05, gnorm=5.013, clip=0, train_wall=6, gb_free=71.5, wall=1893 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:30:00]    INFO >> epoch 008:    906 / 1539 loss=4.041, wps=5175.6, ups=6.36, wpb=813.3, bsz=813.3, num_updates=11650, lr=6.5e-05, gnorm=6.484, clip=0, train_wall=7, gb_free=74, wall=1901 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:30:07]    INFO >> epoch 008:    956 / 1539 loss=4.032, wps=4693.6, ups=6.96, wpb=674.1, bsz=674.1, num_updates=11700, lr=6.5e-05, gnorm=5.992, clip=0, train_wall=7, gb_free=72.9, wall=1908 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:30:14] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 33.25 MiB is free. Including non-PyTorch memory, this process has 79.08 GiB memory in use. Of the allocated memory 76.50 GiB is allocated by PyTorch, and 2.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:30:14] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 30           |        cudaMalloc retries: 59        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  78274 MiB |  78334 MiB | 377371 GiB | 377294 GiB |
|       from large pool |  78193 MiB |  78253 MiB | 375231 GiB | 375154 GiB |
|       from small pool |     80 MiB |     82 MiB |   2139 GiB |   2139 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  78274 MiB |  78334 MiB | 377371 GiB | 377294 GiB |
|       from large pool |  78193 MiB |  78253 MiB | 375231 GiB | 375154 GiB |
|       from small pool |     80 MiB |     82 MiB |   2139 GiB |   2139 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  78222 MiB |  78281 MiB | 376569 GiB | 376492 GiB |
|       from large pool |  78141 MiB |  78201 MiB | 374432 GiB | 374356 GiB |
|       from small pool |     80 MiB |     81 MiB |   2136 GiB |   2136 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  80472 MiB |  80498 MiB |    830 GiB | 770116 MiB |
|       from large pool |  80388 MiB |  80388 MiB |    825 GiB | 765152 MiB |
|       from small pool |     84 MiB |    246 MiB |      4 GiB |   4964 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   2137 MiB |   7144 MiB | 358016 GiB | 358014 GiB |
|       from large pool |   2134 MiB |   7133 MiB | 355596 GiB | 355594 GiB |
|       from small pool |      3 MiB |     33 MiB |   2419 GiB |   2419 GiB |
|---------------------------------------------------------------------------|
| Allocations           |    1796    |    1799    |   24927 K  |   24926 K  |
|       from large pool |     455    |     456    |   11890 K  |   11890 K  |
|       from small pool |    1341    |    1344    |   13037 K  |   13035 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    1796    |    1799    |   24927 K  |   24926 K  |
|       from large pool |     455    |     456    |   11890 K  |   11890 K  |
|       from small pool |    1341    |    1344    |   13037 K  |   13035 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     241    |     562    |    5866    |    5625    |
|       from large pool |     199    |     439    |    3342    |    3143    |
|       from small pool |      42    |     123    |    2524    |    2482    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     160    |     161    |   14099 K  |   14099 K  |
|       from large pool |     113    |     113    |    7829 K  |    7829 K  |
|       from small pool |      47    |      65    |    6269 K  |    6269 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:30:14] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:30:14] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:30:14] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:30:14] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:30:17]    INFO >> epoch 008:   1007 / 1539 loss=4.095, wps=3724.3, ups=6.18, wpb=602.8, bsz=602.8, num_updates=11750, lr=6.5e-05, gnorm=5.527, clip=0, train_wall=6, gb_free=70.6, wall=1916 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:30:27]    INFO >> epoch 008:   1057 / 1539 loss=3.862, wps=4055.2, ups=4.9, wpb=828.4, bsz=828.4, num_updates=11800, lr=6.5e-05, gnorm=5.849, clip=2, train_wall=10, gb_free=71.7, wall=1926 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:30:34]    INFO >> epoch 008:   1107 / 1539 loss=4.026, wps=4668.8, ups=7.06, wpb=661.2, bsz=661.2, num_updates=11850, lr=6.5e-05, gnorm=6.027, clip=0, train_wall=7, gb_free=72.8, wall=1933 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:30:41]    INFO >> epoch 008:   1157 / 1539 loss=4.134, wps=4025.3, ups=7.22, wpb=557.5, bsz=557.5, num_updates=11900, lr=6.5e-05, gnorm=5.269, clip=0, train_wall=7, gb_free=73.2, wall=1940 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:30:44] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 1.86 GiB. GPU 0 has a total capacity of 79.14 GiB of which 521.25 MiB is free. Including non-PyTorch memory, this process has 78.61 GiB memory in use. Of the allocated memory 75.66 GiB is allocated by PyTorch, and 2.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:30:44] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 31           |        cudaMalloc retries: 61        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  76954 MiB |  77477 MiB | 382821 GiB | 382746 GiB |
|       from large pool |  76941 MiB |  77464 MiB | 380654 GiB | 380579 GiB |
|       from small pool |     12 MiB |     19 MiB |   2167 GiB |   2167 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  76954 MiB |  77477 MiB | 382821 GiB | 382746 GiB |
|       from large pool |  76941 MiB |  77464 MiB | 380654 GiB | 380579 GiB |
|       from small pool |     12 MiB |     19 MiB |   2167 GiB |   2167 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  76936 MiB |  77458 MiB | 382008 GiB | 381933 GiB |
|       from large pool |  76923 MiB |  77445 MiB | 379844 GiB | 379769 GiB |
|       from small pool |     12 MiB |     19 MiB |   2164 GiB |   2164 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  79984 MiB |  80024 MiB |    903 GiB |    825 GiB |
|       from large pool |  79958 MiB |  79958 MiB |    898 GiB |    820 GiB |
|       from small pool |     26 MiB |     66 MiB |      4 GiB |      4 GiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   3029 MiB |   8676 MiB | 363956 GiB | 363953 GiB |
|       from large pool |   3016 MiB |   8662 MiB | 361504 GiB | 361502 GiB |
|       from small pool |     13 MiB |     27 MiB |   2451 GiB |   2451 GiB |
|---------------------------------------------------------------------------|
| Allocations           |     606    |     613    |   25272 K  |   25272 K  |
|       from large pool |     315    |     322    |   12070 K  |   12070 K  |
|       from small pool |     291    |     348    |   13202 K  |   13201 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     606    |     613    |   25272 K  |   25272 K  |
|       from large pool |     315    |     322    |   12070 K  |   12070 K  |
|       from small pool |     291    |     348    |   13202 K  |   13201 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |      91    |     111    |    5928    |    5837    |
|       from large pool |      78    |      78    |    3385    |    3307    |
|       from small pool |      13    |      33    |    2543    |    2530    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      92    |      92    |   14285 K  |   14285 K  |
|       from large pool |      67    |      67    |    7943 K  |    7943 K  |
|       from small pool |      25    |      56    |    6342 K  |    6342 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:30:44] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:30:44] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:30:44] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:30:44] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:30:51]    INFO >> epoch 008:   1208 / 1539 loss=4.04, wps=4329.9, ups=6.06, wpb=715, bsz=715, num_updates=11950, lr=6.5e-05, gnorm=5.56, clip=0, train_wall=7, gb_free=76, wall=1949 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:30:56] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 47.25 MiB is free. Including non-PyTorch memory, this process has 79.07 GiB memory in use. Of the allocated memory 77.61 GiB is allocated by PyTorch, and 983.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:30:56] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 32           |        cudaMalloc retries: 62        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  79414 MiB |  79474 MiB | 385104 GiB | 385026 GiB |
|       from large pool |  79015 MiB |  79075 MiB | 382922 GiB | 382845 GiB |
|       from small pool |    398 MiB |    399 MiB |   2181 GiB |   2181 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  79414 MiB |  79474 MiB | 385104 GiB | 385026 GiB |
|       from large pool |  79015 MiB |  79075 MiB | 382922 GiB | 382845 GiB |
|       from small pool |    398 MiB |    399 MiB |   2181 GiB |   2181 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  79398 MiB |  79458 MiB | 384287 GiB | 384209 GiB |
|       from large pool |  79002 MiB |  79061 MiB | 382108 GiB | 382031 GiB |
|       from small pool |    396 MiB |    397 MiB |   2178 GiB |   2178 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  80458 MiB |  80458 MiB |    903 GiB |    825 GiB |
|       from large pool |  80018 MiB |  80018 MiB |    898 GiB |    820 GiB |
|       from small pool |    440 MiB |    440 MiB |      5 GiB |      4 GiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |    983 MiB |   5675 MiB | 366593 GiB | 366592 GiB |
|       from large pool |    942 MiB |   5668 MiB | 364125 GiB | 364124 GiB |
|       from small pool |     41 MiB |     42 MiB |   2467 GiB |   2467 GiB |
|---------------------------------------------------------------------------|
| Allocations           |    7351    |    7354    |   25429 K  |   25421 K  |
|       from large pool |     938    |     939    |   12139 K  |   12138 K  |
|       from small pool |    6413    |    6416    |   13290 K  |   13283 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    7351    |    7354    |   25429 K  |   25421 K  |
|       from large pool |     938    |     939    |   12139 K  |   12138 K  |
|       from small pool |    6413    |    6416    |   13290 K  |   13283 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     299    |     299    |    6136    |    5837    |
|       from large pool |      79    |      79    |    3386    |    3307    |
|       from small pool |     220    |     220    |    2750    |    2530    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     473    |     473    |   14372 K  |   14372 K  |
|       from large pool |      80    |      80    |    7985 K  |    7985 K  |
|       from small pool |     393    |     393    |    6387 K  |    6386 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:30:56] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:30:56] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:30:56] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:30:56] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:30:59]    INFO >> epoch 008:   1259 / 1539 loss=4.088, wps=5049.3, ups=5.94, wpb=850.7, bsz=850.7, num_updates=12000, lr=6.5e-05, gnorm=6.191, clip=0, train_wall=8, gb_free=73.2, wall=1957 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:31:06]    INFO >> epoch 008:   1309 / 1539 loss=4.035, wps=4744.5, ups=6.74, wpb=704.3, bsz=704.3, num_updates=12050, lr=6.5e-05, gnorm=5.893, clip=0, train_wall=7, gb_free=72.7, wall=1964 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:31:14]    INFO >> epoch 008:   1359 / 1539 loss=4.029, wps=4492.8, ups=6.76, wpb=664.7, bsz=664.7, num_updates=12100, lr=6.5e-05, gnorm=5.455, clip=0, train_wall=7, gb_free=69.7, wall=1972 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:31:16] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacity of 79.14 GiB of which 1.20 GiB is free. Including non-PyTorch memory, this process has 77.92 GiB memory in use. Of the allocated memory 74.92 GiB is allocated by PyTorch, and 2.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:31:16] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 33           |        cudaMalloc retries: 64        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  76324 MiB |  78599 MiB | 388761 GiB | 388687 GiB |
|       from large pool |  76305 MiB |  78581 MiB | 386561 GiB | 386487 GiB |
|       from small pool |     18 MiB |     19 MiB |   2200 GiB |   2200 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  76324 MiB |  78599 MiB | 388761 GiB | 388687 GiB |
|       from large pool |  76305 MiB |  78581 MiB | 386561 GiB | 386487 GiB |
|       from small pool |     18 MiB |     19 MiB |   2200 GiB |   2200 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  76304 MiB |  78579 MiB | 387938 GiB | 387863 GiB |
|       from large pool |  76285 MiB |  78562 MiB | 385741 GiB | 385666 GiB |
|       from small pool |     18 MiB |     19 MiB |   2197 GiB |   2197 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  79276 MiB |  80398 MiB |    974 GiB |    897 GiB |
|       from large pool |  79252 MiB |  79958 MiB |    969 GiB |    892 GiB |
|       from small pool |     24 MiB |    440 MiB |      5 GiB |      5 GiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   2951 MiB |   4272 MiB | 370710 GiB | 370707 GiB |
|       from large pool |   2946 MiB |   4266 MiB | 368220 GiB | 368217 GiB |
|       from small pool |      5 MiB |     27 MiB |   2489 GiB |   2489 GiB |
|---------------------------------------------------------------------------|
| Allocations           |     637    |     643    |   25655 K  |   25655 K  |
|       from large pool |     340    |     346    |   12256 K  |   12256 K  |
|       from small pool |     297    |     348    |   13399 K  |   13398 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     637    |     643    |   25655 K  |   25655 K  |
|       from large pool |     340    |     346    |   12256 K  |   12256 K  |
|       from small pool |     297    |     348    |   13399 K  |   13398 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     106    |     298    |    6194    |    6088    |
|       from large pool |      94    |      95    |    3444    |    3350    |
|       from small pool |      12    |     220    |    2750    |    2738    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     112    |     114    |   14496 K  |   14496 K  |
|       from large pool |      89    |      91    |    8059 K  |    8059 K  |
|       from small pool |      23    |      59    |    6437 K  |    6437 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:31:16] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:31:16] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:31:16] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:31:16] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:31:25]    INFO >> epoch 008:   1410 / 1539 loss=4.022, wps=4125, ups=5, wpb=824.4, bsz=824.4, num_updates=12150, lr=6.5e-05, gnorm=6.467, clip=2, train_wall=7, gb_free=73, wall=1982 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:31:33]    INFO >> epoch 008:   1460 / 1539 loss=4.178, wps=4323.7, ups=6.05, wpb=715.2, bsz=715.2, num_updates=12200, lr=6.5e-05, gnorm=5.515, clip=0, train_wall=8, gb_free=75, wall=1990 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:31:41]    INFO >> epoch 008:   1510 / 1539 loss=4.053, wps=4483.3, ups=6.73, wpb=666.4, bsz=666.4, num_updates=12250, lr=6.5e-05, gnorm=5.823, clip=0, train_wall=7, gb_free=67.3, wall=1997 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:31:45]    INFO >> epoch 008 | loss 4.033 | wps 4398.1 | ups 6.17 | wpb 712.7 | bsz 712.7 | num_updates 12279 | lr 6.5e-05 | gnorm 6.002 | clip 0.3 | train_wall 218 | gb_free 74.8 | wall 2002 (progress_bar.py:267, print())[0m
[33m[2025-11-19 04:31:45] WARNING >> tensorboard or required dependencies not found, please see README for using tensorboard. (e.g. pip install tensorboardX) (progress_bar.py:314, __init__())[0m
[32m[2025-11-19 04:32:00]    INFO >> epoch 008 | valid on 'valid' subset | loss 4.037 | wps 11640.1 | wpb 5412.5 | bsz 5412.5 | num_updates 12279 | best_loss 5.983 (progress_bar.py:267, print())[0m
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
[32m[2025-11-19 04:32:00]    INFO >> è®­ç»ƒæ›²çº¿å·²ä¿å­˜: /home/zhaojunzhang/naturalcc/typilus/experiments/exp_lr_1e-4/logs/plots/training.png (train_enhanced.py:118, plot())[0m
[32m[2025-11-19 04:32:00]    INFO >> saved checkpoint /home/zhaojunzhang/naturalcc/typilus/experiments/exp_lr_1e-4/checkpoints/checkpoint_last.pt (epoch 8 @ 12279 updates, score 4.037) (writing took 0.012771 seconds) (checkpoint_utils.py:78, save_checkpoint())[0m
[33m[2025-11-19 04:32:00] WARNING >> tensorboard or required dependencies not found, please see README for using tensorboard. (e.g. pip install tensorboardX) (progress_bar.py:314, __init__())[0m
[32m[2025-11-19 04:32:03]    INFO >> epoch 009:     21 / 1539 loss=3.968, wps=1634.7, ups=2.44, wpb=668.9, bsz=668.9, num_updates=12300, lr=5.7e-05, gnorm=6.329, clip=0, train_wall=7, gb_free=73.1, wall=2018 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:32:10]    INFO >> epoch 009:     71 / 1539 loss=4.058, wps=4513.4, ups=6.8, wpb=663.6, bsz=663.6, num_updates=12350, lr=5.7e-05, gnorm=5.448, clip=0, train_wall=7, gb_free=73.5, wall=2025 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:32:17]    INFO >> epoch 009:    121 / 1539 loss=3.906, wps=4790.3, ups=6.96, wpb=688.4, bsz=688.4, num_updates=12400, lr=5.7e-05, gnorm=6.672, clip=0, train_wall=7, gb_free=73.7, wall=2032 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:32:26]    INFO >> epoch 009:    171 / 1539 loss=3.914, wps=5348, ups=6.35, wpb=842.4, bsz=842.4, num_updates=12450, lr=5.7e-05, gnorm=7.28, clip=2, train_wall=7, gb_free=71.8, wall=2040 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:32:33]    INFO >> epoch 009:    221 / 1539 loss=4.099, wps=4945.6, ups=7.15, wpb=691.5, bsz=691.5, num_updates=12500, lr=5.7e-05, gnorm=5.667, clip=0, train_wall=7, gb_free=71.5, wall=2047 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:32:40]    INFO >> epoch 009:    271 / 1539 loss=4.068, wps=5000.9, ups=7.11, wpb=703.6, bsz=703.6, num_updates=12550, lr=5.7e-05, gnorm=5.702, clip=0, train_wall=7, gb_free=70, wall=2054 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:32:48]    INFO >> epoch 009:    321 / 1539 loss=4.097, wps=5168, ups=6.59, wpb=784.5, bsz=784.5, num_updates=12600, lr=5.7e-05, gnorm=6.056, clip=0, train_wall=7, gb_free=66.3, wall=2062 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:32:56]    INFO >> epoch 009:    371 / 1539 loss=4.028, wps=4191.8, ups=5.98, wpb=701, bsz=701, num_updates=12650, lr=5.7e-05, gnorm=6.269, clip=0, train_wall=8, gb_free=65.8, wall=2070 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:32:57] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 1.86 GiB. GPU 0 has a total capacity of 79.14 GiB of which 213.25 MiB is free. Including non-PyTorch memory, this process has 78.91 GiB memory in use. Of the allocated memory 73.80 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:32:57] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 34           |        cudaMalloc retries: 66        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  75049 MiB |  75992 MiB | 409585 GiB | 409512 GiB |
|       from large pool |  75037 MiB |  75979 MiB | 407262 GiB | 407188 GiB |
|       from small pool |     12 MiB |     16 MiB |   2323 GiB |   2323 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  75049 MiB |  75992 MiB | 409585 GiB | 409512 GiB |
|       from large pool |  75037 MiB |  75979 MiB | 407262 GiB | 407188 GiB |
|       from small pool |     12 MiB |     16 MiB |   2323 GiB |   2323 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  75035 MiB |  75977 MiB | 408722 GiB | 408649 GiB |
|       from large pool |  75022 MiB |  75964 MiB | 406402 GiB | 406329 GiB |
|       from small pool |     12 MiB |     16 MiB |   2319 GiB |   2319 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  80292 MiB |  80292 MiB |    979 GiB |    901 GiB |
|       from large pool |  80266 MiB |  80266 MiB |    974 GiB |    895 GiB |
|       from small pool |     26 MiB |    124 MiB |      5 GiB |      5 GiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   5242 MiB |   8856 MiB | 391468 GiB | 391463 GiB |
|       from large pool |   5228 MiB |   8843 MiB | 388844 GiB | 388838 GiB |
|       from small pool |     13 MiB |     21 MiB |   2624 GiB |   2624 GiB |
|---------------------------------------------------------------------------|
| Allocations           |     605    |     613    |   26995 K  |   26995 K  |
|       from large pool |     314    |     322    |   12839 K  |   12839 K  |
|       from small pool |     291    |     341    |   14155 K  |   14155 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     605    |     613    |   26995 K  |   26995 K  |
|       from large pool |     314    |     322    |   12839 K  |   12839 K  |
|       from small pool |     291    |     341    |   14155 K  |   14155 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     103    |     156    |    6251    |    6148    |
|       from large pool |      90    |      94    |    3451    |    3361    |
|       from small pool |      13    |      62    |    2800    |    2787    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      98    |      98    |   15252 K  |   15252 K  |
|       from large pool |      72    |      72    |    8430 K  |    8430 K  |
|       from small pool |      26    |      43    |    6822 K  |    6821 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:32:57] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:32:57] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:32:57] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:32:57] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:33:06]    INFO >> epoch 009:    422 / 1539 loss=4.011, wps=4362.6, ups=6.09, wpb=716.4, bsz=716.4, num_updates=12700, lr=5.7e-05, gnorm=5.61, clip=0, train_wall=7, gb_free=73.1, wall=2079 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:33:13]    INFO >> epoch 009:    472 / 1539 loss=3.97, wps=4657.3, ups=6.74, wpb=691.3, bsz=691.3, num_updates=12750, lr=5.7e-05, gnorm=5.294, clip=0, train_wall=7, gb_free=74, wall=2086 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:33:21]    INFO >> epoch 009:    522 / 1539 loss=3.995, wps=5003.8, ups=6.58, wpb=760.8, bsz=760.8, num_updates=12800, lr=5.7e-05, gnorm=6, clip=0, train_wall=7, gb_free=72.7, wall=2094 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:33:29]    INFO >> epoch 009:    572 / 1539 loss=3.989, wps=4793.7, ups=6.38, wpb=750.9, bsz=750.9, num_updates=12850, lr=5.7e-05, gnorm=6.76, clip=2, train_wall=7, gb_free=74.2, wall=2101 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:33:30] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 25.25 MiB is free. Including non-PyTorch memory, this process has 79.09 GiB memory in use. Of the allocated memory 77.35 GiB is allocated by PyTorch, and 1.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:33:30] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 35           |        cudaMalloc retries: 67        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  79147 MiB |  79207 MiB | 415679 GiB | 415602 GiB |
|       from large pool |  79057 MiB |  79117 MiB | 413324 GiB | 413247 GiB |
|       from small pool |     89 MiB |     91 MiB |   2355 GiB |   2354 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  79147 MiB |  79207 MiB | 415679 GiB | 415602 GiB |
|       from large pool |  79057 MiB |  79117 MiB | 413324 GiB | 413247 GiB |
|       from small pool |     89 MiB |     91 MiB |   2355 GiB |   2354 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  79123 MiB |  79183 MiB | 414803 GiB | 414726 GiB |
|       from large pool |  79034 MiB |  79093 MiB | 412452 GiB | 412375 GiB |
|       from small pool |     89 MiB |     90 MiB |   2351 GiB |   2351 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  80480 MiB |  80482 MiB |    979 GiB |    901 GiB |
|       from large pool |  80386 MiB |  80386 MiB |    974 GiB |    895 GiB |
|       from small pool |     94 MiB |     96 MiB |      5 GiB |      5 GiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   1272 MiB |   7349 MiB | 398206 GiB | 398205 GiB |
|       from large pool |   1268 MiB |   7339 MiB | 395545 GiB | 395544 GiB |
|       from small pool |      4 MiB |     23 MiB |   2660 GiB |   2660 GiB |
|---------------------------------------------------------------------------|
| Allocations           |    1961    |    1964    |   27385 K  |   27383 K  |
|       from large pool |     470    |     471    |   13039 K  |   13038 K  |
|       from small pool |    1491    |    1494    |   14346 K  |   14345 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    1961    |    1964    |   27385 K  |   27383 K  |
|       from large pool |     470    |     471    |   13039 K  |   13038 K  |
|       from small pool |    1491    |    1494    |   14346 K  |   14345 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     139    |     140    |    6288    |    6149    |
|       from large pool |      92    |      92    |    3453    |    3361    |
|       from small pool |      47    |      48    |    2835    |    2788    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     130    |     131    |   15463 K  |   15463 K  |
|       from large pool |      78    |      79    |    8556 K  |    8556 K  |
|       from small pool |      52    |      54    |    6906 K  |    6906 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:33:30] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:33:30] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:33:30] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:33:30] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:33:38]    INFO >> epoch 009:    623 / 1539 loss=4.014, wps=4465.4, ups=6.29, wpb=709.4, bsz=709.4, num_updates=12900, lr=5.7e-05, gnorm=5.618, clip=0, train_wall=7, gb_free=65.9, wall=2109 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:33:45]    INFO >> epoch 009:    673 / 1539 loss=3.949, wps=4513.2, ups=6.85, wpb=658.7, bsz=658.7, num_updates=12950, lr=5.7e-05, gnorm=6.748, clip=0, train_wall=7, gb_free=71.5, wall=2117 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:33:53]    INFO >> epoch 009:    723 / 1539 loss=4.013, wps=4568.2, ups=6.81, wpb=671.1, bsz=671.1, num_updates=13000, lr=5.7e-05, gnorm=6.061, clip=0, train_wall=7, gb_free=71.2, wall=2124 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:34:00]    INFO >> epoch 009:    773 / 1539 loss=4.117, wps=4558.1, ups=6.57, wpb=693.9, bsz=693.9, num_updates=13050, lr=5.7e-05, gnorm=5.927, clip=2, train_wall=7, gb_free=57.9, wall=2132 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:34:09] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacity of 79.14 GiB of which 151.25 MiB is free. Including non-PyTorch memory, this process has 78.97 GiB memory in use. Of the allocated memory 77.59 GiB is allocated by PyTorch, and 897.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:34:09] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 36           |        cudaMalloc retries: 68        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  79058 MiB |  79456 MiB | 422841 GiB | 422763 GiB |
|       from large pool |  79039 MiB |  79437 MiB | 420449 GiB | 420372 GiB |
|       from small pool |     18 MiB |     19 MiB |   2391 GiB |   2391 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  79058 MiB |  79456 MiB | 422841 GiB | 422763 GiB |
|       from large pool |  79039 MiB |  79437 MiB | 420449 GiB | 420372 GiB |
|       from small pool |     18 MiB |     19 MiB |   2391 GiB |   2391 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  79031 MiB |  79429 MiB | 421950 GiB | 421873 GiB |
|       from large pool |  79012 MiB |  79410 MiB | 419562 GiB | 419485 GiB |
|       from small pool |     18 MiB |     19 MiB |   2388 GiB |   2388 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  80354 MiB |  80420 MiB |    979 GiB |    901 GiB |
|       from large pool |  80326 MiB |  80326 MiB |    974 GiB |    895 GiB |
|       from small pool |     28 MiB |     94 MiB |      5 GiB |      5 GiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   1295 MiB |   5531 MiB | 406084 GiB | 406083 GiB |
|       from large pool |   1286 MiB |   5521 MiB | 403382 GiB | 403380 GiB |
|       from small pool |      9 MiB |     25 MiB |   2702 GiB |   2702 GiB |
|---------------------------------------------------------------------------|
| Allocations           |     641    |     647    |   27845 K  |   27844 K  |
|       from large pool |     341    |     347    |   13278 K  |   13278 K  |
|       from small pool |     300    |     348    |   14567 K  |   14566 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     641    |     647    |   27845 K  |   27844 K  |
|       from large pool |     341    |     347    |   13278 K  |   13278 K  |
|       from small pool |     300    |     348    |   14567 K  |   14566 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     105    |     138    |    6288    |    6183    |
|       from large pool |      91    |      91    |    3453    |    3362    |
|       from small pool |      14    |      47    |    2835    |    2821    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      97    |     103    |   15710 K  |   15710 K  |
|       from large pool |      70    |      76    |    8707 K  |    8707 K  |
|       from small pool |      27    |      49    |    7003 K  |    7003 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:34:09] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:34:09] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:34:09] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:34:09] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:34:10]    INFO >> epoch 009:    824 / 1539 loss=3.937, wps=4504.6, ups=6.26, wpb=719.6, bsz=719.6, num_updates=13100, lr=5.7e-05, gnorm=6.291, clip=0, train_wall=7, gb_free=70.5, wall=2140 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:34:17]    INFO >> epoch 009:    874 / 1539 loss=4.031, wps=4715.6, ups=7.32, wpb=644.4, bsz=644.4, num_updates=13150, lr=5.7e-05, gnorm=5.388, clip=0, train_wall=6, gb_free=74.8, wall=2146 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:34:23]    INFO >> epoch 009:    924 / 1539 loss=4.1, wps=4474, ups=7.23, wpb=618.7, bsz=618.7, num_updates=13200, lr=5.7e-05, gnorm=4.904, clip=0, train_wall=7, gb_free=73.5, wall=2153 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:34:33]    INFO >> epoch 009:    974 / 1539 loss=3.801, wps=4702.5, ups=5.47, wpb=859.7, bsz=859.7, num_updates=13250, lr=5.7e-05, gnorm=6.509, clip=0, train_wall=9, gb_free=70.8, wall=2162 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:34:41]    INFO >> epoch 009:   1024 / 1539 loss=3.961, wps=4819, ups=6.7, wpb=718.9, bsz=718.9, num_updates=13300, lr=5.7e-05, gnorm=5.652, clip=0, train_wall=7, gb_free=69.9, wall=2170 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:34:49]    INFO >> epoch 009:   1074 / 1539 loss=3.815, wps=4808.7, ups=6.63, wpb=725.8, bsz=725.8, num_updates=13350, lr=5.7e-05, gnorm=6.575, clip=2, train_wall=7, gb_free=65.3, wall=2177 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:34:57]    INFO >> epoch 009:   1124 / 1539 loss=3.937, wps=5001.5, ups=6.58, wpb=760.3, bsz=760.3, num_updates=13400, lr=5.7e-05, gnorm=7.336, clip=4, train_wall=7, gb_free=73.5, wall=2185 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:35:04]    INFO >> epoch 009:   1174 / 1539 loss=4.059, wps=4803, ups=7.17, wpb=669.6, bsz=669.6, num_updates=13450, lr=5.7e-05, gnorm=5.344, clip=0, train_wall=7, gb_free=72.7, wall=2192 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:35:12]    INFO >> epoch 009:   1224 / 1539 loss=3.588, wps=5214.3, ups=6.05, wpb=862, bsz=862, num_updates=13500, lr=5.7e-05, gnorm=6.06, clip=2, train_wall=8, gb_free=69, wall=2200 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:35:21]    INFO >> epoch 009:   1274 / 1539 loss=3.963, wps=5064.8, ups=6.52, wpb=776.3, bsz=776.3, num_updates=13550, lr=5.7e-05, gnorm=6.067, clip=0, train_wall=7, gb_free=72.6, wall=2208 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:35:29]    INFO >> epoch 009:   1324 / 1539 loss=4.046, wps=4627.7, ups=6.49, wpb=712.6, bsz=712.6, num_updates=13600, lr=5.7e-05, gnorm=5.864, clip=0, train_wall=7, gb_free=75.1, wall=2216 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:35:36]    INFO >> epoch 009:   1374 / 1539 loss=3.848, wps=4836.4, ups=6.45, wpb=749.6, bsz=749.6, num_updates=13650, lr=5.7e-05, gnorm=5.588, clip=0, train_wall=7, gb_free=69.9, wall=2223 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:35:42] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 37.25 MiB is free. Including non-PyTorch memory, this process has 79.08 GiB memory in use. Of the allocated memory 76.24 GiB is allocated by PyTorch, and 2.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:35:42] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 37           |        cudaMalloc retries: 70        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  78007 MiB |  78067 MiB | 440587 GiB | 440511 GiB |
|       from large pool |  77625 MiB |  77685 MiB | 438093 GiB | 438017 GiB |
|       from small pool |    382 MiB |    383 MiB |   2494 GiB |   2493 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  78007 MiB |  78067 MiB | 440587 GiB | 440511 GiB |
|       from large pool |  77625 MiB |  77685 MiB | 438093 GiB | 438017 GiB |
|       from small pool |    382 MiB |    383 MiB |   2494 GiB |   2493 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  77777 MiB |  77836 MiB | 439658 GiB | 439582 GiB |
|       from large pool |  77397 MiB |  77456 MiB | 437167 GiB | 437092 GiB |
|       from small pool |    380 MiB |    381 MiB |   2490 GiB |   2490 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  80468 MiB |  80468 MiB |   1006 GiB |    927 GiB |
|       from large pool |  80046 MiB |  80046 MiB |   1000 GiB |    922 GiB |
|       from small pool |    422 MiB |    422 MiB |      5 GiB |      5 GiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   2400 MiB |   7496 MiB | 423378 GiB | 423376 GiB |
|       from large pool |   2360 MiB |   7489 MiB | 420558 GiB | 420555 GiB |
|       from small pool |     39 MiB |     40 MiB |   2820 GiB |   2820 GiB |
|---------------------------------------------------------------------------|
| Allocations           |    7054    |    7057    |   29063 K  |   29056 K  |
|       from large pool |     911    |     912    |   13873 K  |   13872 K  |
|       from small pool |    6143    |    6146    |   15190 K  |   15184 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    7054    |    7057    |   29063 K  |   29056 K  |
|       from large pool |     911    |     912    |   13873 K  |   13872 K  |
|       from small pool |    6143    |    6146    |   15190 K  |   15184 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     742    |     742    |    6935    |    6193    |
|       from large pool |     531    |     531    |    3903    |    3372    |
|       from small pool |     211    |     211    |    3032    |    2821    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     503    |     503    |   16394 K  |   16393 K  |
|       from large pool |     127    |     127    |    9094 K  |    9094 K  |
|       from small pool |     376    |     376    |    7300 K  |    7299 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:35:42] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:35:42] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:35:42] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:35:42] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:35:44]    INFO >> epoch 009:   1425 / 1539 loss=3.903, wps=4449.8, ups=6.58, wpb=676.7, bsz=676.7, num_updates=13700, lr=5.7e-05, gnorm=5.836, clip=0, train_wall=7, gb_free=72, wall=2231 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:35:52]    INFO >> epoch 009:   1475 / 1539 loss=4.012, wps=4361.6, ups=6.88, wpb=634.1, bsz=634.1, num_updates=13750, lr=5.7e-05, gnorm=6.322, clip=0, train_wall=7, gb_free=72.9, wall=2238 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:36:00]    INFO >> epoch 009:   1525 / 1539 loss=3.99, wps=4350.5, ups=6.98, wpb=623.3, bsz=623.3, num_updates=13800, lr=5.7e-05, gnorm=5.913, clip=0, train_wall=7, gb_free=67.9, wall=2245 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:36:02]    INFO >> epoch 009 | loss 3.972 | wps 4450.7 | ups 6.25 | wpb 712.7 | bsz 712.7 | num_updates 13814 | lr 5.7e-05 | gnorm 6.021 | clip 0.5 | train_wall 217 | gb_free 74.2 | wall 2248 (progress_bar.py:267, print())[0m
[33m[2025-11-19 04:36:02] WARNING >> tensorboard or required dependencies not found, please see README for using tensorboard. (e.g. pip install tensorboardX) (progress_bar.py:314, __init__())[0m
[32m[2025-11-19 04:36:14]    INFO >> epoch 009 | valid on 'valid' subset | loss 3.982 | wps 11884.7 | wpb 5412.5 | bsz 5412.5 | num_updates 13814 | best_loss 5.983 (progress_bar.py:267, print())[0m
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
[32m[2025-11-19 04:36:15]    INFO >> è®­ç»ƒæ›²çº¿å·²ä¿å­˜: /home/zhaojunzhang/naturalcc/typilus/experiments/exp_lr_1e-4/logs/plots/training.png (train_enhanced.py:118, plot())[0m
[32m[2025-11-19 04:36:15]    INFO >> saved checkpoint /home/zhaojunzhang/naturalcc/typilus/experiments/exp_lr_1e-4/checkpoints/checkpoint_last.pt (epoch 9 @ 13814 updates, score 3.982) (writing took 0.012619 seconds) (checkpoint_utils.py:78, save_checkpoint())[0m
[33m[2025-11-19 04:36:15] WARNING >> tensorboard or required dependencies not found, please see README for using tensorboard. (e.g. pip install tensorboardX) (progress_bar.py:314, __init__())[0m
[32m[2025-11-19 04:36:23]    INFO >> epoch 010:     36 / 1539 loss=3.965, wps=1603.9, ups=2.29, wpb=701.4, bsz=701.4, num_updates=13850, lr=4.8e-05, gnorm=5.561, clip=0, train_wall=8, gb_free=72.8, wall=2267 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:36:30]    INFO >> epoch 010:     86 / 1539 loss=3.992, wps=4938.8, ups=6.89, wpb=716.9, bsz=716.9, num_updates=13900, lr=4.8e-05, gnorm=6.439, clip=0, train_wall=7, gb_free=69.6, wall=2275 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:36:37]    INFO >> epoch 010:    136 / 1539 loss=3.914, wps=4354.5, ups=6.95, wpb=626.5, bsz=626.5, num_updates=13950, lr=4.8e-05, gnorm=5.506, clip=0, train_wall=7, gb_free=74.1, wall=2282 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:36:45]    INFO >> epoch 010:    186 / 1539 loss=3.922, wps=4614.5, ups=6.2, wpb=744.2, bsz=744.2, num_updates=14000, lr=4.8e-05, gnorm=6.214, clip=0, train_wall=8, gb_free=74.2, wall=2290 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:36:55]    INFO >> epoch 010:    236 / 1539 loss=3.818, wps=5189.5, ups=6.01, wpb=863.9, bsz=863.9, num_updates=14050, lr=4.8e-05, gnorm=6.548, clip=2, train_wall=8, gb_free=74.4, wall=2298 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:37:02]    INFO >> epoch 010:    286 / 1539 loss=3.959, wps=4551.7, ups=6.73, wpb=676, bsz=676, num_updates=14100, lr=4.8e-05, gnorm=6.191, clip=0, train_wall=7, gb_free=73.9, wall=2306 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:37:08] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacity of 79.14 GiB of which 953.25 MiB is free. Including non-PyTorch memory, this process has 78.19 GiB memory in use. Of the allocated memory 74.10 GiB is allocated by PyTorch, and 3.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:37:08] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 38           |        cudaMalloc retries: 72        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  72064 MiB |  75873 MiB | 458286 GiB | 458216 GiB |
|       from large pool |  72046 MiB |  75855 MiB | 455686 GiB | 455615 GiB |
|       from small pool |     17 MiB |     18 MiB |   2600 GiB |   2600 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  72064 MiB |  75873 MiB | 458286 GiB | 458216 GiB |
|       from large pool |  72046 MiB |  75855 MiB | 455686 GiB | 455615 GiB |
|       from small pool |     17 MiB |     18 MiB |   2600 GiB |   2600 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  72044 MiB |  75852 MiB | 457323 GiB | 457252 GiB |
|       from large pool |  72027 MiB |  75835 MiB | 454726 GiB | 454656 GiB |
|       from small pool |     17 MiB |     18 MiB |   2596 GiB |   2596 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  79552 MiB |  79754 MiB |   1029 GiB |    952 GiB |
|       from large pool |  79528 MiB |  79528 MiB |   1023 GiB |    946 GiB |
|       from small pool |     24 MiB |    226 MiB |      6 GiB |      6 GiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   4759 MiB |   7038 MiB | 438558 GiB | 438553 GiB |
|       from large pool |   4753 MiB |   7031 MiB | 435622 GiB | 435617 GiB |
|       from small pool |      6 MiB |     25 MiB |   2936 GiB |   2936 GiB |
|---------------------------------------------------------------------------|
| Allocations           |     606    |     615    |   30202 K  |   30201 K  |
|       from large pool |     308    |     317    |   14352 K  |   14352 K  |
|       from small pool |     298    |     342    |   15849 K  |   15849 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     606    |     615    |   30202 K  |   30201 K  |
|       from large pool |     308    |     317    |   14352 K  |   14352 K  |
|       from small pool |     298    |     342    |   15849 K  |   15849 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     149    |     250    |    7045    |    6896    |
|       from large pool |     137    |     137    |    3912    |    3775    |
|       from small pool |      12    |     113    |    3133    |    3121    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     141    |     142    |   17052 K  |   17052 K  |
|       from large pool |     113    |     114    |    9412 K  |    9412 K  |
|       from small pool |      28    |      52    |    7640 K  |    7640 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:37:08] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:37:08] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:37:08] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:37:08] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:37:10]    INFO >> epoch 010:    337 / 1539 loss=3.977, wps=4580.9, ups=6.51, wpb=703.9, bsz=703.9, num_updates=14150, lr=4.8e-05, gnorm=6.003, clip=0, train_wall=7, gb_free=67.2, wall=2313 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:37:18]    INFO >> epoch 010:    387 / 1539 loss=3.989, wps=4688.3, ups=6.48, wpb=723.5, bsz=723.5, num_updates=14200, lr=4.8e-05, gnorm=5.43, clip=0, train_wall=7, gb_free=73.3, wall=2321 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:37:25]    INFO >> epoch 010:    437 / 1539 loss=3.853, wps=4313.8, ups=6.83, wpb=631.4, bsz=631.4, num_updates=14250, lr=4.8e-05, gnorm=5.844, clip=0, train_wall=7, gb_free=72.6, wall=2328 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:37:34]    INFO >> epoch 010:    487 / 1539 loss=4, wps=4294, ups=6.42, wpb=668.5, bsz=668.5, num_updates=14300, lr=4.8e-05, gnorm=5.61, clip=0, train_wall=7, gb_free=72.5, wall=2336 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:37:41]    INFO >> epoch 010:    537 / 1539 loss=3.811, wps=4824.9, ups=7.47, wpb=645.7, bsz=645.7, num_updates=14350, lr=4.8e-05, gnorm=5.465, clip=0, train_wall=6, gb_free=75, wall=2343 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:37:49]    INFO >> epoch 010:    587 / 1539 loss=3.976, wps=4397.7, ups=6.61, wpb=665.2, bsz=665.2, num_updates=14400, lr=4.8e-05, gnorm=6.119, clip=0, train_wall=7, gb_free=71.4, wall=2350 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:37:56]    INFO >> epoch 010:    637 / 1539 loss=3.945, wps=5021.9, ups=6.98, wpb=719.7, bsz=719.7, num_updates=14450, lr=4.8e-05, gnorm=6.643, clip=0, train_wall=7, gb_free=69.1, wall=2358 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:38:04]    INFO >> epoch 010:    687 / 1539 loss=3.908, wps=5022.5, ups=6.91, wpb=726.6, bsz=726.6, num_updates=14500, lr=4.8e-05, gnorm=5.641, clip=0, train_wall=7, gb_free=73.3, wall=2365 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:38:08] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 41.25 MiB is free. Including non-PyTorch memory, this process has 79.08 GiB memory in use. Of the allocated memory 76.29 GiB is allocated by PyTorch, and 2.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:38:08] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 39           |        cudaMalloc retries: 73        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  78063 MiB |  78123 MiB | 469353 GiB | 469277 GiB |
|       from large pool |  77678 MiB |  77738 MiB | 466692 GiB | 466616 GiB |
|       from small pool |    384 MiB |    385 MiB |   2661 GiB |   2660 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  78063 MiB |  78123 MiB | 469353 GiB | 469277 GiB |
|       from large pool |  77678 MiB |  77738 MiB | 466692 GiB | 466616 GiB |
|       from small pool |    384 MiB |    385 MiB |   2661 GiB |   2660 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  78017 MiB |  78077 MiB | 468366 GiB | 468290 GiB |
|       from large pool |  77635 MiB |  77694 MiB | 465709 GiB | 465633 GiB |
|       from small pool |    382 MiB |    383 MiB |   2657 GiB |   2656 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  80464 MiB |  80464 MiB |   1033 GiB |    954 GiB |
|       from large pool |  80040 MiB |  80040 MiB |   1027 GiB |    948 GiB |
|       from small pool |    424 MiB |    424 MiB |      6 GiB |      6 GiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   2340 MiB |   6606 MiB | 449455 GiB | 449453 GiB |
|       from large pool |   2301 MiB |   6599 MiB | 446449 GiB | 446446 GiB |
|       from small pool |     39 MiB |     40 MiB |   3006 GiB |   3006 GiB |
|---------------------------------------------------------------------------|
| Allocations           |    7098    |    7101    |   30947 K  |   30940 K  |
|       from large pool |     915    |     916    |   14731 K  |   14730 K  |
|       from small pool |    6183    |    6186    |   16216 K  |   16209 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    7098    |    7101    |   30947 K  |   30940 K  |
|       from large pool |     915    |     916    |   14731 K  |   14730 K  |
|       from small pool |    6183    |    6186    |   16216 K  |   16209 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     402    |     402    |    7299    |    6897    |
|       from large pool |     190    |     190    |    3966    |    3776    |
|       from small pool |     212    |     212    |    3333    |    3121    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     495    |     496    |   17467 K  |   17466 K  |
|       from large pool |     118    |     118    |    9660 K  |    9660 K  |
|       from small pool |     377    |     378    |    7806 K  |    7805 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:38:08] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:38:08] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:38:08] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:38:08] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:38:12]    INFO >> epoch 010:    738 / 1539 loss=4.006, wps=4249.3, ups=6.61, wpb=642.7, bsz=642.7, num_updates=14550, lr=4.8e-05, gnorm=5.659, clip=0, train_wall=7, gb_free=68.7, wall=2372 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:38:20]    INFO >> epoch 010:    788 / 1539 loss=3.956, wps=4705.4, ups=6.51, wpb=723.3, bsz=723.3, num_updates=14600, lr=4.8e-05, gnorm=5.886, clip=0, train_wall=7, gb_free=67.8, wall=2380 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:38:27]    INFO >> epoch 010:    838 / 1539 loss=3.923, wps=4552.3, ups=6.75, wpb=673.9, bsz=673.9, num_updates=14650, lr=4.8e-05, gnorm=6.016, clip=2, train_wall=7, gb_free=66.8, wall=2387 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:38:36]    INFO >> epoch 010:    888 / 1539 loss=3.854, wps=5234.2, ups=6.17, wpb=848.7, bsz=848.7, num_updates=14700, lr=4.8e-05, gnorm=6.294, clip=0, train_wall=8, gb_free=76.2, wall=2396 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:38:44]    INFO >> epoch 010:    938 / 1539 loss=3.952, wps=4901, ups=6.87, wpb=713.5, bsz=713.5, num_updates=14750, lr=4.8e-05, gnorm=6.034, clip=2, train_wall=7, gb_free=74.7, wall=2403 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:38:51]    INFO >> epoch 010:    988 / 1539 loss=3.949, wps=4904.7, ups=7.1, wpb=690.7, bsz=690.7, num_updates=14800, lr=4.8e-05, gnorm=6.637, clip=0, train_wall=7, gb_free=74.4, wall=2410 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:38:58]    INFO >> epoch 010:   1038 / 1539 loss=4.006, wps=4678.8, ups=6.97, wpb=671.7, bsz=671.7, num_updates=14850, lr=4.8e-05, gnorm=6.073, clip=0, train_wall=7, gb_free=70, wall=2417 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:39:06]    INFO >> epoch 010:   1088 / 1539 loss=3.92, wps=5263.5, ups=6.55, wpb=803.8, bsz=803.8, num_updates=14900, lr=4.8e-05, gnorm=6.249, clip=0, train_wall=7, gb_free=72.8, wall=2425 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:39:14]    INFO >> epoch 010:   1138 / 1539 loss=3.949, wps=4245.2, ups=6.93, wpb=612.7, bsz=612.7, num_updates=14950, lr=4.8e-05, gnorm=5.264, clip=0, train_wall=7, gb_free=71.8, wall=2432 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:39:21] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 17.25 MiB is free. Including non-PyTorch memory, this process has 79.10 GiB memory in use. Of the allocated memory 76.47 GiB is allocated by PyTorch, and 2.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:39:21] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 40           |        cudaMalloc retries: 75        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  78250 MiB |  78310 MiB | 483183 GiB | 483107 GiB |
|       from large pool |  78169 MiB |  78229 MiB | 480446 GiB | 480370 GiB |
|       from small pool |     80 MiB |     82 MiB |   2736 GiB |   2736 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  78250 MiB |  78310 MiB | 483183 GiB | 483107 GiB |
|       from large pool |  78169 MiB |  78229 MiB | 480446 GiB | 480370 GiB |
|       from small pool |     80 MiB |     82 MiB |   2736 GiB |   2736 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  78222 MiB |  78281 MiB | 482164 GiB | 482088 GiB |
|       from large pool |  78141 MiB |  78201 MiB | 479431 GiB | 479355 GiB |
|       from small pool |     80 MiB |     81 MiB |   2732 GiB |   2732 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  80488 MiB |  80490 MiB |   1034 GiB |    955 GiB |
|       from large pool |  80404 MiB |  80404 MiB |   1028 GiB |    949 GiB |
|       from small pool |     84 MiB |    424 MiB |      6 GiB |      6 GiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   2177 MiB |   9886 MiB | 462307 GiB | 462304 GiB |
|       from large pool |   2174 MiB |   9877 MiB | 459213 GiB | 459211 GiB |
|       from small pool |      3 MiB |     21 MiB |   3093 GiB |   3093 GiB |
|---------------------------------------------------------------------------|
| Allocations           |    1796    |    1799    |   31868 K  |   31866 K  |
|       from large pool |     455    |     456    |   15195 K  |   15195 K  |
|       from small pool |    1341    |    1344    |   16672 K  |   16671 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    1796    |    1799    |   31868 K  |   31866 K  |
|       from large pool |     455    |     456    |   15195 K  |   15195 K  |
|       from small pool |    1341    |    1344    |   16672 K  |   16671 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     224    |     401    |    7332    |    7108    |
|       from large pool |     182    |     189    |    3969    |    3787    |
|       from small pool |      42    |     212    |    3363    |    3321    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     187    |     188    |   17986 K  |   17986 K  |
|       from large pool |     140    |     144    |    9970 K  |    9969 K  |
|       from small pool |      47    |      52    |    8016 K  |    8016 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:39:21] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:39:21] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:39:21] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:39:21] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:39:23]    INFO >> epoch 010:   1189 / 1539 loss=4.02, wps=4577.1, ups=5.81, wpb=787.9, bsz=787.9, num_updates=15000, lr=4.8e-05, gnorm=5.946, clip=0, train_wall=8, gb_free=70.1, wall=2440 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:39:31]    INFO >> epoch 010:   1239 / 1539 loss=3.827, wps=4984.8, ups=6.34, wpb=786.3, bsz=786.3, num_updates=15050, lr=4.8e-05, gnorm=6.365, clip=0, train_wall=7, gb_free=73.2, wall=2448 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:39:39]    INFO >> epoch 010:   1289 / 1539 loss=3.693, wps=4640.1, ups=6.05, wpb=766.5, bsz=766.5, num_updates=15100, lr=4.8e-05, gnorm=6.248, clip=0, train_wall=8, gb_free=72.7, wall=2457 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:39:47]    INFO >> epoch 010:   1339 / 1539 loss=4.03, wps=4638.3, ups=6.87, wpb=675.5, bsz=675.5, num_updates=15150, lr=4.8e-05, gnorm=5.475, clip=0, train_wall=7, gb_free=74.4, wall=2464 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:39:55]    INFO >> epoch 010:   1389 / 1539 loss=3.844, wps=5051.8, ups=6.77, wpb=746.1, bsz=746.1, num_updates=15200, lr=4.8e-05, gnorm=6.122, clip=2, train_wall=7, gb_free=73.6, wall=2471 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:40:02]    INFO >> epoch 010:   1439 / 1539 loss=3.83, wps=4591.7, ups=6.76, wpb=679.6, bsz=679.6, num_updates=15250, lr=4.8e-05, gnorm=5.86, clip=0, train_wall=7, gb_free=70.1, wall=2479 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:40:08] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 482.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 251.25 MiB is free. Including non-PyTorch memory, this process has 78.87 GiB memory in use. Of the allocated memory 73.46 GiB is allocated by PyTorch, and 4.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:40:08] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 41           |        cudaMalloc retries: 78        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  72822 MiB |  75426 MiB | 491921 GiB | 491850 GiB |
|       from large pool |  72809 MiB |  75413 MiB | 489137 GiB | 489066 GiB |
|       from small pool |     12 MiB |     24 MiB |   2784 GiB |   2784 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  72822 MiB |  75426 MiB | 491921 GiB | 491850 GiB |
|       from large pool |  72809 MiB |  75413 MiB | 489137 GiB | 489066 GiB |
|       from small pool |     12 MiB |     24 MiB |   2784 GiB |   2784 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  72801 MiB |  75403 MiB | 490883 GiB | 490812 GiB |
|       from large pool |  72788 MiB |  75391 MiB | 488103 GiB | 488032 GiB |
|       from small pool |     12 MiB |     24 MiB |   2780 GiB |   2780 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  80254 MiB |  80254 MiB |   1073 GiB |    995 GiB |
|       from large pool |  80228 MiB |  80228 MiB |   1067 GiB |    988 GiB |
|       from small pool |     26 MiB |    210 MiB |      6 GiB |      6 GiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   5153 MiB |   9503 MiB | 470014 GiB | 470009 GiB |
|       from large pool |   5140 MiB |   9488 MiB | 466866 GiB | 466861 GiB |
|       from small pool |     13 MiB |     33 MiB |   3148 GiB |   3148 GiB |
|---------------------------------------------------------------------------|
| Allocations           |     603    |     612    |   32444 K  |   32444 K  |
|       from large pool |     312    |     320    |   15487 K  |   15486 K  |
|       from small pool |     291    |     356    |   16957 K  |   16957 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     603    |     612    |   32444 K  |   32444 K  |
|       from large pool |     312    |     320    |   15487 K  |   15486 K  |
|       from small pool |     291    |     356    |   16957 K  |   16957 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     185    |     325    |    7504    |    7319    |
|       from large pool |     172    |     220    |    4078    |    3906    |
|       from small pool |      13    |     105    |    3426    |    3413    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     168    |     169    |   18312 K  |   18312 K  |
|       from large pool |     142    |     143    |   10166 K  |   10166 K  |
|       from small pool |      26    |      63    |    8146 K  |    8146 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:40:08] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:40:08] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:40:08] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:40:08] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:40:10]    INFO >> epoch 010:   1490 / 1539 loss=4.061, wps=4444.3, ups=6.4, wpb=694.7, bsz=694.7, num_updates=15300, lr=4.8e-05, gnorm=5.961, clip=0, train_wall=7, gb_free=64.7, wall=2487 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:40:19]    INFO >> epoch 010 | loss 3.926 | wps 4442.5 | ups 6.23 | wpb 712.7 | bsz 712.7 | num_updates 15349 | lr 4.8e-05 | gnorm 5.967 | clip 0.3 | train_wall 218 | gb_free 70.8 | wall 2494 (progress_bar.py:267, print())[0m
[33m[2025-11-19 04:40:19] WARNING >> tensorboard or required dependencies not found, please see README for using tensorboard. (e.g. pip install tensorboardX) (progress_bar.py:314, __init__())[0m
[32m[2025-11-19 04:40:32]    INFO >> epoch 010 | valid on 'valid' subset | loss 3.943 | wps 11662.9 | wpb 5412.5 | bsz 5412.5 | num_updates 15349 | best_loss 5.983 (progress_bar.py:267, print())[0m
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
[32m[2025-11-19 04:40:32]    INFO >> è®­ç»ƒæ›²çº¿å·²ä¿å­˜: /home/zhaojunzhang/naturalcc/typilus/experiments/exp_lr_1e-4/logs/plots/training.png (train_enhanced.py:118, plot())[0m
[32m[2025-11-19 04:40:32]    INFO >> saved checkpoint /home/zhaojunzhang/naturalcc/typilus/experiments/exp_lr_1e-4/checkpoints/checkpoint_last.pt (epoch 10 @ 15349 updates, score 3.943) (writing took 0.013508 seconds) (checkpoint_utils.py:78, save_checkpoint())[0m
[33m[2025-11-19 04:40:32] WARNING >> tensorboard or required dependencies not found, please see README for using tensorboard. (e.g. pip install tensorboardX) (progress_bar.py:314, __init__())[0m
[32m[2025-11-19 04:40:32]    INFO >> epoch 011:      1 / 1539 loss=3.966, wps=1747.7, ups=2.4, wpb=728.6, bsz=728.6, num_updates=15350, lr=4e-05, gnorm=5.593, clip=0, train_wall=7, gb_free=68.7, wall=2507 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:40:39]    INFO >> epoch 011:     51 / 1539 loss=3.924, wps=4594, ups=7.1, wpb=647.3, bsz=647.3, num_updates=15400, lr=4e-05, gnorm=5.62, clip=0, train_wall=7, gb_free=75, wall=2514 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:40:47]    INFO >> epoch 011:    101 / 1539 loss=3.78, wps=4912.3, ups=6.73, wpb=729.7, bsz=729.7, num_updates=15450, lr=4e-05, gnorm=6.595, clip=0, train_wall=7, gb_free=74.4, wall=2522 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:40:55]    INFO >> epoch 011:    151 / 1539 loss=4.059, wps=4848, ups=7.28, wpb=666, bsz=666, num_updates=15500, lr=4e-05, gnorm=5.19, clip=0, train_wall=6, gb_free=71.4, wall=2529 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:41:03]    INFO >> epoch 011:    201 / 1539 loss=3.709, wps=5098, ups=6.63, wpb=769.4, bsz=769.4, num_updates=15550, lr=4e-05, gnorm=6.521, clip=4, train_wall=7, gb_free=71.9, wall=2536 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:41:10]    INFO >> epoch 011:    251 / 1539 loss=3.85, wps=5112.1, ups=7.01, wpb=729.4, bsz=729.4, num_updates=15600, lr=4e-05, gnorm=6.427, clip=0, train_wall=7, gb_free=73.3, wall=2543 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:41:17]    INFO >> epoch 011:    301 / 1539 loss=3.905, wps=4257.9, ups=6.83, wpb=623.3, bsz=623.3, num_updates=15650, lr=4e-05, gnorm=5.523, clip=0, train_wall=7, gb_free=74.6, wall=2551 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:41:26]    INFO >> epoch 011:    351 / 1539 loss=3.875, wps=4971.6, ups=6.62, wpb=751.3, bsz=751.3, num_updates=15700, lr=4e-05, gnorm=6.18, clip=0, train_wall=7, gb_free=72, wall=2558 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:41:33]    INFO >> epoch 011:    401 / 1539 loss=3.947, wps=4881.9, ups=7.21, wpb=677.5, bsz=677.5, num_updates=15750, lr=4e-05, gnorm=5.682, clip=0, train_wall=7, gb_free=72.3, wall=2565 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:41:40]    INFO >> epoch 011:    451 / 1539 loss=3.948, wps=4463.5, ups=7.15, wpb=624.1, bsz=624.1, num_updates=15800, lr=4e-05, gnorm=6.572, clip=0, train_wall=7, gb_free=72.8, wall=2572 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:41:48]    INFO >> epoch 011:    501 / 1539 loss=4.041, wps=3687, ups=6.08, wpb=606.7, bsz=606.7, num_updates=15850, lr=4e-05, gnorm=5.21, clip=0, train_wall=8, gb_free=75, wall=2580 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:41:55]    INFO >> epoch 011:    551 / 1539 loss=3.9, wps=4536.7, ups=7.03, wpb=645.8, bsz=645.8, num_updates=15900, lr=4e-05, gnorm=6.647, clip=2, train_wall=7, gb_free=73.9, wall=2588 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:41:58] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 31.25 MiB is free. Including non-PyTorch memory, this process has 79.09 GiB memory in use. Of the allocated memory 76.39 GiB is allocated by PyTorch, and 2.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:41:58] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 42           |        cudaMalloc retries: 79        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  78168 MiB |  78228 MiB | 514019 GiB | 513943 GiB |
|       from large pool |  77782 MiB |  77842 MiB | 511102 GiB | 511026 GiB |
|       from small pool |    385 MiB |    386 MiB |   2916 GiB |   2916 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  78168 MiB |  78228 MiB | 514019 GiB | 513943 GiB |
|       from large pool |  77782 MiB |  77842 MiB | 511102 GiB | 511026 GiB |
|       from small pool |    385 MiB |    386 MiB |   2916 GiB |   2916 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  78137 MiB |  78197 MiB | 512935 GiB | 512858 GiB |
|       from large pool |  77753 MiB |  77813 MiB | 510022 GiB | 509946 GiB |
|       from small pool |    383 MiB |    384 MiB |   2912 GiB |   2912 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  80474 MiB |  80476 MiB |   1076 GiB |    997 GiB |
|       from large pool |  80050 MiB |  80050 MiB |   1069 GiB |    990 GiB |
|       from small pool |    424 MiB |    426 MiB |      7 GiB |      6 GiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   2245 MiB |   6868 MiB | 489062 GiB | 489060 GiB |
|       from large pool |   2207 MiB |   6862 MiB | 485767 GiB | 485765 GiB |
|       from small pool |     38 MiB |     40 MiB |   3295 GiB |   3295 GiB |
|---------------------------------------------------------------------------|
| Allocations           |    7120    |    7123    |   33914 K  |   33907 K  |
|       from large pool |     917    |     918    |   16134 K  |   16134 K  |
|       from small pool |    6203    |    6206    |   17779 K  |   17773 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    7120    |    7123    |   33914 K  |   33907 K  |
|       from large pool |     917    |     918    |   16134 K  |   16134 K  |
|       from small pool |    6203    |    6206    |   17779 K  |   17773 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     417    |     418    |    7739    |    7322    |
|       from large pool |     205    |     205    |    4113    |    3908    |
|       from small pool |     212    |     213    |    3626    |    3414    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     548    |     550    |   19159 K  |   19159 K  |
|       from large pool |     171    |     171    |   10604 K  |   10604 K  |
|       from small pool |     377    |     379    |    8555 K  |    8554 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:41:58] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:41:58] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:41:58] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:41:58] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:42:05]    INFO >> epoch 011:    602 / 1539 loss=3.94, wps=4318.5, ups=6.22, wpb=694.1, bsz=694.1, num_updates=15950, lr=4e-05, gnorm=5.832, clip=0, train_wall=7, gb_free=71.6, wall=2596 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:42:12]    INFO >> epoch 011:    652 / 1539 loss=3.814, wps=5226.7, ups=6.41, wpb=815.3, bsz=815.3, num_updates=16000, lr=4e-05, gnorm=6.426, clip=0, train_wall=7, gb_free=71.5, wall=2603 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:42:20]    INFO >> epoch 011:    702 / 1539 loss=4.007, wps=4607.9, ups=6.97, wpb=661.1, bsz=661.1, num_updates=16050, lr=4e-05, gnorm=5.287, clip=0, train_wall=7, gb_free=71, wall=2611 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:42:28]    INFO >> epoch 011:    752 / 1539 loss=3.783, wps=4411.7, ups=6.03, wpb=731.8, bsz=731.8, num_updates=16100, lr=4e-05, gnorm=6.49, clip=2, train_wall=8, gb_free=72.6, wall=2619 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:42:35] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 482.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 457.25 MiB is free. Including non-PyTorch memory, this process has 78.67 GiB memory in use. Of the allocated memory 73.46 GiB is allocated by PyTorch, and 4.72 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:42:35] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 43           |        cudaMalloc retries: 81        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  72821 MiB |  75424 MiB | 521026 GiB | 520955 GiB |
|       from large pool |  72808 MiB |  75411 MiB | 518072 GiB | 518001 GiB |
|       from small pool |     12 MiB |     21 MiB |   2953 GiB |   2953 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  72821 MiB |  75424 MiB | 521026 GiB | 520955 GiB |
|       from large pool |  72808 MiB |  75411 MiB | 518072 GiB | 518001 GiB |
|       from small pool |     12 MiB |     21 MiB |   2953 GiB |   2953 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  72801 MiB |  75403 MiB | 519925 GiB | 519854 GiB |
|       from large pool |  72788 MiB |  75391 MiB | 516976 GiB | 516905 GiB |
|       from small pool |     12 MiB |     21 MiB |   2949 GiB |   2949 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  80048 MiB |  80424 MiB |   1078 GiB |   1000 GiB |
|       from large pool |  80024 MiB |  80400 MiB |   1071 GiB |    993 GiB |
|       from small pool |     24 MiB |    424 MiB |      7 GiB |      7 GiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   7226 MiB |  10655 MiB | 495432 GiB | 495425 GiB |
|       from large pool |   7215 MiB |  10644 MiB | 492094 GiB | 492087 GiB |
|       from small pool |     11 MiB |     27 MiB |   3338 GiB |   3338 GiB |
|---------------------------------------------------------------------------|
| Allocations           |     603    |     612    |   34373 K  |   34372 K  |
|       from large pool |     312    |     320    |   16366 K  |   16366 K  |
|       from small pool |     291    |     356    |   18006 K  |   18006 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     603    |     612    |   34373 K  |   34372 K  |
|       from large pool |     312    |     320    |   16366 K  |   16366 K  |
|       from small pool |     291    |     356    |   18006 K  |   18006 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     182    |     416    |    7742    |    7560    |
|       from large pool |     170    |     204    |    4116    |    3946    |
|       from small pool |      12    |     212    |    3626    |    3614    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     175    |     176    |   19423 K  |   19423 K  |
|       from large pool |     147    |     148    |   10761 K  |   10761 K  |
|       from small pool |      28    |      63    |    8662 K  |    8662 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:42:35] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:42:35] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:42:35] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:42:35] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:42:37]    INFO >> epoch 011:    803 / 1539 loss=3.959, wps=3889.9, ups=6.64, wpb=586.3, bsz=586.3, num_updates=16150, lr=4e-05, gnorm=5.759, clip=0, train_wall=6, gb_free=62.8, wall=2626 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:42:44]    INFO >> epoch 011:    853 / 1539 loss=3.881, wps=4628.2, ups=7.04, wpb=657, bsz=657, num_updates=16200, lr=4e-05, gnorm=6.217, clip=0, train_wall=7, gb_free=74.8, wall=2633 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:42:51]    INFO >> epoch 011:    903 / 1539 loss=3.918, wps=5391.1, ups=6.91, wpb=779.8, bsz=779.8, num_updates=16250, lr=4e-05, gnorm=6.165, clip=0, train_wall=7, gb_free=72.7, wall=2641 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:42:59]    INFO >> epoch 011:    953 / 1539 loss=3.775, wps=4988.5, ups=6.69, wpb=746, bsz=746, num_updates=16300, lr=4e-05, gnorm=5.992, clip=0, train_wall=7, gb_free=72, wall=2648 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:43:07]    INFO >> epoch 011:   1003 / 1539 loss=3.932, wps=4841.5, ups=6.56, wpb=737.8, bsz=737.8, num_updates=16350, lr=4e-05, gnorm=5.834, clip=0, train_wall=7, gb_free=71.3, wall=2656 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:43:15]    INFO >> epoch 011:   1053 / 1539 loss=3.783, wps=4697.6, ups=6.78, wpb=692.9, bsz=692.9, num_updates=16400, lr=4e-05, gnorm=5.411, clip=0, train_wall=7, gb_free=73.7, wall=2663 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:43:20] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacity of 79.14 GiB of which 457.25 MiB is free. Including non-PyTorch memory, this process has 78.67 GiB memory in use. Of the allocated memory 70.08 GiB is allocated by PyTorch, and 8.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:43:20] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 44           |        cudaMalloc retries: 82        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  69006 MiB |  71763 MiB | 529586 GiB | 529518 GiB |
|       from large pool |  68989 MiB |  71746 MiB | 526586 GiB | 526518 GiB |
|       from small pool |     16 MiB |     17 MiB |   2999 GiB |   2999 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  69006 MiB |  71763 MiB | 529586 GiB | 529518 GiB |
|       from large pool |  68989 MiB |  71746 MiB | 526586 GiB | 526518 GiB |
|       from small pool |     16 MiB |     17 MiB |   2999 GiB |   2999 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  68980 MiB |  71736 MiB | 528466 GiB | 528399 GiB |
|       from large pool |  68963 MiB |  71719 MiB | 525471 GiB | 525403 GiB |
|       from small pool |     16 MiB |     17 MiB |   2995 GiB |   2995 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  80048 MiB |  80148 MiB |   1079 GiB |   1000 GiB |
|       from large pool |  80024 MiB |  80024 MiB |   1071 GiB |    993 GiB |
|       from small pool |     24 MiB |    124 MiB |      7 GiB |      7 GiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   8407 MiB |  12173 MiB | 503623 GiB | 503614 GiB |
|       from large pool |   8400 MiB |  12165 MiB | 500231 GiB | 500223 GiB |
|       from small pool |      7 MiB |     23 MiB |   3391 GiB |   3391 GiB |
|---------------------------------------------------------------------------|
| Allocations           |     641    |     649    |   34930 K  |   34930 K  |
|       from large pool |     343    |     351    |   16651 K  |   16650 K  |
|       from small pool |     298    |     342    |   18279 K  |   18279 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     641    |     649    |   34930 K  |   34930 K  |
|       from large pool |     343    |     351    |   16651 K  |   16650 K  |
|       from small pool |     298    |     342    |   18279 K  |   18279 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     182    |     232    |    7792    |    7610    |
|       from large pool |     170    |     170    |    4116    |    3946    |
|       from small pool |      12    |      62    |    3676    |    3664    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     164    |     165    |   19736 K  |   19736 K  |
|       from large pool |     137    |     138    |   10951 K  |   10951 K  |
|       from small pool |      27    |      55    |    8785 K  |    8785 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:43:20] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:43:20] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:43:20] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:43:20] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:43:23]    INFO >> epoch 011:   1104 / 1539 loss=3.983, wps=4455.3, ups=5.83, wpb=764, bsz=764, num_updates=16450, lr=4e-05, gnorm=5.555, clip=0, train_wall=8, gb_free=75, wall=2672 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:43:31]    INFO >> epoch 011:   1154 / 1539 loss=3.668, wps=5685.4, ups=6.25, wpb=909, bsz=909, num_updates=16500, lr=4e-05, gnorm=6.984, clip=2, train_wall=8, gb_free=69.3, wall=2680 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:43:40]    INFO >> epoch 011:   1204 / 1539 loss=3.886, wps=4047.8, ups=6.66, wpb=608.2, bsz=608.2, num_updates=16550, lr=4e-05, gnorm=5.913, clip=0, train_wall=7, gb_free=68.8, wall=2687 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:43:49]    INFO >> epoch 011:   1254 / 1539 loss=3.948, wps=4771.8, ups=5.76, wpb=828.9, bsz=828.9, num_updates=16600, lr=4e-05, gnorm=5.906, clip=0, train_wall=8, gb_free=73.1, wall=2696 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:43:56]    INFO >> epoch 011:   1304 / 1539 loss=3.896, wps=4957.9, ups=6.71, wpb=739.1, bsz=739.1, num_updates=16650, lr=4e-05, gnorm=6.56, clip=0, train_wall=7, gb_free=71.9, wall=2703 (progress_bar.py:258, log())[0m
[33m[2025-11-19 04:43:59] WARNING >> OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacity of 79.14 GiB of which 1.06 GiB is free. Including non-PyTorch memory, this process has 78.06 GiB memory in use. Of the allocated memory 74.92 GiB is allocated by PyTorch, and 2.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables) (ncc_trainers.py:760, _log_oom())[0m
[33m[2025-11-19 04:43:59] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 45           |        cudaMalloc retries: 85        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  76320 MiB |  78596 MiB | 536717 GiB | 536643 GiB |
|       from large pool |  76301 MiB |  78578 MiB | 533678 GiB | 533604 GiB |
|       from small pool |     18 MiB |     23 MiB |   3038 GiB |   3038 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  76320 MiB |  78596 MiB | 536717 GiB | 536643 GiB |
|       from large pool |  76301 MiB |  78578 MiB | 533678 GiB | 533604 GiB |
|       from small pool |     18 MiB |     23 MiB |   3038 GiB |   3038 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  76304 MiB |  78579 MiB | 535583 GiB | 535508 GiB |
|       from large pool |  76285 MiB |  78562 MiB | 532548 GiB | 532474 GiB |
|       from small pool |     18 MiB |     23 MiB |   3034 GiB |   3034 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  79424 MiB |  79424 MiB |   1176 GiB |   1099 GiB |
|       from large pool |  79400 MiB |  79400 MiB |   1169 GiB |   1091 GiB |
|       from small pool |     24 MiB |     76 MiB |      7 GiB |      7 GiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   3103 MiB |   4235 MiB | 510470 GiB | 510467 GiB |
|       from large pool |   3098 MiB |   4229 MiB | 507033 GiB | 507030 GiB |
|       from small pool |      5 MiB |     27 MiB |   3436 GiB |   3436 GiB |
|---------------------------------------------------------------------------|
| Allocations           |     640    |     646    |   35395 K  |   35394 K  |
|       from large pool |     340    |     346    |   16881 K  |   16880 K  |
|       from small pool |     300    |     356    |   18513 K  |   18513 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     640    |     646    |   35395 K  |   35394 K  |
|       from large pool |     340    |     346    |   16881 K  |   16880 K  |
|       from small pool |     300    |     356    |   18513 K  |   18513 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     110    |     179    |    7980    |    7870    |
|       from large pool |      98    |     141    |    4186    |    4088    |
|       from small pool |      12    |      38    |    3794    |    3782    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     125    |     125    |   20000 K  |   20000 K  |
|       from large pool |     100    |     100    |   11103 K  |   11103 K  |
|       from small pool |      25    |      61    |    8897 K  |    8897 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:43:59] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:43:59] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:43:59] WARNING >> |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
 (ncc_trainers.py:763, _log_oom())[0m
[33m[2025-11-19 04:43:59] WARNING >> attempting to recover from OOM in forward/backward pass (ncc_trainers.py:399, train_step())[0m
[32m[2025-11-19 04:44:06]    INFO >> epoch 011:   1355 / 1539 loss=3.892, wps=3501.7, ups=5.08, wpb=689.1, bsz=689.1, num_updates=16700, lr=4e-05, gnorm=6.277, clip=0, train_wall=7, gb_free=56.8, wall=2713 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:44:15]    INFO >> epoch 011:   1405 / 1539 loss=4.01, wps=5046.9, ups=6.38, wpb=791.3, bsz=791.3, num_updates=16750, lr=4e-05, gnorm=6.6, clip=2, train_wall=7, gb_free=73.5, wall=2721 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:44:23]    INFO >> epoch 011:   1455 / 1539 loss=3.873, wps=4516.8, ups=6.79, wpb=665.3, bsz=665.3, num_updates=16800, lr=4e-05, gnorm=6.007, clip=0, train_wall=7, gb_free=65.3, wall=2728 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:44:31]    INFO >> epoch 011:   1505 / 1539 loss=3.881, wps=5090.6, ups=6.22, wpb=818.6, bsz=818.6, num_updates=16850, lr=4e-05, gnorm=5.604, clip=0, train_wall=8, gb_free=72.5, wall=2736 (progress_bar.py:258, log())[0m
[32m[2025-11-19 04:44:36]    INFO >> epoch 011 | loss 3.887 | wps 4415.7 | ups 6.2 | wpb 712.7 | bsz 712.7 | num_updates 16884 | lr 4e-05 | gnorm 6.028 | clip 0.4 | train_wall 218 | gb_free 73.9 | wall 2742 (progress_bar.py:267, print())[0m
[33m[2025-11-19 04:44:36] WARNING >> tensorboard or required dependencies not found, please see README for using tensorboard. (e.g. pip install tensorboardX) (progress_bar.py:314, __init__())[0m
[32m[2025-11-19 04:44:50]    INFO >> epoch 011 | valid on 'valid' subset | loss 3.942 | wps 11980.7 | wpb 5412.5 | bsz 5412.5 | num_updates 16884 | best_loss 5.983 (progress_bar.py:267, print())[0m
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
[32m[2025-11-19 04:44:50]    INFO >> è®­ç»ƒæ›²çº¿å·²ä¿å­˜: /home/zhaojunzhang/naturalcc/typilus/experiments/exp_lr_1e-4/logs/plots/training.png (train_enhanced.py:118, plot())[0m
[32m[2025-11-19 04:44:50]    INFO >> saved checkpoint /home/zhaojunzhang/naturalcc/typilus/experiments/exp_lr_1e-4/checkpoints/checkpoint_last.pt (epoch 11 @ 16884 updates, score 3.942) (writing took 0.012529 seconds) (checkpoint_utils.py:78, save_checkpoint())[0m
[32m[2025-11-19 04:44:50]    INFO >> æ—©åœ: éªŒè¯æ€§èƒ½å·²10è½®æœªæå‡ (train_enhanced.py:345, single_main())[0m
[32m[2025-11-19 04:44:50]    INFO >> è®­ç»ƒå®Œæˆï¼Œç”¨æ—¶ 2698.4 ç§’ (train_enhanced.py:355, single_main())[0m
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
[32m[2025-11-19 04:44:51]    INFO >> è®­ç»ƒæ›²çº¿å·²ä¿å­˜: /home/zhaojunzhang/naturalcc/typilus/experiments/exp_lr_1e-4/logs/plots/training.png (train_enhanced.py:118, plot())[0m
[32m[2025-11-19 04:44:51]    INFO >> æ‰€æœ‰æ—¥å¿—å·²ä¿å­˜åˆ°: /home/zhaojunzhang/naturalcc/typilus/experiments/exp_lr_1e-4/logs (train_enhanced.py:359, single_main())[0m
