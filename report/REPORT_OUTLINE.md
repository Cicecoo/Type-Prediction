# 图神经网络实验报告大纲

## 整体结构建议

根据实际工作内容和老师要求，建议采用以下章节组织：

```
1. 概述 (1页)
2. 背景知识 (2-3页)
   2.1 图神经网络基础
   2.2 代码智能与类型推断
3. Typilus方法介绍 (2-3页)
   3.1 问题定义：Python类型推断
   3.2 Typilus模型设计
   3.3 训练与推理流程
4. 实验环境与数据准备 (2-3页)
   4.1 环境配置
   4.2 数据集构建
   4.3 数据处理流程
5. Typilus模型复现 (3-4页)
   5.1 模型训练
   5.2 推理与评估
   5.3 问题与解决
6. 对比实验 (4-5页)
   6.1 Transformer模型实现
   6.2 实验设计
   6.3 结果分析
7. 总结与展望 (1页)
8. 课程感想 (1页)
参考文献
```

---

## 详细内容组织

### 1. 概述 (1页)

**核心定位：这是一篇复现研究报告，而非原创方法论文**

#### 1.1 研究背景 (2-3段)

**第一段：问题背景**
Python作为动态类型语言，在提供开发灵活性的同时，也给大型项目的维护和调试带来挑战。自动类型推断技术能够为Python代码补充类型标注，帮助开发者及早发现类型错误，提高代码质量。近年来，基于深度学习的类型推断方法逐渐成为研究热点。

**第二段：课程背景**
图神经网络（Graph Neural Networks, GNN）作为一类处理图结构数据的深度学习模型，在代码智能领域展现出强大的能力（课程第10章）。本报告基于图神经网络课程所学内容，选择类型推断任务作为实践对象，通过复现经典方法并设计对比实验，加深对图神经网络在代码分析中应用的理解。

**第三段：本报告工作**
本报告的主要工作包括三个方面：
1. **复现Typilus模型**：基于PLDI 2020论文，在NaturalCC框架下复现Typilus方法，并在测试集上验证其类型推断准确率
2. **对比实验设计**：实现Transformer baseline，设计7组消融实验，系统性地探索模型架构和超参数对性能的影响
3. **工程实践**：构建完整的实验管理工具链，处理数据格式转换、词典构建、批量训练等工程问题

#### 1.2 报告定位与贡献 (2-3段)

**明确说明这不是原创方法：**

本报告属于**复现研究（Reproduction Study）**和**实验研究（Experimental Study）**。复现研究在科学研究中具有重要价值：一方面验证已发表方法的有效性和可靠性，另一方面为后续改进和扩展提供基线。本报告的主要贡献包括：

**技术贡献：**
1. **成功复现**：在不同环境和工具链下重现Typilus的核心算法，验证其在类型推断任务上的有效性
2. **系统性对比**：首次将Transformer模型应用于相同数据集和任务设置，提供不同模型架构的性能基准
3. **消融实验**：通过7组实验系统地分析了模型大小、层数、学习率等关键超参数的影响，为实际应用提供调参参考

**工程贡献：**
1. **环境适配**：解决NaturalCC框架在新环境下的多个兼容性问题（依赖版本、词典格式、特殊token等）
2. **数据转换**：实现Typilus图数据到Transformer序列格式的转换，统一词典构建
3. **自动化工具**：开发实验管理、批量运行、结果分析等工具，支持可复现的实验流程

**学习价值：**
通过完整的复现和实验过程，深入理解了：
- 图神经网络在代码智能中的实际应用
- 消息传递机制如何捕获代码的结构化信息
- 从理论到实践的技术细节和工程挑战

#### 1.3 报告组织 (1段)

本报告的后续章节组织如下：第2章介绍图神经网络和代码智能的背景知识；第3章详细描述Typilus方法的原理和设计；第4章介绍实验环境配置和数据准备过程；第5章展示Typilus模型的复现结果和遇到的技术问题；第6章描述Transformer对比实验的设计和结果分析；第7章总结全文并展望未来工作；第8章分享课程学习感想。

---

**写作要点：**

✅ **正面回应"复现"的定位**
- 不要回避这是复现研究
- 强调复现研究的科学价值
- 突出系统性实验和工程实践的贡献

✅ **避免过度承诺**
- 不要说"提出了新方法"
- 不要说"超越了state-of-the-art"
- 可以说"首次对比"、"系统性分析"

✅ **体现学习视角**
- 这是课程实验报告，学习价值本身就是贡献
- "通过复现加深理解"是合理的目标
- 工程实践能力的提升也是成果

✅ **量化工作量**
- "解决了15+个技术问题"
- "构建了5个工具脚本"
- "设计了7组对比实验"

---

### 2. 背景知识 (3-4页)

**整体思路：**从课程内容出发，逐步聚焦到类型推断任务，体现"课程学习→问题理解→方法选择"的逻辑链条。

#### 2.1 图神经网络基础 (1.5页)

**内容框架（对应课程第1-5章）：**

**2.1.1 图结构数据与表示学习** (0.5页)
- 图的定义与类型（课程第1章）
- 图的计算任务：节点级、边级、图级
- 图嵌入的目标：将图映射到低维向量空间

**2.1.2 图神经网络模型** (1页)
- 从图嵌入到图神经网络（课程第4-5章）
- 谱域方法：基于图傅里叶变换和图滤波（课程第5章）
  - 拉普拉斯矩阵：$L = D - A$
  - 图卷积的频域理解
- 空间域方法：消息传递机制（课程第5章）
  - 邻居聚合：$h_v^{(l+1)} = \sigma(W \cdot \text{AGG}(\{h_u^{(l)} : u \in N(v)\}))$
  - 多层堆叠与感受野扩展
- 图池化（课程第5章）

**写作要点：**
- **明确标注课程章节**，如"根据课程第5章的介绍..."
- 复用 `report/body/survey.tex` 中的内容，但调整顺序和侧重点
- 保持定义和公式的规范性
- 图示说明消息传递过程（可以直接引用课程PPT）

#### 2.2 代码智能与图神经网络 (1-1.5页)

**内容框架（对应课程第10章）：**

**2.2.1 源码表示学习** (0.5页)
- 程序的图结构表示（课程第10章）：
  - 抽象语法树（AST）：语法结构
  - 控制流图（CFG）：执行流程
  - 数据流图（DFG）：变量依赖
  - 代码属性图（CPG）：多种关系的融合
- 为什么用图神经网络：
  - 捕获长距离依赖
  - 综合语法和语义信息
  - 端到端学习

**2.2.2 图神经网络在代码智能中的应用** (0.5-1页)
- 节点级任务：变量误用检测、类型推断
- 图级任务：代码缺陷检测、代码克隆检测
- 序列生成任务：神经代码补全
- 本报告关注：**类型推断任务**

**写作要点：**
- 明确指出"根据课程第10章..."
- 用简单代码示例说明不同图结构
- 突出类型推断任务的特点：节点级预测 + 类型空间建模

#### 2.3 Python类型推断问题 (0.5-1页)

**内容要点：**

**2.3.1 问题背景**
- Python动态类型的优势与挑战
- 静态类型标注（Type Hints）的重要性
- 自动类型推断的需求

**2.3.2 相关工作**
- 基于规则的方法：pytype、mypy
- 基于机器学习的方法：
  - Type4Py (序列模型)
  - **Typilus (图神经网络)** ← 本报告的复现对象
  - LambdaNet (概率图模型)
  - 其他Transformer-based方法

**2.3.3 本报告的研究问题**
- **主要任务**：复现Typilus方法，验证其有效性
- **探索问题**：Transformer模型在类型推断任务上的性能
- **系统性实验**：超参数对模型性能的影响

**写作要点：**
- 明确定位：这是**复现研究 + 对比实验**
- 避免过度承诺"创新性"
- 强调"系统性验证"和"工程实践"的价值

---

### 3. Typilus方法介绍 (2-3页)

**这是核心章节，需要"学生视角的理解"但保持正式简洁**

#### 3.1 问题定义 (0.5页)

**内容要点：**
- 输入：Python源代码
- 输出：变量和表达式的类型标注
- 数据表示：代码属性图（CPG）
  - 节点：变量、表达式、语句
  - 边：数据流、控制流、语法依赖

**写作建议：**
- 用简单例子说明（如图1）
- 形式化定义：给定图 $G=(V,E)$ 和节点特征 $X$，预测节点类型 $y_i$

#### 3.2 Typilus模型设计 (1-1.5页)

**内容要点（学生理解视角）：**

1. **图构建**
   - 使用pytype进行类型推断，提取已知类型标注
   - 构建代码属性图，包含：
     - 语法边：AST结构
     - 数据流边：变量使用-定义关系
     - 控制流边：执行顺序
   - 节点特征：token embedding

2. **GNN编码器**
   - 使用GGNN（Gated Graph Neural Network）
   - 多层消息传递：$h_v^{(l+1)} = \text{GRU}(h_v^{(l)}, \text{AGG}(\{h_u^{(l)} : u \in N(v)\}))$
   - 聚合邻居信息，更新节点表示

3. **类型预测**
   - 节点表示 → 类型空间映射
   - 使用triplet loss训练：
     - 相同类型的节点在嵌入空间中距离近
     - 不同类型的节点距离远

**写作建议：**
- 用图示说明架构（输入→图构建→GNN→预测）
- 关键公式简洁给出，重点解释直观含义
- 突出设计选择的合理性：
  - 为什么用GGNN？（处理有向图和多关系边）
  - 为什么用triplet loss？（类型空间的相似性建模）

#### 3.3 训练与推理流程 (0.5页)

**内容要点：**
- 训练数据：已标注类型的开源Python仓库
- 训练目标：最小化triplet loss + 交叉熵loss
- 推理：给定新代码，构建图 → GNN编码 → 类型预测

**写作建议：**
- 流程图清晰展示
- 为后续"复现"章节做铺垫

---

### 4. 实验环境与数据准备 (2-3页)

**这部分体现工作量和工程实践能力**

#### 4.1 环境配置 (0.5-1页)

**内容要点：**
- 硬件环境：服务器配置（128GB内存，80GB显存×4）
- 软件环境：
  - Python 3.8 + NaturalCC工具集
  - PyTorch 2.4.0 + DGL 2.4.0（CUDA 12.4）
  - 依赖版本协调：transformers, tokenizers, numpy等

**工作量体现：**
- 版本冲突解决（列举关键问题）
- DGL与PyTorch的CUDA版本匹配
- 环境变量配置（NCC路径）

#### 4.2 数据集构建 (1-1.5页)

**内容要点：**

1. **原始数据获取**
   - 从GitHub克隆500+开源Python仓库
   - 使用pytype进行静态类型分析
   - 生成类型标注和图结构

2. **本地化改进**（工作量体现）
   - 脱离Docker容器限制
   - 编写 `prepare_data_local.sh` 本地处理脚本
   - 优化克隆和处理流程

3. **数据统计**
   - 数据集规模：训练集/验证集/测试集
   - 类型分布
   - 图结构特点（平均节点数、边数等）

**写作建议：**
- 用表格展示数据统计
- 说明数据处理的挑战和解决方案

#### 4.3 数据处理流程 (0.5-1页)

**内容要点：**
- NaturalCC格式转换：
  - `ncc_dataset.prepare_dataset('typilus')`
  - `ncc_dataset.binarize_dataset('typilus')`
- 数据预处理：
  - 词典构建
  - 图索引化
  - 批次采样

**工作量体现：**
- 编码问题处理
- 缺失依赖安装
- 配置文件修改

---

### 5. Typilus模型复现 (3-4页)

**这部分是"复现"的核心，要体现完整性和遇到的挑战**

#### 5.1 模型训练 (1.5-2页)

**内容要点：**

1. **训练配置**
   - 超参数设置（从config.yml）：
     - 学习率：1e-3
     - Batch size：32
     - Epoch：5
     - Dropout：0.1
   - GPU设备选择

2. **训练过程**
   - 训练曲线（loss下降）
   - 每个epoch时间
   - 显存占用情况

3. **遇到的问题与解决**（重点！）
   
   **问题1：显存溢出**
   - 现象：第1个epoch验证阶段OOM（尝试分配65GB）
   - 原因：triplet loss计算时 $B \times B$ 距离矩阵过大
   - 解决：修改计算方式，分批计算距离
   
   **问题2：训练不稳定**
   - 现象：第3个epoch后loss波动不下降
   - 分析：可能原因包括学习率过大、梯度爆炸
   - 尝试：调整学习率和warmup策略（后续实验）

**写作建议：**
- 用图表展示训练曲线
- 详细描述问题解决过程（体现调试能力）
- 代码片段展示关键修改

#### 5.2 推理与评估 (1页)

**内容要点：**

1. **推理流程**
   - 加载训练好的模型
   - 在测试集上进行预测
   - 计算准确率、Top-5准确率等指标

2. **评估结果**
   - Typilus模型性能（表格）
   - 与论文报告的对比
   - 结果分析

3. **实现细节**
   - 编写推理脚本
   - 批量预测优化

**写作建议：**
- 表格清晰展示指标
- 讨论复现质量（是否达到论文水平）

#### 5.3 问题与解决汇总 (0.5-1页)

**内容要点（工作量体现）：**

除了训练中的问题，还包括：
- 词典格式问题
- 特殊token处理
- 数据加载异常
- 版本兼容性

**写作建议：**
- 用列表或表格汇总
- 每个问题：现象→原因→解决方案
- 体现系统性调试思路

---

### 6. 对比实验 (4-5页)

**这部分是"改进和探索"，符合老师对"接近满分"的要求**

#### 6.1 Transformer模型实现 (1.5-2页)

**内容要点：**

1. **动机**
   - GNN的局限性：过平滑、表达能力受限
   - Transformer的优势：全局注意力、更强的序列建模能力
   - 研究问题：在类型推断任务上，Transformer能否超越GNN？

2. **数据格式转换**（工作量体现）
   - Typilus图数据 → Transformer序列格式
   - 实现 `convert_typilus_to_transformer.py`
   - 生成 `train.code`, `train.type` 等文件
   - 构建统一词典（10001 tokens）

3. **词典与Token问题修复**（重要！体现调试能力）
   
   **遇到的问题系列：**
   - Dictionary初始化方式错误（`load()` vs `__init__()`）
   - 特殊token映射不一致（`<unk>` vs `[UNK]`）
   - pad_idx设置错误（-1 vs 0）
   - 重复token问题
   - valid_step返回值问题
   
   **解决过程：**
   - 阅读源码理解Dictionary实现
   - 修改数据加载逻辑
   - 统一特殊token处理
   - （用代码diff或截图展示关键修改）

4. **模型架构**
   - Encoder: LSTM或Transformer
   - 配置选项：层数、维度、注意力头数
   - 与Typilus的对比：序列建模 vs 图建模

**写作建议：**
- 架构图对比Typilus和Transformer
- 详细说明数据转换逻辑（可能是审稿人关注点）
- 用表格列出解决的问题清单

#### 6.2 实验设计 (1页)

**内容要点：**

1. **实验目标**
   - 验证Transformer在类型推断任务的有效性
   - 探索不同超参数的影响（消融实验）
   - 对比不同编码器架构

2. **实验设置**

   设计7组对比实验：
   
   | 实验组 | 变量 | 取值 |
   |--------|------|------|
   | Baseline | - | LSTM, 2层, 512维 |
   | Model Size | embed_dim | 128, 256, 512 |
   | Layers | n_layers | 1, 2, 4, 6 |
   | Learning Rate | lr | 1e-3, 5e-4, 1e-4 |
   | Dropout | dropout | 0.1, 0.3, 0.5 |
   | Encoder Type | encoder | LSTM, Transformer |
   | Batch Size | batch_size | 16, 32, 64 |

3. **实验管理工具**（工程能力体现）
   - `run_transformer_experiment.py`：单实验管理
   - `generate_experiment_suite.py`：批量生成配置
   - `run_batch_experiments.py`：并行运行
   - `analyze_results.py`：结果分析和可视化

4. **快速验证**
   - `run_quick_test.py`：小数据集（1000样本）快速测试
   - 2 epoch验证完整pipeline
   - 在正式实验前排除bug

**写作建议：**
- 表格清晰列出实验配置
- 说明工具链的必要性（15个实验，自动化管理）
- 可以附录中展示工具使用示例

#### 6.3 结果分析 (1.5-2页)

**内容要点：**

1. **整体结果**
   - 所有实验的准确率对比（表格+柱状图）
   - Typilus vs Transformer baseline
   - 最佳配置识别

2. **消融实验分析**
   
   **模型大小（embed_dim）：**
   - 结果：512 > 256 > 128
   - 分析：更大的表示空间捕获更丰富的类型信息
   
   **层数（n_layers）：**
   - 结果：[填入实际结果]
   - 分析：过深可能过拟合或梯度消失
   
   **学习率（lr）：**
   - 结果：[填入实际结果]
   - 分析：学习率对收敛速度和最终性能的影响
   
   **其他超参数...**

3. **编码器对比**
   - LSTM vs Transformer
   - 分析：
     - Transformer的全局注意力是否有优势？
     - 计算开销对比
     - 适用场景讨论

4. **训练曲线**
   - 不同配置的loss和accuracy曲线
   - 收敛速度对比
   - 过拟合分析

5. **案例分析**（可选）
   - 展示一些预测样例
   - 正确预测和错误预测的分析
   - 模型的优势和局限

**写作建议：**
- 大量使用图表（柱状图、折线图、热力图）
- 每个结论有数据支撑
- 分析要有深度，不只是描述现象

**如果实验尚未完成：**
- 说明实验设计和预期
- 展示部分初步结果
- 讨论可能的结果和意义

---

### 7. 总结与展望 (1页)

**内容要点：**

1. **工作总结**
   - 成功复现Typilus模型，验证其有效性
   - 实现Transformer baseline，完成系统化对比实验
   - 构建完整的实验管理工具链
   - 深入理解了GNN在代码智能中的应用

2. **主要发现**
   - Typilus在图结构建模上的优势
   - Transformer在[某方面]的表现
   - 超参数对性能的影响规律
   - 工程实践中的关键问题

3. **局限性**
   - 数据集规模限制
   - 计算资源限制
   - 模型复杂度与推理速度的权衡

4. **未来工作**
   - 结合Transformer和GNN的混合模型
   - 引入预训练语言模型（如CodeBERT）
   - 扩展到其他类型推断任务
   - 在实际项目中的应用探索

---

### 8. 课程感想 (1页)

**内容要点：**

1. **理论收获**
   - 对图神经网络的深入理解
   - 消息传递机制的直观认识
   - 从理论到实践的跨越

2. **实践收获**
   - 大型深度学习项目的调试经验
   - 实验管理和版本控制的重要性
   - 科研实验的系统性思维

3. **挑战与成长**
   - 环境配置的复杂性
   - 问题定位和解决能力的提升
   - 阅读论文和源码的能力

4. **对课程的建议**（可选）
   - 更多实践案例
   - 工程实践指导
   - 协作交流机会

---

## 附录建议

**A. 实验配置文件示例**
- config.yml完整示例
- 关键参数说明

**B. 工具使用说明**
- 实验管理工具的使用方法
- 命令行示例

**C. 详细实验结果**
- 完整的实验数据表格
- 更多可视化图表

**D. 代码仓库**
- GitHub链接
- 关键代码片段

---

## 写作建议汇总

### 语言风格
- 正式但不失可读性
- 专业术语准确使用
- 避免过于口语化

### 图表使用
- 每个关键概念配图说明
- 实验结果必须有图表
- 图表标题和标注清晰

### 工作量体现
- 详细描述问题解决过程
- 不要一笔带过"配置环境"等
- 用具体数字说明规模（如"解决了15个版本冲突"）

### 学术规范
- 引用Typilus原文
- 引用NaturalCC工具集论文
- 引用相关方法（GNN、Transformer等）
- 所有公式、定义标准化

### 创新性体现
- Transformer对比实验是自己设计的
- 实验管理工具链是自己开发的
- 问题解决方案是独立完成的

---

## 预估篇幅

| 章节 | 页数 |
|------|------|
| 1. 概述 | 1 |
| 2. 背景知识 | 2-3 |
| 3. Typilus方法介绍 | 2-3 |
| 4. 实验环境与数据准备 | 2-3 |
| 5. Typilus模型复现 | 3-4 |
| 6. 对比实验 | 4-5 |
| 7. 总结与展望 | 1 |
| 8. 课程感想 | 1 |
| 参考文献 | 1 |
| **总计** | **17-24页** |

---

## 下一步行动

1. **补充实验数据**
   - 完成Transformer实验（如未完成）
   - 收集所有实验结果
   - 生成可视化图表

2. **素材准备**
   - 训练曲线截图
   - 代码diff截图
   - 数据统计表格

3. **撰写顺序建议**
   - 先写4、5章（实验部分，最清楚）
   - 再写6章（对比实验）
   - 然后写3章（Typilus方法，可参考论文）
   - 再写2章（背景知识，可复用现有内容）
   - 最后写1、7、8章（总结性内容）

4. **时间安排**
   - 第1-2天：完成实验（如需要）
   - 第3-4天：撰写实验部分（4-6章）
   - 第5天：撰写方法和背景（2-3章）
   - 第6天：撰写概述和总结（1、7、8章）
   - 第7天：润色和排版
