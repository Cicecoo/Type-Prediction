\section{背景知识}
\label{sec:related}

近年来，面向图结构数据的表示学习与图神经网络（Graph Neural Networks, GNN）得到了广泛关注。
本节从三个方面对相关工作进行简要综述：
首先回顾图结构数据与图表示学习的基础；讨论图神经网络模型的主要类别，及其鲁棒性与可扩展性；
最后结合课程涉及的若干应用领域，重点介绍自然语言处理、代码智能及其与大语言模型的结合。


\subsection{图结构数据与图表示学习}

\subsubsection{图及其典型任务}

图是一类用于刻画实体及其关系的通用数据结构，通常记为 $G = (V, E)$，其中 $V$ 为节点集合，$E$ 为边集合。
根据具体场景，可以得到带权图、有向图、异质图、多关系图和二分图等多种变体，广泛存在于社交网络、引文网络、知识图谱、生物分子结构以及程序代码等领域。

围绕图结构数据，常见学习任务大致包括三个层次：
节点级任务（如节点分类与节点属性预测）、边级任务（如链接预测和关系预测）以及以子图或整图为对象的任务（如图分类）。
这些任务的一个共同需求是将图中的节点、边或子图映射到低维向量空间，
以便采用标准的机器学习或深度学习模型进行处理，这一过程通常被称为图表示学习或图嵌入。

\subsubsection{谱图论与图信号处理}

在图上构建表示学习和神经网络模型时，一个核心问题是如何形式化"相邻节点应当有相似表示"这一直观要求。
谱图论提供了一种自然的刻画方式。
给定图的邻接矩阵 $A$ 和度矩阵 $D$，无向图的拉普拉斯矩阵通常定义为
\begin{equation}
    \label{eq:laplacian_simple}
    L = D - A.
\end{equation}
拉普拉斯二次型 $x^\top L x$ 可以被理解为对图信号平滑性的度量：
当相邻节点取值差异较大时，该值变大；当相邻节点取值相近时，该值较小，因此 $L$ 在一定意义上刻画了信号在图上的“粗糙程度”。

通过对拉普拉斯矩阵进行特征分解，可以得到一组“图上的正交基”，并据此定义图傅立叶变换，将图信号分解为不同“频率”的成分。
特征值较小的模式对应在图上变化缓慢的低频成分，特征值较大的模式对应变化剧烈的高频成分。
在这一框架下，对图信号进行低通滤波就对应于一种“平滑”操作，即在图结构约束下拉近相邻节点的特征。
许多谱方法的图卷积以及部分消息传递式 GNN，都可以在这一谱图论视角下解释为某种形式的图滤波。

\subsubsection{图嵌入方法}

在对图信号平滑性有了基本理解之后，一个自然的问题是如何据此构造具体的表示学习算法，
即如何将图中的节点嵌入到欧氏空间中的向量表示。
在图神经网络框架出现之前，相关研究主要沿着两条思路展开。

一条思路基于矩阵分解和谱嵌入，通过对拉普拉斯矩阵或相似度矩阵进行特征分解，
将节点嵌入到低维空间，并尽量保持图的局部邻接关系或整体结构，
拉普拉斯特征映射（Laplacian Eigenmaps）与谱聚类等方法属于这一类。
另一条思路基于随机游走和词向量技术。
在图上进行随机游走，将得到的节点序列类比为自然语言中的句子，
再借助word2vec风格的目标函数学习节点嵌入。
该方法认为在随机游走中经常共同出现的节点应具有相似的表示，
从而在嵌入空间中保持一阶、二阶邻接关系以及更高阶共现信息，典型代表包括DeepWalk、LINE等方法。

总体来看，这些方法解决了如何将图编码为向量的问题，
但通常采用"先嵌入、再建模"的两阶段流程，
嵌入学习与下游任务相互独立，无法端到端优化。
为实现表示学习与任务目标的联合训练，图神经网络应运而生。

\subsection{图神经网络模型及其扩展}

\subsubsection{核心思想与主要类别}

图神经网络将卷积神经网络“局部聚合与参数共享”的思想推广到一般图结构上。
其核心机制是通过消息传递,让节点从邻居收集信息并进行聚合与非线性变换,
叠加多层后逐步扩展感受野,从而同时捕获图的局部与全局特征。

根据卷积的定义方式,GNN 主要分为谱域方法和空间域方法。
谱域方法基于拉普拉斯谱和图傅立叶变换定义卷积,通过多项式近似实现局部化和高效计算;
空间域方法(也称消息传递方法)直接在邻接结构上进行邻居聚合,是当前应用最广泛的一类。
从任务角度看,GNN 可统一用于节点级(如节点分类、类型预测)、边级(如链接预测)和图级任务(如图分类)。

\subsubsection{图神经网络的鲁棒性与可扩展性}

在实际应用中,图结构和节点特征往往包含噪声,甚至可能受到对抗性攻击。
已有工作从攻击对象(节点特征、图结构)、攻击目标(针对性或无差别)和攻击者知识(白盒、黑盒等)等维度对图对抗攻击进行建模,
并通过对抗训练、显式学习“干净”图结构和在聚合过程中引入结构正则化等方式提升模型鲁棒性。

随着图规模增大,标准 GCN 等模型面临邻域爆炸问题:多层传播后感受野迅速扩张,计算和存储开销急剧增加。
为在大规模图上高效训练,GNN 引入了多种采样策略,包括为每个节点随机采样固定数量邻居的逐点采样,
在每层整体采样一批节点或边的逐层采样,以及基于图划分的子图/簇采样。
这些方法在可接受的计算和内存成本下,使模型能够扩展到包含百万乃至上亿节点的图数据。

\subsection{图神经网络应用}

\subsubsection{图神经网络与代码智能}

在代码智能（code intelligence）场景中，程序语言具有严格的语法规则和可执行语义，
适合构建多种程序图表示，例如抽象语法树（Abstract Syntax Tree, AST）、控制流图（Control Flow Graph, CFG）、
数据流图（Data Flow Graph, DFG）以及融合多种静态分析信息的代码属性图（Code Property Graph, CPG）等。
在这些程序图上应用图神经网络，通过多跳消息传递可以同时聚合局部上下文与远距离依赖，
从语法与语义两个层面刻画代码的结构化特征。

基于程序图的图神经网络已被用于多种代码分析任务。
在图级或子图级任务中，典型问题包括代码漏洞或缺陷检测、恶意代码识别等，
需要对一个函数、方法或更大代码片段给出整体判定；
在节点级任务中，常见问题包括静态类型推断、变量误用检测、变量命名建议等，
需要对变量或表达式节点进行精细化预测；
在序列到序列类任务中，还可以结合程序图表示生成代码摘要或支持代码搜索。
其中，基于 Typilus 的类型推断对应于在程序图上进行节点级预测，
模型需要综合语法结构与上下文信息，以推断变量和表达式的类型。

\subsubsection{其他应用}

除代码智能外，图神经网络在多个领域得到了广泛应用。
在生物信息学中，分子和蛋白质天然可建模为图，GNN 被用于分子性质预测、蛋白质结构与界面建模，
以及药物--靶点、药物--蛋白质和药物--疾病等相互作用预测任务。
在自然语言处理领域，可将句子解析为依存树或语义图、将文档构成文档图，
GNN 通过在这些结构上传播信息，提升了语义角色标注、关系抽取和多跳问答等任务中对长距离依赖和全局语义的建模能力。
在知识图谱和多关系网络中，实体与关系构成异质图或多关系图，
基于图表示学习与消息传递的模型在知识补全和多跳推理等任务中表现出良好效果。

近年来，图神经网络与大语言模型（Large Language Models, LLM）的结合也成为前沿方向。
一类工作在图结构上引入 Transformer 或进行图预训练，并将所学图表示或图结构编码为 LLM 的条件输入，
以更好地利用知识图谱、文档图或代码图等结构信息；
另一类工作则利用 LLM 为节点和边生成自然语言描述或补全缺失信息，为图提供更丰富的语义特征。
二者的结合在自然语言处理与代码分析等场景中展现出显著潜力，
也为基于程序图的类型推断等任务提供了进一步扩展的空间。
