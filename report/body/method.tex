\section{Typilus方法介绍}
\label{sec:method}

本章介绍Typilus方法的核心思想和模型设计。
Typilus\cite{typilus2020}是PLDI 2020发表的基于图神经网络的Python类型推断方法,
通过在代码属性图上进行消息传递,学习变量和表达式的类型表示。

\subsection{问题定义}

Python类型推断任务的目标是为源代码中的变量和表达式自动补充类型标注。
形式化地,给定一段Python代码,首先将其表示为代码属性图 $G=(V,E)$,
其中节点集 $V$ 包含变量、表达式、语句等程序元素,
边集 $E$ 包含数据流、控制流和语法依赖等关系。
每个节点 $v \in V$ 有初始特征 $x_v$(如token embedding),
任务目标是预测节点的类型标签 $y_v \in \mathcal{T}$,其中 $\mathcal{T}$ 是预定义的类型集合。

代码属性图的构建涉及多种静态分析技术。
首先通过抽象语法树(AST)解析源代码的语法结构,
再通过数据流分析提取变量的定义-使用关系,
最后融合控制流信息构成完整的代码属性图。
这一图结构相比单纯的序列表示,能够显式刻画变量之间的依赖关系和程序的执行逻辑,
为图神经网络提供了丰富的结构信息。

\subsection{模型设计}

Typilus模型采用图神经网络对代码属性图进行编码,
通过多跳消息传递聚合节点的邻域信息,学习类型相关的表示。
模型的核心组件包括图构建、GNN编码器和类型预测三个部分。

\subsubsection{图构建与节点特征}

给定Python源文件,Typilus使用pytype工具进行静态类型推断,
提取已知的类型标注和类型信息作为监督信号。
在此基础上构建代码属性图,包含以下类型的边:
\begin{itemize}
    \item \textbf{语法边}:源自抽象语法树的父子关系和兄弟关系
    \item \textbf{数据流边}:变量的定义-使用关系,表示值的传播路径
    \item \textbf{控制流边}:语句之间的执行顺序关系
    \item \textbf{类型边}:已知类型标注之间的关联
\end{itemize}

节点的初始特征由token名称的词嵌入构成,
采用预训练的word2vec或随机初始化后端到端学习。
对于不同类型的边,模型为每种边类型学习独立的消息传递参数,
以区分不同语义关系在类型推断中的作用。

\subsubsection{GGNN编码器}

Typilus采用门控图神经网络(Gated Graph Neural Network, GGNN)\cite{ggnn2016}作为编码器。
GGNN通过门控循环单元(GRU)更新节点表示,在每一层中,
节点 $v$ 收集其邻居节点的信息并进行加权聚合:
\begin{equation}
    \label{eq:ggnn_aggregate}
    a_v^{(l)} = \sum_{u \in N(v)} W_{r(u,v)} h_u^{(l)},
\end{equation}
其中 $N(v)$ 是节点 $v$ 的邻居集合,$r(u,v)$ 是边的类型,$W_{r(u,v)}$ 是对应的权重矩阵。

聚合后的信息通过GRU单元更新节点表示:
\begin{equation}
    \label{eq:ggnn_update}
    h_v^{(l+1)} = \text{GRU}(h_v^{(l)}, a_v^{(l)}).
\end{equation}

相比标准的图卷积网络,GGNN的门控机制能够更好地控制信息流动,
避免梯度消失并保留长距离依赖。
经过 $L$ 层消息传递后,节点获得融合了 $L$ 跳邻域信息的表示 $h_v^{(L)}$,
用于后续的类型预测。

\subsubsection{类型预测与训练}

Typilus将类型预测建模为度量学习问题,而非直接分类。
具体地,将类型集合 $\mathcal{T}$ 中的每个类型 $t$ 也表示为向量 $e_t$,
通过三元组损失(triplet loss)训练模型:
\begin{equation}
    \label{eq:triplet_loss}
    \mathcal{L}_{\text{triplet}} = \max(0, d(h_v, e_{t_v}) - d(h_v, e_{t'}) + \alpha),
\end{equation}
其中 $t_v$ 是节点 $v$ 的真实类型,$t'$ 是负例类型,$d(\cdot,\cdot)$ 是欧氏距离,$\alpha$ 是间隔超参数。
该损失函数鼓励节点表示靠近其真实类型的嵌入,远离其他类型的嵌入。

此外,模型还结合交叉熵损失进行分类训练,
综合度量学习和监督学习的优势。
最终的损失函数为两者的加权组合:
\begin{equation}
    \label{eq:total_loss}
    \mathcal{L} = \mathcal{L}_{\text{triplet}} + \lambda \mathcal{L}_{\text{CE}},
\end{equation}
其中 $\mathcal{L}_{\text{CE}}$ 是交叉熵损失,$\lambda$ 是权重系数。

推理时,对于给定代码中的待预测节点,
首先通过GGNN编码器得到节点表示 $h_v$,
然后计算其与所有类型嵌入 $e_t$ 的距离,
选择距离最小的类型作为预测结果:
\begin{equation}
    \label{eq:prediction}
    \hat{t}_v = \arg\min_{t \in \mathcal{T}} d(h_v, e_t).
\end{equation}

\subsection{训练与推理流程}

Typilus的完整流程包括数据准备、模型训练和推理三个阶段。

在数据准备阶段,从GitHub收集大量开源Python项目,
使用pytype工具提取类型标注,过滤掉类型信息过少或无法解析的文件。
对于每个文件,构建代码属性图并提取训练样本。
样本由图结构、节点特征和已知类型标注组成,
划分为训练集、验证集和测试集。

在模型训练阶段,采用随机梯度下降优化损失函数。
训练过程中需要注意类型分布的不平衡问题:
常见类型(如int、str)的样本远多于罕见类型。
Typilus通过类型采样策略缓解该问题,
在构造mini-batch时确保各类型均有代表。
此外,由于代码图的规模差异较大,
采用动态批处理策略,根据图的大小调整batch size,
避免显存溢出。

在推理阶段,给定新代码文件,
首先构建代码属性图,提取节点特征,
然后加载训练好的模型进行前向传播,
得到所有节点的类型预测。
对于每个预测,模型还可以输出置信度(基于距离的倒数),
帮助用户识别不确定的预测结果。
